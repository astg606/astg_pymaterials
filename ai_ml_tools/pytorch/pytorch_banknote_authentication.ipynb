{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71bce70-9dc3-448b-9f9a-8896e83b6d09",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Course Series</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h1><font color=\"red\">\n",
    "        Banknote Authentication Problem with PyTorch\n",
    "    </font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df4d162-122d-47d2-bdf4-45895a93bc6b",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Objectives</font>\n",
    "\n",
    "In this presentation, we use a simple classification dataset to:\n",
    "\n",
    "- Build a PyTorch model\n",
    "- Train the model\n",
    "- Evaluate the model\n",
    "\n",
    "We show the steps for building a Machine Learning (ML) model with PyTorch. The functions presented here can be used as reference for other ML applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec71f2-3cbc-42eb-a080-3b987b707390",
   "metadata": {},
   "source": [
    "# <font color=\"red\">References</font>\n",
    "\n",
    "- [Banknote Authentication using Machine Learning Algorithms](https://www.coditude.com/insights/banknote-authentication-using-machine-learning-algorithms/)\n",
    "- [Comparative Analysis Of Machine Learning Based Bank Note Authentication Through Variable Selection](https://nhsjs.com/2023/comparative-analysis-of-machine-learning-based-bank-note-authentication-through-variable-selection/) by Rick Nie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e02d09-9b14-4830-8973-f268ec8c2bb0",
   "metadata": {},
   "source": [
    "# <font color=\"red\"> Python packages used</font>\n",
    "\n",
    "- __Matplotlib__: Create visualization.\n",
    "- __Pandas__: Data (two-dimensional labelled array) manipulation and analysis.\n",
    "- __Scikit-Learn__:  Provide supervised and unsupervised Machine Learning algorithms.\n",
    "- __PyTorch__: Used to to build, train, and evaluate a deep machine learning algorithm based on Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002780f8-b579-4d36-a0eb-d11f0db4dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    print(\"Running in Google Colab\")\n",
    "except:\n",
    "    print(\"Not running in Google Colab\")\n",
    "else:\n",
    "    print(\"Installing modules in Google Colab\")\n",
    "    !pip install seaborn\n",
    "    !pip install -U scikit-learn\n",
    "    !pip3 uninstall --yes torch torchaudio torchvision torchtext torchdata\n",
    "    !pip3 install torch torchaudio torchvision torchtext torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40223c7-e654-45b5-bd57-03f788418db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355bc5a3-aa20-4097-bd46-50d31762eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17763b-8baf-40a2-9d71-825d42d82b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee059fe1-47c6-4011-908d-3d338bf70173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06afe3c-f18d-4b68-9ce0-92a34a085094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775d10f-4277-4a1a-a01c-261ee032b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c03f2b-c0c4-4b7e-8af4-98df1be6f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9549676-2fa5-41a7-bbb9-ce03f5797c34",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Loading the dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2194fb57-a0a2-455d-a6a9-a411684fd058",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Description of the data</font>\n",
    "\n",
    "- We have a dataset which consists on information on banknotes.\n",
    "- Banknotes are classified into two classes whether they are real or not:\n",
    "   - `1`: fake banknote\n",
    "   - `0`: real banknote\n",
    "- We want to build a Machine Learning model to be able to predict the classes given a set of banknotes.\n",
    "- We will use __logistic regression__ that is a statistical method for predicting binary classes.\n",
    "   - It is a special case of linear regression where the target variable is categorical in nature.\n",
    "   - It is one of the most simple and commonly used Machine Learning algorithms for two-class classification.\n",
    "   - The outcome or the target variable has only two possible classes.\n",
    "   - It predicts the probability of occurrence of a binary event utilizing a logit function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2778b4-e2b3-4a7c-8b8f-07e0e08a4501",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Read the data</font>\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "- We use 1372 images that were taken from genuine and forged banknote-like specimens.\n",
    "- Wavelet Transform tools were used to extract features from images.\n",
    "   - Among the five variables, four are features, and one is target class.\n",
    "   - The four features are continuous numbers that measure the characteristics of digital images of each banknote.\n",
    "      - `variance`: Measures the spread or distribution of pixel values within the banknote image.\n",
    "      - `skew`: Quantifies the asymmetry or distortion in the distribution of pixel intensity values, according to GeeksforGeeks.\n",
    "      - `curtosis`: Describes the sharpness of the peaks in the pixel intensity distribution.\n",
    "      - `entropy`: Describes the amount of information that must be coded for by a compression algorithm.\n",
    "   - The target class contains two values, 0 and 1, where 0 represents a genuine note, and 1 represents a fake note.\n",
    "   - The dataset contains a balanced ratio of both classes which is 55:45 (genuine: counterfeit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e234697-87a6-42de-931f-d48621c1ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/Kuntal-G/Machine-Learning/master/R-machine-learning/data/banknote-authentication.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609024c-3eae-4ad5-8cb8-b95b403b7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c21b4-5f4d-44e2-9212-c2111e722688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98702ef-bcd3-4a13-a7ee-fdfed75cb627",
   "metadata": {},
   "source": [
    "## <font color='blue'>Perform EDA</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553d33e0-67c2-485e-b035-da5a98260703",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Quick observation on the data types</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3765d0-0062-444d-a567-1781d853bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba464efe-ad92-42c0-a0c6-b236440133ce",
   "metadata": {},
   "source": [
    "- All the columns have data types of either `float` or `int`.\n",
    "   - There is no need to do any data conversion.\n",
    "- There are no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5f5fb0-b650-4ee4-a821-6be4c7c37466",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Descriptive statistics</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c75fd73-753b-4b15-9b30-17d985ebc8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35825f15-d194-434b-953c-a5bee392881f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "173faadc-fb2a-4a11-85de-f0610340f28f",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Basic plots</font>\n",
    "\n",
    "__Percentage of instances for each class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403618e-005c-4c8f-8af7-b4bbbd7f237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts().plot(kind=\"pie\", autopct='%1.1f%%');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b87a228-9ff7-438a-9955-369d869cafbe",
   "metadata": {},
   "source": [
    "__Pairplot__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325d8ac-0304-4322-b50d-7a6bfcf14930",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8cef93-2a2e-4b21-9834-dc73c87d8d87",
   "metadata": {},
   "source": [
    "__Observations__\n",
    "\n",
    "- `entropy` and `variance` have a slight linear correlation.\n",
    "- There is an inverse linear correlation between the `curtosis` and `skew`.\n",
    "- The values for `curtosis` and `entropy` are slightly higher for real banknotes, while the values for `skew` and `variance` are higher for the fake banknotes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7db1ec-e1d2-4a06-93ca-e3f0c255f00f",
   "metadata": {},
   "source": [
    "__Heatmap__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331af5c-9d51-47a1-bd9b-ccc35029813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22, 11));\n",
    "correlation_matrix = df.corr().round(3);\n",
    "sns.heatmap(correlation_matrix, cmap=\"YlGnBu\", annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995f8c8-1ec8-4730-aaed-ca1952db539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22, 11));\n",
    "sns.heatmap(correlation_matrix[(correlation_matrix >= 0.7) | (correlation_matrix <= -0.6)], \n",
    "            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
    "            annot=True, annot_kws={\"size\": 8}, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199425a2-093e-4a16-af4a-6dbd047e49fd",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Identify possible non-linear relationships</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e3128-3829-472d-8b89-054396973f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d3c42c-53d1-4c07-ba8c-63626cf35f84",
   "metadata": {},
   "source": [
    "__Observations__\n",
    "\n",
    "-  Out of all the combinations of variables, the scatter plot of `curtosis` vs `entropy` has the most significant overlap between classes.\n",
    "   - The overlapping of the data indicates that there is substantial ambiguity and similarity between classes based just on their `curtosi`s and `entropy` values, which implies that there is no distinct separation that allows for easy classification.\n",
    "   - ML algorithms would face significant challenges in accurately classifying banknotes based on these two variables.\n",
    "- `skew` vs `entropy` and `skew` vs `curtosis` also have relatively high overlap between classes.\n",
    "   - The overlapping feature also has some implications for the effectiveness of ML algorithms. \n",
    "- A large overlap of different classes will require more complex decision boundaries to determine the class of the banknote accurately.\n",
    "- __It is reasonable to predict that algorithms such as Logistic Regression and Linear Discriminant Analysis, which assume linear relationships between variables, may struggle with an accurate prediction with only two features.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87100bb-5b88-463b-9fe2-bc23e70e7354",
   "metadata": {},
   "source": [
    "__Analyzing 3D plots__\n",
    "\n",
    "- We extend our analysis by incorporating an additional feature in plots by doing three-feature scatter plots.\n",
    "- By including a new variable, our goal is to mitigate the issue of significant overlap observed in the two-feature scatter plot and improve the separability between the classes.\n",
    "- As the plots below show, the three-feature scatter plots exhibit a notable reduction in overlap among the different classes compared to the two-feature plots, suggesting the additional variable added to any of the two variable combinations provided additional discriminatory power, leading to clearer separation between genuine and counterfeit banknotes.\n",
    "- __The reduced overlap and improved separability in the three-feature scatter plots indicate that ML methods, including those that assume linear relationships among the variables, such as Logistic Regression and Linear Discriminant Analysis, are expected to perform better when using three features for classification.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdc4b3-d18f-44da-9e13-92b895b794e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_3d_plot(data, ax, labels):\n",
    "    # Plot the data, using Seaborn's palette for color differentiation\n",
    "    # Iterate through each class to plot separately for distinct colors\n",
    "    for class_label in data['class'].unique():\n",
    "        subset = data[data['class'] == class_label]\n",
    "        ax.scatter(subset[labels[0]], subset[labels[1]], subset[labels[2]], \n",
    "                   label=f'Class {class_label}',\n",
    "                   color=sns.color_palette(\"tab10\", n_colors=2)[int(class_label)],\n",
    "                   s=3\n",
    "                  ) # s for marker size\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(labels[0])\n",
    "    ax.set_ylabel(labels[1])\n",
    "    ax.set_zlabel(labels[2])\n",
    "    #ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8178c-3808-4cc1-ba16-77c5f3738c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels = [\n",
    "    ('variance', 'entropy', 'skew'),\n",
    "    ('variance', 'entropy', 'curtosis'),\n",
    "    ('entropy', 'skew', 'curtosis'),\n",
    "    ('skew', 'variance', 'curtosis', )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e3e553-0746-4e92-bec6-d354744ede97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 6), subplot_kw={'projection': '3d'})\n",
    "\n",
    "for ax, labels in zip(axes.flat, list_labels):\n",
    "    do_3d_plot(df, ax, labels)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa860ddf-67d4-4a3c-9d4c-c31720da0697",
   "metadata": {},
   "source": [
    "- The above observations were based on the visual analysis of the scatter plots.\n",
    "- Further quantitative analysis is necessary to confirm the extent of the visual analysis and its impact on classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46ff77-a7b3-4631-88ac-53605afba77d",
   "metadata": {},
   "source": [
    "#  <font color=\"red\">Data preparation</font>\n",
    "\n",
    "##  <font color=\"blue\"> Splitting the data into training and testing sets</font>\n",
    "- We split the data into training and testing sets. \n",
    "- We train the model with 80% of the samples and test with the remaining 20%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d6d511-2795-4b6c-be25-f3d5c5766d77",
   "metadata": {},
   "source": [
    "__Extract the train and test datasets as NumPy arrays__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a16a71-679b-4d22-8211-7a3fc393b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = list(df.columns)\n",
    "del feature_cols[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f656f27f-b3c6-42a5-9472-6c11815e7128",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c9cd8-7882-431b-bd09-ae5aa737fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = list(df.columns)[-1]\n",
    "label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f93ae-dbf6-4b58-9402-02cda89127bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[feature_cols].values, \n",
    "                                                    df[label_name].values, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71792068-9926-41bb-81c0-2a46f6e956fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2571853-0be0-48b2-9985-8a6021d01276",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e5ffb-1bca-4f1b-b4cf-a78be1b07753",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfbbf9-4fed-4111-8391-15f2b338d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b374d7-a932-4cf9-a9d1-a65301438d64",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Normailized the Data</font> <a class=\"anchor\" id=\"sec_tf_norm\"></a>\n",
    "\n",
    "- In general, variables may not be a similar scale. High values would gain more importance in any distance-based calculations. \n",
    "- It is good practice to normalize features that use different scales and ranges.\n",
    "   - The normalization process brings all variables to a similar scale, preventing certain variables from dominating others in later analysis and ensuring fair comparisons and interpretations.\n",
    "- Although the model might converge without feature normalization, it makes training more difficult, and it makes the resulting model dependent on the choice of units used in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5080b6-f78b-43b5-b960-3b949da1276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122a1b8-68de-47fb-80a8-d5cba2ca0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = X_train.mean(axis=0)\n",
    "train_std = X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1277bd-e81d-46a7-94a1-d9e77b5b9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138f810-069d-44f3-ae65-de3ba13f0d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364e4f3-36a7-4b3c-be31-8388547654ee",
   "metadata": {},
   "source": [
    "__Normalization of the train features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ee619-625f-4d4e-bd24-5d0ce2888cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94729c0a-2b7c-45e3-9da2-d1192edfea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e880315b-9f50-4501-9ded-b07ae065111b",
   "metadata": {},
   "source": [
    "__Normalization of the test features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df36d26-155b-4141-a935-8289e19f6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (X_test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42acd45-028c-41bc-8e78-e233d1d720b6",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Creating the ML model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56965881-aa98-43ac-afaf-540b8e6ec15f",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Set the hyperparameters</font>\n",
    "\n",
    "It is a good practice to declare the following parameters before creating the model for ease of change and understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa170e6-c30f-4567-be4a-d731cc18e6d6",
   "metadata": {},
   "source": [
    "__Dataset parameters__\n",
    "\n",
    "These parameters are defines by the dataset used:\n",
    "\n",
    "- number of features\n",
    "- number of classes to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bcc8d-3b6c-463d-a5be-3555f9243279",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(feature_cols)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199bec34-dab6-4479-bc5f-a44f0ef646bb",
   "metadata": {},
   "source": [
    "__Model parameters__\n",
    "\n",
    "- batch size\n",
    "- number of epochs\n",
    "- learning rate (optimizer steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08230641-70fa-4058-9507-e0efe5b20a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_epochs = 10\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9795e-6204-4830-9922-c6fe9ef8b67b",
   "metadata": {},
   "source": [
    "#### Device configuration: check for CUDA availability and set device accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f7656-416c-47e8-92f4-c3a4ad5826ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50db02-3696-4f86-b149-74baabeec6c4",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Building the PyTorch model</font>\n",
    "\n",
    "### <font color=\"green\"> Class to create a simple model with one linear layer\n",
    "\n",
    "- We define a neural network by subclassing `nn.Module`, and initialize the neural network layers in `__init__`.\n",
    "- Every `nn.Module` subclass implements the operations on input data in the `forward` method.\n",
    "   - The `__init()__`  method defines the layers and other components of a model.\n",
    "   - The `forward()` method is where the computation gets done.\n",
    "- The input layer has `num_features` nodes and the output layer `num_classes` nodes.\n",
    "- The most basic type of neural network layer is a linear or fully connected layer.\n",
    "   - This is a layer where every input influences every output of the layer to a degree specified by the layer’s weights.\n",
    "   - If a model has `m` inputs and `n` outputs, the weights will be an `m x n` matrix.\n",
    "- One of the most common places you will see linear layers is in classifier models, which will usually have one or more linear layers at the end, where the last layer will have `n` outputs, where `n` is the number of classes the classifier addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da86d9a-7cd5-467c-bf65-3388fe272bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e643a50-b6f7-45ff-9bbe-2534aab2e33e",
   "metadata": {},
   "source": [
    "Note that we do not have any activation function here because there is only one layer:\n",
    "- Activation functions make deep learning possible.\n",
    "   - Inserting non-linear activation functions between layers is what allows a deep learning model to simulate any function, rather than just linear ones.\n",
    "- __The model defined above can be seen as a single matrix multiplication.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4915d06-3ae5-461f-9791-c84401b262ec",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b360e-c33c-4724-b46f-58323a9a7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "model = LogisticRegression(num_features=input_size, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be31197-96e8-468e-abe3-33dd25cf0e2b",
   "metadata": {},
   "source": [
    "Move the model to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a97db7-4e2a-4671-93f3-9b51b03c9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba6e597-830a-48fd-8e39-ad4a4acda512",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Model Summary\n",
    "\n",
    "- The function `summary()` of `torchsummary` provides the architectural summary of the model in the same similar as in case of Keras’ model summary().\n",
    "- It shows the layer types, the resultant shape of the model, and the number of parameters available in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8459b08-40e9-4525-bc85-26db10da84d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(input_size, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077a5f1-762d-406f-8aa3-e4f93711eb95",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Print model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861aa7ad-0923-4fee-aa7b-4a45baba9863",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t Model information: \\n')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04be5b-dec4-4adf-a02c-99c56fa2004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t Layer information: \\n')\n",
    "print(model.linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840ee82-b2ef-42dc-bed1-37bb41cf47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t Model trainable parameters: \\n')\n",
    "model_dict = model.state_dict()\n",
    "for key in model_dict:\n",
    "    print(f\"{key}: \\n \\t {model_dict[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad06c9-38ac-4723-b56b-6f4460ac5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t Model parameters: \\n')\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d8ff34-57ee-40e2-b432-274319e96b38",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Basic testing of the model with arbitrary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2923ae0-cf24-4252-bd19-cc326a39bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[-0.6391558 ,  1.80557961, -0.18836535, -3.05096841],\n",
    "                  [ 0.82188925,  0.85239902, -0.59407847,  0.60345479],\n",
    "                  [-1.65703344, -1.63328321,  2.38386151, -0.34235536]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da5e98-4bbd-4190-9bfe-5dde46aec7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(x.to(device))\n",
    "    probas = F.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa7eeb-2782-477e-80d1-532a520cebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12068721-daf9-4ea1-9240-5bcc19c75ce9",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Defining a Dataset</font>\n",
    "\n",
    "- A dataset is represented by a regular Python class that inherits from the `Dataset` class.\n",
    "   - I can be seen as a kind of a Python list of tuples, each of which corresponding to one data point (features, label)\n",
    "- Unless the dataset is huge (cannot fit in memory), you don’t explictly need to define this class. We then use `TensorDataset` instead.\n",
    "- There are three components:\n",
    "   - `__init__(self)`\n",
    "   - `__get_item__(self, index)`\n",
    "   - `__len__(self)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6376d80-e7cf-43b4-96eb-bfd99709b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.features = torch.tensor(X, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.features[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09094819-2b05-40c7-8a08-f6ee815ae8c5",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Defining a DataLoader</font>\n",
    "\n",
    "- Very useful if we have a hude dataset.\n",
    "- We pass the dataset to our dataloader, and our `batch_size` hyperparameter as initialization arguments.\n",
    "- This creates an iterable data loader, so we can easily iterate over each batch using a loop.\n",
    "   - Behave like an __iterator__, so we can __loop over__ it and fetch a different __mini-batch__ every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a9d65-294d-4c70-ab48-8bb9b9d706d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_data(Xdata: np.array, \n",
    "                     ydata: np.array, \n",
    "                     batch_size: int, \n",
    "                     shuffle: bool=False) -> DataLoader:\n",
    "    \"\"\"\n",
    "    Take the NumPy arrays for the features and labels to\n",
    "    create a PyTorch DataLoader object. It also subdivide\n",
    "    the arrays into groups of size batch_size. \n",
    "    If shuffle is set to True (for the training set only),\n",
    "    the data will be shuffled. It allows for stable training \n",
    "    and faster convergence of our model parameters.\n",
    "    \"\"\"\n",
    "    dataset = MyDataset(Xdata, ydata)\n",
    "    dataloader = DataLoader(dataset=dataset, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=shuffle)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192f1c4-a457-498d-a6ba-840baf85d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = instantiate_data(X_train, y_train, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f8926-930c-4945-950a-31083608ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238283f-1d02-427e-ab52-e6489de69064",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = instantiate_data(X_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc16a0-ec59-4c54-a209-0a5e22406287",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">The training loop</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90a8f3-71f8-4f89-87fd-e17355b00a20",
   "metadata": {},
   "source": [
    "__Define the loss function__\n",
    "\n",
    "- We use the Cross-Entropy Loss that is primarily used for multi-label classification models.\n",
    "- It first applies softmax to the predictions and calculates the given target labels and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a202ec04-4ea6-4b75-ab5d-3494f3e4c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc0006a-5d3c-4d1a-b6f2-3d2d3c55e25d",
   "metadata": {},
   "source": [
    "__Define the optimizer__\n",
    "\n",
    "- We use the SGD optimizer that implements the stochastic gradient descent method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581766d-b3f3-4788-b6cf-81defa0d8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d13c2-c9ee-441e-9afa-e2359d7cbe53",
   "metadata": {},
   "source": [
    "__Feed train data into the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcaa2b1-4019-4128-9ff5-6a966c3abdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model = model.train()\n",
    "    for batch_idx, (features, class_labels) in enumerate(train_loader):\n",
    "        # Predict outputs\n",
    "        outputs = model(features.to(device))\n",
    "\n",
    "        # Compute the loss function\n",
    "        loss = loss_function(outputs, class_labels.to(device))\n",
    "\n",
    "        # Reset and calculate gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        ### LOGGING\n",
    "        print(f'Epoch: {epoch+1:03d}/{num_epochs:03d}'\n",
    "               f' | Batch {batch_idx+1:03d}/{len(train_loader):03d}'\n",
    "               f' | Loss: {loss:.4f}')\n",
    "    print(43*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d5821-7c8d-46b5-9e7d-02e72cac2acc",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Evaluating the results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d910ddbb-798f-47ab-8aab-e2dba4aa4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "    \"\"\"\n",
    "    Compute the percentage of correct classification.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    pred_values = list()\n",
    "    true_values = list()\n",
    "\n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "\n",
    "    for idx, (features, class_labels) in enumerate(dataloader):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(features.to(device))\n",
    "\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        pred_values = np.append(pred_values, pred.cpu().numpy())\n",
    "        true_values = np.append(true_values, class_labels)\n",
    "\n",
    "        compare = class_labels.to(device) == pred\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return correct / total_examples, true_values, pred_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb64f5d-72e6-4ee6-9042-568e105ff0f2",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Evaluation on the train dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27538c8d-61bc-47b0-8289-b6aab4aa16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, train_true, train_pred = compute_accuracy(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ecf35-4745-43a8-8ea8-14f71cba5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train accuracy: {train_acc*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dedfa00-3246-43e7-aa55-564a33dd5653",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Evaluation on the test dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26992a7-23ba-46c5-b7b2-4ec2689ce9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, test_true, test_pred = compute_accuracy(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18ba27-9389-426a-a289-35516755c0ec",
   "metadata": {},
   "source": [
    "__Accuracy__\n",
    "\n",
    "- Measures the proportion of correct predictions in the total sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd84261-ffab-4357-8beb-19a08edaacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test accuracy: {test_acc*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb51a7c-7713-4d85-9567-50cef70c4e23",
   "metadata": {},
   "source": [
    "__Precision score__\n",
    "\n",
    "- Measures how many of the items identified as positive are actually positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf5250-c5e1-4c65-9997-5f7f6f355d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(test_true, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24abba9d-a91a-4350-aa73-9c4b5a5095cf",
   "metadata": {},
   "source": [
    "__Recall score__\n",
    "\n",
    "- Measures how many of the actual positive cases were identified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58445ad-86d9-4ffe-8da2-ca992dd04857",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(test_true, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb0b556-8ec4-4ea7-a339-4deedddde81a",
   "metadata": {},
   "source": [
    "__F1 score__\n",
    "\n",
    "- Harmonic mean of Precision and Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040de743-d3f1-4d90-b8c7-67ea5c28608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(test_true, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c8172-02f6-4fd6-9188-812b58e3da75",
   "metadata": {},
   "source": [
    "__ROC-AUC__\n",
    "\n",
    "- The area under the Receiver Operating Characteristic curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9ed50-2859-4982-bb42-cac046f51e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(test_true, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd5ebe-7403-4286-85bd-a8f28b658303",
   "metadata": {},
   "source": [
    "__Generate the confusion matrix__\n",
    "\n",
    "- A table used to describe the performance of a classification model.\n",
    "\n",
    "| | Predicted Class A | Predicted Class B |\n",
    "|---|---|---|\n",
    "| **Actual Class A** | True Positive (TP) | False Negative (FN) |\n",
    "| **Actual Class B** | False Positive (FP) | True Negative (TN) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ea54b5-ffb5-46b7-a3e2-a36341b0024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(test_true, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c00d75-9554-4b2b-9be0-4c34a135f0af",
   "metadata": {},
   "source": [
    "__ROC curve__\n",
    "\n",
    "- Visualizes how well the model distinguishes between two classes (e.g., positive and negative) by plotting the true positive rate against the false positive rate at different threshold settings.\n",
    "   - True Positive Rate (TPR): Proportion of actual positive cases that are correctly classified as positive.\n",
    "   - False Positive Rate (FPR): Proportion of actual negative cases that are incorrectly classified as positive.\n",
    "- A curve closer to the top-left corner (higher TPR, lower FPR) indicates better performance, meaning the model is more accurate at distinguishing between the two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223f13e0-29b4-4f2a-a93b-138a61398b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_true, test_pred)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
