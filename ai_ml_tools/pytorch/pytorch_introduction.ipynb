{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71bce70-9dc3-448b-9f9a-8896e83b6d09",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Course Series</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h1><font color=\"red\">Introduction to PyTorch</font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df4d162-122d-47d2-bdf4-45895a93bc6b",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Objectives</font>\n",
    "\n",
    "The goal of this presentation is introduce the basic concepts of PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec71f2-3cbc-42eb-a080-3b987b707390",
   "metadata": {},
   "source": [
    "# <font color=\"red\">References</font>\n",
    "\n",
    "- [PyTorch](https://pytorch.org/)\n",
    "- [What is PyTotch?](https://www.nvidia.com/en-us/glossary/pytorch/) from NVIDIA.\n",
    "- [What is PyTorch](https://www.ibm.com/think/topics/pytorch) by IBM\n",
    "- [Efficiently Building PyTorch Models: A Step-by-Step Guide](https://myscale.com/blog/efficient-pytorch-model-building-step-by-step-guide/) from myscale.com\n",
    "- [The Good and Bad of PyTorch Machine Learning Library](https://www.altexsoft.com/blog/pytorch-library/) from altexsoft.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0239364b-112d-4dae-9454-9e32a93e3c23",
   "metadata": {},
   "source": [
    "# <font color=\"red\">What is PyTorch?</font>\n",
    "\n",
    "- Open-source deep learning framework.\n",
    "- Started of as a more flexible alternative to TensorFlow.\n",
    "- Provide a flexible and efficient platform for building and training neural networks.\n",
    "   - It has a dynamic computational graph that allows users to modify the architecture during runtime, making debugging and experimentation easier.\n",
    "- Written in Python and integrated with popular Python libraries like NumPy (for scientific computing), SciPy, and Cython (for compiling Python to C for better performance). \n",
    "- Support CPU, GPU, and parallel processing, as well as distributed training.\n",
    "   - PyTorch’s intuitive API and support for GPU acceleration make it ideal for building efficient feedforward networks, particularly in tasks such as image classification and digit recognition.\n",
    "- Excellent tool to learn and use for creating machnine learning models.\n",
    "- Rely on tensors that are a specialized data structure that are very similar to arrays and matrices.\n",
    "   - Tensors are like NumPy’s ndarrays, except that tensors can run on GPUs or other specialized hardware to accelerate computing.\n",
    "   - They are used to encode the inputs and outputs of a model, as well as the model’s parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f9f81-2937-4d2b-b501-98faaf162eb8",
   "metadata": {},
   "source": [
    "![fig_pytorch](https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/pytorch/img-1.png)\n",
    "Image reference: [https://pytorch.org/features/](https://pytorch.org/features/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5865fe-c542-470d-b862-7dc58f6956fb",
   "metadata": {},
   "source": [
    "# <font color=\"red\">How PyTorch works</font>\n",
    "\n",
    "The core components of PyTorch are:\n",
    "\n",
    "- __Tensors__\n",
    "   - A core PyTorch data type, similar to a multidimensional array, used to store and manipulate the inputs and outputs of a model, as well as the model’s parameters.\n",
    "   - They are similar to NumPy’s ndarrays, except that tensors can run on GPUs to accelerate computing.\n",
    "- __Graphs__\n",
    "   - Graphs are data structures consisting of connected nodes (called vertices) and edges.\n",
    "   - Neural Networks are represented as a graph structure of computations. They transform input data by applying a collection of nested functions to input parameters.\n",
    "   - The goal of deep learning is to optimize these parameters (weights and biases) by computing their partial derivatives (gradients) with respect to a loss metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f64c95-e3c9-44db-9198-ccb78bbc24a2",
   "metadata": {},
   "source": [
    "# <font color=\"red\">PyTorch main modules</font>\n",
    "\n",
    "- PyTorch uses modules as the building blocks of deep learning models, which allows for the quick and straightforward construction of neural networks without the tedious work of manually coding each algorithm.\n",
    "- There are three primary classes of modules used to build and optimize deep learning models in PyTorch:\n",
    "   - __nn modules__ are deployed as the layers of a neural network.\n",
    "      - The `torch.nn` package contains a large library of modules that perform common operations like convolutions, pooling and regression.\n",
    "   - The __autograd module__ provides a simple way to automatically compute gradients, used to optimize model parameters via gradient descent, for any function operated within a neural network.\n",
    "      - The `loss.backward()` function is used to compute the gradients.\n",
    "      - We need to to zero out gradients after each update: `t.grad.zero_()`.\n",
    "   - __Optim modules__ apply optimization algorithms to those gradients.\n",
    "      - The `torch.optim` package provides modules for various optimization methods, like stochastic gradient descent (SGD) or root mean square propagation (RMSprop), to suit specific optimization needs.\n",
    "      - An optimizer takes the parameters we want to update, the learning rate we want to use (and possibly many other hyper-parameters as well!) and performs the updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0b9ad8-ca26-418a-b051-7c24c787296d",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Steps for building a PyTorch model workflow</font>\n",
    "\n",
    "Implementating the following steps into building your first PyTorch model sets a solid foundation for creating sophisticated neural networks tailored to diverse applications.\n",
    "\n",
    "1. Define your model architecture\n",
    "   - Set the numbers of nodes in the input and output layers. The two parameters are the sizes of the features and the labels.\n",
    "   - Determine the number of layers and the function (linear, convolutional, or recurrent) associated to each layers.\n",
    "2. Data preprocessing to prepare the data\n",
    "   - Splitting into training and validation sets\n",
    "   - Normalizing the data (if needed)\n",
    "   - Creating data loaders\n",
    "3. Train your model\n",
    "   - Define the loss function\n",
    "   - Define the optimizer\n",
    "   - Write a loop to:\n",
    "      - Feed batches of data through your model\n",
    "      - Compute loss functions\n",
    "      - Optimize parameters with backpropagation\n",
    "          - Compute the gradients\n",
    "          - Update the weights\n",
    "      - Monitor performance metrics iteratively.\n",
    "4. Evaluate the model performance\n",
    "   - Test the model using unseen data and evaluate the performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242d89f-d9eb-4e8e-b05f-7a28aac277a3",
   "metadata": {},
   "source": [
    "![fig_workflow](https://www.scaler.com/topics/images/this-detailed-resource.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276aeca8-dff9-4cdf-8b2d-b61ad82c7ce9",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Basics of PyTorch model</font>\n",
    "\n",
    "A PyTorch model (represented by a regular Python class) is constructed using two fundamental components that play crucial roles in defining and executing the neural network: \n",
    "\n",
    "- __init()__ Method:\n",
    "   - Serves as the constructor function for your model.\n",
    "   - Where you define all the layers that will be used in your neural network architecture. That is needed to establish the structure of the model and initialize parameters such as weights and biases. \n",
    "- __forward()__ Method:\n",
    "   - Defines the actual computation that takes place when input data passes through each layer of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf8da3-2e88-4493-adc6-8abd7777d541",
   "metadata": {},
   "source": [
    "Once a `model` is defined, we can access it properties:\n",
    "\n",
    "- `model.state_dict()`: Dictionary of trainable parameters with their current values.\n",
    "- `model.parameters()`: List of all trainable parameters in the model.\n",
    "- `model.train()` or `model.eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1b8fe-7333-4491-ab85-f058c9bb1088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e49cf83-9100-4689-9eb1-e968217783f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
