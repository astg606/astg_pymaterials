{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h1><font color=\"red\">Image Classification with Scikit-Learn</font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Links\n",
    "\n",
    "- <a href=\"https://www.dataquest.io/blog/sci-kit-learn-tutorial/\">Scikit-learn Tutorial: Machine Learning in Python</a>\n",
    "- <a href=\"https://debuggercafe.com/image-classification-with-mnist-dataset/\">Image Classification with MNIST Dataset</a>\n",
    "- <a href=\"https://davidburn.github.io/notebooks/mnist-numbers/MNIST%20Handwrititten%20numbers/\">MNIST handwritten number identification</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    print(\"Running in Google Colab\")\n",
    "except:\n",
    "    print(\"Not running in Google Colab\")\n",
    "else:\n",
    "    print(\"Installing modules in Google Colab\")\n",
    "    !pip install seaborn\n",
    "    !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Numpy version:        {np.__version__}\")\n",
    "print(f\"Pandas version:       {pd.__version__}\")\n",
    "print(f\"Seaborn version:      {sns.__version__}\")\n",
    "print(f\"Scikit-Learn version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\"> MNIST Dataset</font>\n",
    "\n",
    "- The <A HREF=\"https://en.wikipedia.org/wiki/MNIST_database\"> MNIST database</A> (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.\n",
    "- The database is also widely used for training and testing in the field of machine learning.\n",
    "- The dataset we will be using contains 70000 images of handwritten digits among which 10000 are reserved for testing.\n",
    "- This dataset is  suitable for anyone who wants to get started with image classification using Scikit-Learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Obtain the Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist_data = fetch_openml('mnist_784', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnist_data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Features of the Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keys: \", mnist_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that the `data` and `target` already separated.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of Data: {mnist_data.data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Datatype of Data: {type(mnist_data.data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of the Target Data: {mnist_data.target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Datatype of Target Data: {type(mnist_data.target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Feature Names: {mnist_data.feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Url: {mnist_data.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the feature and target arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data, np_target = mnist_data['data'], mnist_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' Shape of data:   {np_data.shape}')\n",
    "print(f' Shape of target: {np_target.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(np_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(np_data.values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Datatype of the target values: {np_target.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np_target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a few values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np_target[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the labels from string to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_target = np_target.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np_target[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of unique labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_target.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np_target.value_counts().sort_values(ascending=False)\n",
    "percent = (np_target.value_counts()/np_target.count()).sort_values(ascending=False)*100\n",
    "percent_data = pd.concat([total, percent], axis=1, \n",
    "                         keys=['Total', 'Percent'])\n",
    "percent_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"> \n",
    "There are 70000 numbers, each stored as an array of 784 numbers depicting the opacity of each pixel, it can be displayed by reshaping the data into a 28x28 array and plotting using matplotlib. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_index = 15657\n",
    "some_digit = np_data.values[some_index]\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_digit_image, \n",
    "           cmap = matplotlib.cm.binary, \n",
    "           interpolation='nearest')\n",
    "plt.axis=('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us find the target for row `some_index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_target[some_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def display_digits(X, y):\n",
    "    \"\"\"\n",
    "      Given an array of images of digits X and \n",
    "      the corresponding values of the digit y,\n",
    "      this function plots 96 unique randomly selected images \n",
    "      and their values.\n",
    "    \"\"\"\n",
    "    # Figure size (width, height) in inches\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Adjust the subplots \n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, \n",
    "                        hspace=0.05, wspace=0.05)\n",
    "\n",
    "    num_images = X.shape[0]\n",
    "    \n",
    "    num_selected_images = 96\n",
    "    row_indices = random.sample(range(num_images), num_selected_images)\n",
    "    \n",
    "    i = 0\n",
    "    for idx in row_indices:\n",
    "        # Initialize the subplots: \n",
    "        # Add a subplot in the grid of 8 by 12, at the i+1-th position\n",
    "        ax = fig.add_subplot(8, 12, i + 1, xticks=[], yticks=[])\n",
    "        \n",
    "        # Display an image at the i-th position\n",
    "        ax.imshow(X[idx].reshape(28, 28), cmap=plt.cm.binary, \n",
    "                  interpolation='nearest')\n",
    "       \n",
    "        # label the image with the target value\n",
    "        ax.text(0, 7, str(y[idx]))\n",
    "        i += 1\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_digits(np_data.values, np_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Model Selection Process</font>\n",
    "\n",
    "![fig_skl](https://miro.medium.com/max/1400/1*LixatBxkewppAhv1Mm5H2w.jpeg)\n",
    "Image Source: Christophe Bourguignat\n",
    "\n",
    "- A Machine Learning algorithm needs to be trained on a set of data to learn the relationships between different features and how these features affect the target variable. \n",
    "- We need to divide the entire data set into two sets:\n",
    "    + Training set on which we are going to train our algorithm to build a model. \n",
    "    + Testing set on which we will test our model to see how accurate its predictions are.\n",
    "    \n",
    "Before we create the two sets, we need to identify the algorithm we will use for our model.\n",
    "We can use the `machine_learning_map` map (shown at the top of this page) as a cheat sheet to shortlist the algorithms that we can try out to build our prediction model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Separating the Training and Testing Set</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first 60000 (among the 70000) images are used for training.\n",
    "- The remaining 10000 images are used for validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 60000\n",
    "\n",
    "X_train = np_data.values[:num_train]\n",
    "X_test  = np_data.values[num_train:]\n",
    "y_train = np_target[:num_train]\n",
    "y_test  = np_target[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' Train Data:  {X_train.shape}')\n",
    "print(f' Test Data:   {X_test.shape}')\n",
    "print(f' Train label: {y_train.shape}')\n",
    "print(f' Test Label:  {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle the training set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = X_train.shape[0]\n",
    "shuffle_index = np.random.permutation(nn)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\"> ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=\"blue\">Binary classifier</font>\n",
    "\n",
    "- Binary classification means there are two classes to work with that relate to one another as `true` and `false`.\n",
    "- Here, we want to identify a single digit: looking at `9`s.\n",
    "- The classification will tell us if we have a `9` (true) or not (false)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the target arrays as boolean arrays:** true if 9 otherwise false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_9 = (y_train == 9)\n",
    "y_test_9 = (y_test == 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and train the model\n",
    "\n",
    "- We use the SGDClassifier that applies regularized linear model with SGD (Stochastic Gradient Descent) learning to build an estimator.\n",
    "- It works by progressively changing model parameters in the direction of a loss function's sharpest gradient. \n",
    "- The method helps building an estimator for classification and regression problems.\n",
    "\n",
    "```python\n",
    "SGDClassifier(loss='hinge', *, penalty='l2', \n",
    "              alpha=0.0001, l1_ratio=0.15, fit_intercept=True, \n",
    "              max_iter=1000, tol=0.001, shuffle=True, \n",
    "              verbose=0, epsilon=0.1, n_jobs=None, random_state=None, \n",
    "              learning_rate='optimal', eta0=0.0, power_t=0.5, \n",
    "              early_stopping=False, validation_fraction=0.1, \n",
    "              n_iter_no_change=5, class_weight=None, warm_start=False, \n",
    "              average=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf =SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.fit(X_train, y_train_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make an initial prediction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_index = 15657\n",
    "some_digit = np_data.values[some_index]\n",
    "print(np_target[some_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit_predict = sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measuring accuracy using cross validation**\n",
    "\n",
    "- The `stratifiedKfold` class performs stratified sampling to produce folds that contain a representative ratio of each class. \n",
    "- At each iteration the code creates a clone of the classifier, trains that clone on the training fold and then makes predictions on the test fold. \n",
    "- It then counts the number of correct predictions and outputs the ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 3\n",
    "skfolds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "kfold_scores = list()\n",
    "idx = 0\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_9):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_9[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_9[test_index]\n",
    "    \n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    scr = n_correct/len(y_pred)\n",
    "    kfold_scores.append(scr)\n",
    "    print(f\"Test: {idx} -- Score: {scr}\")\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{n_splits}-fold average score: {np.mean(np.array(kfold_scores))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = cross_val_score(sgd_clf, X_train, y_train_9, \n",
    "                             cv=3, \n",
    "                             scoring='accuracy', \n",
    "                             verbose=1)\n",
    "\n",
    "print(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn cross_val_score in action returning the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (sum(np_target==9)/len(np_target))*100\n",
    "print(f'{np.max(validation)*100}% accuracy might not as impressive as it sounds \\n where there are {accuracy :.2f}% of 9s in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix**\n",
    "\n",
    "- A confusion matrix is a tabular summary of the number of correct and incorrect predictions made by a classifier. \n",
    "- It can be used to evaluate the performance of a classification model through the calculation of performance metrics like accuracy, precision, recall, and F1-score.\n",
    "- The confusion matrix is a much better way to evaluate the performance of a classifier, especially when there is a skewed dataset as we have here with only 10% of the dataset being the target.\n",
    "- Each row represents a class, each column a prediction:\n",
    "   * The first row is negative cases (non-9s) with the top left containing all the correctly classified non-9s (True Negatives), the top right the 9s incorrectly classified as non-9s (False-Positves).\n",
    "   * The second row represents the positive class, 9s in this case, bottom left contains the 9s incorrectly classified as non-9s (False Negatives), the bottom right containing the correctly classified 9s (True Positives)\n",
    "\n",
    "\n",
    "|     | Actual |      |\n",
    "| --- |:---   |:--- |\n",
    "| **Prediction** | True Positive  | False Positive |\n",
    "|                | False Negative | True Negative |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need a set of predictions to compare to the actual targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_9, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = metrics.confusion_matrix(y_train_9, y_train_pred)\n",
    "\n",
    "print(f\"Confusion Matrix: \\n{cf_matrix}\")\n",
    "print(f\"\\n Number of images: {np.sum(cf_matrix)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_train_9, y_train_pred, \n",
    "                              labels=sgd_clf.classes_)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                      display_labels=sgd_clf.classes_)\n",
    "disp.plot() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision/Recall\n",
    "- Precision-Recall is a useful measure of success of prediction when the classes are very imbalanced.\n",
    "- Precision measures the number of true positives (correctly classified 9s) as a ratio of the total samples classified as a 9: $\\frac{T_P}{T_P + F_P}$\n",
    "- Recall measures the number of true positives as a ratio of the total number of positives: $\\frac{T_P}{T_P + F_N}$.\n",
    "- The precision-recall curve shows the tradeoff between precision and recall for different threshold. \n",
    "  - A system with high recall but low precision returns many results, but most of its predicted labels are incorrect when compared to the training labels. \n",
    "  - A system with high precision but low recall is just the opposite, returning very few results, but most of its predicted labels are correct when compared to the training labels. \n",
    "  - An ideal system with high precision and high recall will return many results, with all results labeled correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_9, cv=3, method='decision_function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(y_train_9, y_scores)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title('Precision and recall vs decision threshold')\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.ylim([0,1])\n",
    "\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Models with the entire dataset</font>\n",
    "\n",
    "- We will use the Stochastic Gradient Descent classifier (SGD). \n",
    "- Scikit-Learn’s SGDClassifier is a good starting point for linear classifiers. \n",
    "- Using the loss parameter we will see how Support Vector Machine (Linear SVM) and Logistic Regression perform for the same dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Linear Support Vector Machine (SVM)</font>\n",
    "- SVMs are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "- We use linear SVM with stochastic gradient descent (SGD) learning.\n",
    "    - The gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule.\n",
    "    - To use the Linear SVM Classifier, we need to set the loss parameter to `hinge`.\n",
    "\n",
    "```python\n",
    "LinearSVC(penalty='l2', loss='squared_hinge', *, dual='auto', \n",
    "          tol=0.0001, C=1.0, multi_class='ovr', \n",
    "          fit_intercept=True, intercept_scaling=1, \n",
    "          class_weight=None, verbose=0, random_state=None, \n",
    "          max_iter=1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd_clf = SGDClassifier(loss='hinge', random_state=42)\n",
    "svm_clf = LinearSVC(loss='hinge', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before testing the model, it is a good practice to first see the cross-validation scores on the training data. \n",
    "- That you will give you a very good projection of how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = cross_val_score(svm_clf, X_train, y_train, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = np.min(valid)*100\n",
    "max_val = np.max(valid)*100\n",
    "print(f'For three-fold Cross-Validation you are getting around: {min_val}%-{max_val}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the actual test scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreSVM = svm_clf.score(X_test, y_test)\n",
    "print(\"Test score of the Linear SVM: \", scoreSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = svm_clf.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_predict, \n",
    "                              labels=svm_clf.classes_)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                      display_labels=svm_clf.classes_)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Logistic Regression</font>\n",
    "\n",
    "```python\n",
    "LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, \n",
    "                   C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                   class_weight=None, random_state=None, \n",
    "                   solver='lbfgs', max_iter=100, multi_class='deprecated', \n",
    "                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd_clf = SGDClassifier(loss='log_loss', random_state=42)\n",
    "lr_clf = LogisticRegression(random_state=42)\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(lr_clf, X_train, y_train, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_lr = lr_clf.score(X_test, y_test)\n",
    "print(f\"Test score of the Logistic Regression: {score_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lr_clf.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_predict, \n",
    "                              labels=lr_clf.classes_)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                      display_labels=lr_clf.classes_)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Random Forest Classifier</font>\n",
    "\n",
    "- Random forests is a supervised learning algorithm. \n",
    "- A forest is comprised of trees. \n",
    "- It is said that the more trees it has, the more robust a forest is. \n",
    "- Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting. \n",
    "- It also provides a pretty good indicator of the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 500\n",
    "forest = RandomForestClassifier(n_estimators = n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_output = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy on the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Random Forest with n_estimators = {n_estimators}\")\n",
    "print(accuracy_score(y_test, forest_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display few true images against predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_digits(X_test, forest_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, forest_output, \n",
    "                              labels=forest.classes_)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                      display_labels=forest.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Gradient Boosting Classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, \n",
    "                                 max_depth=1, random_state=0).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_output = clf.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy on the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Gradient Boosting Accuracy: {accuracy_score(y_test, gbc_output)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display few true images against predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_digits(X_test, gbc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, gbc_output, \n",
    "                              labels=clf.classes_)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                      display_labels=clf.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">MLP Classifier: Neural Network</font>\n",
    "\n",
    "- The Multi-layer Perceptron (MLP) classifier relies on an underlying Neural Network to perform the task of classification.\n",
    "- MLP trains on two arrays:\n",
    "   - array `X` of size (`n_samples`, `n_features`), which holds the training samples represented as floating point feature vectors; and\n",
    "   - array `y` of size (`n_samples`,), which holds the target values (class labels) for the training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "MLPClassifier(hidden_layer_sizes=(100,), activation='relu',  \n",
    "              solver='adam', alpha=0.0001, batch_size='auto', \n",
    "              learning_rate='constant', learning_rate_init=0.001, \n",
    "              power_t=0.5, max_iter=200, shuffle=True, random_state=None, \n",
    "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "              nesterovs_momentum=True, early_stopping=False, \n",
    "              validation_fraction=0.1, beta_1=0.9, beta_2=0.999, \n",
    "              epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
    "```\n",
    "\n",
    "Here `hidden_layer_sizes=(100,)` means one input layer, one hidden layer with 100 nodes, one output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a range of values for:\n",
    "\n",
    "- `alpha`: Strength of the L2 regularization term. The L2 regularization term is divided by the sample size when added to the loss.\n",
    "- `max_iter`: Maximum number of iterations.\n",
    "\n",
    "to run the model. We access how these parameters affect the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "i = 0\n",
    "df = pd.DataFrame(columns = ['alpha','max_iter','train_acc','test_acc','train_time'])\n",
    "for a in [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]:\n",
    "    for mi in [10, 100, 200, 500, 1000, 2000]:\n",
    "        st = time()\n",
    "        mlp = MLPClassifier(alpha=a, max_iter=mi)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        end = time() - st\n",
    "        \n",
    "        acc_tr = accuracy_score(y_train, mlp.predict(X_train)) # Train Accuracy\n",
    "        acc = accuracy_score(y_test, mlp.predict(X_test)) # Test Accuracy\n",
    "        df.loc[i] = [a, mi, acc_tr, acc, end]\n",
    "        print(f\"| {i:2d} | {a:7.5f} | {mi:4d} | {acc_tr:5.4f} | {acc:5.4f} | {end:7.4f} |\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural networks with two hidden layers\n",
    "\n",
    "We vary the number of nodes in hidden layers and determine the train and test accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [25, 50, 75, 100, 150, 200, 250, 300]\n",
    "N = len(layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test = list()\n",
    "acc_train = list()\n",
    "timelog = list()\n",
    "for l in layer_sizes:\n",
    "    beg_time = time()\n",
    "    mlp = MLPClassifier(alpha=0.0001, max_iter=10, \n",
    "                        hidden_layer_sizes=(l,l),\n",
    "                        activation='relu')\n",
    "    mlp.fit(X_train, y_train)\n",
    "    elapsed_time = time() - beg_time\n",
    "        \n",
    "    a_train = accuracy_score(y_train, mlp.predict(X_train))\n",
    "    a_test = accuracy_score(y_test, mlp.predict(X_test))\n",
    "\n",
    "    acc_train.append(a_train)\n",
    "    acc_test.append(a_test)\n",
    "    timelog.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = np.arange(N)\n",
    "acc_test = np.array(acc_test)\n",
    "acc_train = np.array(acc_train)\n",
    "acc_diff = acc_train - acc_test\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax1.plot(l2, acc_test, color=\"red\", label=\"Testing Accuracy\")\n",
    "ax1.plot(l2, acc_train, color=\"green\", label=\"Training Accuracy\")\n",
    "ax1.set_xticks(l2, layer_sizes)\n",
    "ax1.set_xlabel(\"Hidden Layer Nodes\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.grid()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(l2, acc_diff, 'b:', label='Diff')\n",
    "ax2.set_ylabel('Difference of the two accuracies')\n",
    "#ax2.grid()\n",
    "\n",
    "#plt.grid(axis='both')\n",
    "fig.legend(loc=\"lower right\")\n",
    "plt.title('Accuracy versus Nodes in the Hidden Layer for MLPClassifier', fontsize=12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
