{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h1><font color=\"red\">Regression with Scikit-Learn</font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Objective</font>\n",
    "\n",
    "Use a dataset of home sales in a city to:\n",
    "- Preprocess the data and perform EDA.\n",
    "- Build a predictive regression model to estimate housing prices based on various features of the houses.\n",
    "- Perform the k-fold cross validation on various models to identify the one with the best score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Requirements\n",
    "\n",
    "- NumPy\n",
    "- scipy\n",
    "- matplotlib\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    print(\"Running in Google Colab\")\n",
    "except:\n",
    "    print(\"Not running in Google Colab\")\n",
    "else:\n",
    "    print(\"Installing modules in Google Colab\")\n",
    "    !pip install seaborn\n",
    "    !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from warnings import simplefilter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Numpy version:        {np.__version__}\")\n",
    "print(f\"Pandas version:       {pd.__version__}\")\n",
    "print(f\"Seaborn version:      {sns.__version__}\")\n",
    "print(f\"Scikit-Learn version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">City housing dataset</font>\n",
    "\n",
    "- Contains information about different aspects of residential homes in Ames, Iowa.\n",
    "- There are 1460 observations and 79 feature variables in this dataset.\n",
    "- [Information on the dataset can be done here.](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data).\n",
    "\n",
    "We want to predict the value of prices of the house using the given features. \n",
    "\n",
    "__We use this particular dataset in our EDA presentation.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Obtain the Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_url = \"https://raw.githubusercontent.com/astg606/py_materials/refs/heads/master/machine_learning/data/housing_data.csv\"\n",
    "\n",
    "ames_df = pd.read_csv(ames_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Features of the dataset and first data cleaning</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The target is the `SalePrice` represented in the last column\n",
    "- 37 columns have numerical values\n",
    "- 43 columns have `object` as data type. Are we going to use them for our analysis?\n",
    "- There are many missing values. How are we going to treat them?\n",
    "- From the data, the following columns have far fewer quantities and may not not be relevant for the model we want to build:\n",
    "   - `MiscFeature` (54)\n",
    "   - `Fence` (281)\n",
    "   - `PoolQC` (7)\n",
    "   - `Alley` (91) \n",
    "   \n",
    "We can drop the four columns with a lot of missing values. We also drop the `Id` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = ['Id', 'MiscFeature', 'Fence', 'PoolQC', 'Alley']\n",
    "ames_df.drop(dropped_cols, axis=1, inplace=True)\n",
    "ames_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To facilitate the analysis, we are only going to consider columns with numerical values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df_num = ames_df.select_dtypes(include=['float64', 'int64'])\n",
    "ames_df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(ames_df_num.columns)\n",
    "feature_names.pop(-1)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Exploratory Data Analysis</font>\n",
    "\n",
    "- Important step before training the model. \n",
    "- We use statistical analysis and visualizations to understand the relationship of the target variable with other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Obtain basic statistics on the data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df_num.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The average sale price of a house in our dataset is close to $\\$180,921$, with most of the values falling within the $\\$129,975$ to $\\$214,000$ range.\n",
    "- The fact the sale price standard deviation is $\\$79442$ indicates a large spread of the sale price and the exisitence of outliers.\n",
    "- There might be many mixing values in `LotFrontage` (Linear feet of street connected to property). Do we need to keep this column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Check Missing Values</font>\n",
    "It is a good practice to see if there are any missing values in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of missing values for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df_num.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also determine the perecentage of missing values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = ames_df_num.isnull().sum().sort_values(ascending=False)\n",
    "percent = (ames_df_num.isnull().sum()/ames_df_num.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, \n",
    "                         keys=['Total', 'Percent'])\n",
    "missing_data.head(ames_df_num.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are we going to do with the missing values in?\n",
    "- `LotFrontage` (259): Linear feet of street connected to property\n",
    "- `GarageYrBlt` (81): Year garage was built\n",
    "- `MasVnrArea` (8): Masonry veneer area in square feet\n",
    "\n",
    "**We choose to drop the rows with missing values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df_nonan = ames_df_num.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df_nonan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Distribution of the target variable<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6));\n",
    "sns.distplot(ames_df_nonan['SalePrice']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can see that the values of `SalePrice` are skewed to the left and have some outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Heatmap: two-dimensional graphical representation</font>\n",
    "- Represent the individual values that are contained in a matrix as colors.\n",
    "- Create a correlation matrix that measures the linear relationships between the variables.\n",
    "- We want to identify strong linear correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__You may choose to display only correlations that verify specific conditions:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22, 11));\n",
    "correlation_matrix = ames_df_nonan.corr().round(2);\n",
    "sns.heatmap(correlation_matrix[(correlation_matrix >= 0.7) | \n",
    "                               (correlation_matrix <= -0.7)], \n",
    "            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
    "            annot=True, annot_kws={\"size\": 7}, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **OverallQual** and **GrLivArea** have a strong positive correlation with **SalePrice** (0.8 and 0.71 respectively).\n",
    "- The features **GrLivArea** & **TotRmsAbvGrd**, **GarageCars** & **GarageArea** and **TotalBsmtSF** & **1stFlrSF** have a correlation of at least 0.7. These feature pairs are strongly correlated to each other. This can affect the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_feature_names = ['OverallQual', 'GrLivArea', 'TotRmsAbvGrd', \n",
    "                        'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF']\n",
    "fig,axs= plt.subplots(4, 2, figsize=(20, 30))\n",
    "\n",
    "# adjust horizontal space between plots \n",
    "fig.subplots_adjust(hspace=0.6)\n",
    "\n",
    "# We need to flatten the axes for iterating over them. Here the axes in the dimension [12, 3] is transformed to a vector consisting of 12*3 = 36 values.\n",
    "for i, ax in zip(subset_feature_names, axs.flatten()):\n",
    "    sns.scatterplot(x=i, y='SalePrice', hue='SalePrice',data=ames_df_nonan, ax=ax, palette='viridis_r')\n",
    "    plt.xlabel(i,fontsize=12)\n",
    "    plt.ylabel('SalePrice',fontsize=12)\n",
    "\n",
    "    # ax.set_yticks(np.arange(0,900001,100000))\n",
    "    ax.set_title(f'SalePrice - {i}', fontweight='bold',size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The sale prices increase as the value of `GrLivArea` increases linearly. - There are few outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above observations we will plot an `lmplot` between **GrLivArea** and **SalePrice** to see the relationship between the two more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'GrLivArea', y = 'SalePrice', data = ames_df_nonan);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Model selection process</font>\n",
    "\n",
    "- A ML algorithm needs to be trained on a set of data to learn the relationships between different features and how these features affect the target variable. \n",
    "- We need to divide the entire data set into two sets:\n",
    "    + Training set on which we are going to train our algorithm to build a model. \n",
    "    + Testing set on which we will test our model to see how accurate its predictions are.\n",
    "- Before we create the two sets, we need to identify the algorithm (estimator) we will use for our model.\n",
    "- We use the `machine_learning_map` map (shown below) as a cheat sheet to shortlist the algorithms that we can try out to build our prediction model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig_estimators](https://scikit-learn.org/stable/_downloads/b82bf6cd7438a351f19fac60fbc0d927/ml_map.svg)    \n",
    "\n",
    "Using the checklist let’s see under which category our current dataset falls into:\n",
    "- Do we have more than 50 samples (**1121** samples) ? (**Yes**)\n",
    "- Are we predicting a category? (**No**)\n",
    "- Are we predicting a quantity? (**Yes**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the checklist that we prepared above and going by the `machine_learning_map` we can try out **regression methods** such as:\n",
    "\n",
    "- Linear Regression \n",
    "- Lasso\n",
    "- ElasticNet Regression\n",
    "- Ridge Regression: \n",
    "- K Neighbors Regressor\n",
    "- Decision Tree Regressor\n",
    "- Simple Vector Regression (SVR)\n",
    "- Ada Boost Regressor\n",
    "- Gradient Boosting Regressor\n",
    "- Random Forest Regression\n",
    "- Extra Trees Regressor\n",
    "\n",
    "__Check the following documents on regresssion__: \n",
    "\n",
    "- <a href=\"https://scikit-learn.org/stable/supervised_learning.html\">Supervised learning--scikit-learn</a>\n",
    "- <a href=\"https://developer.ibm.com/technologies/data-science/tutorials/learn-regression-algorithms-using-python-and-scikit-learn/\">Learn regression algorithms using Python and scikit-learn</a>\n",
    "- <a href=\"https://www.pluralsight.com/guides/non-linear-\">Non-Linear Regression Trees with scikit-learn</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Simple Linear Model</font>\n",
    "- It is difficult to visualize the multiple features.\n",
    "- We want to predict the house price with just one variable and then move to the regression with all features.\n",
    "- Because **GrLivArea** shows positive correlation with **SalePrice**, we will use **GrLivArea** for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_garage = ames_df_nonan.GrLivArea\n",
    "y_price = ames_df_nonan.SalePrice\n",
    "\n",
    "\n",
    "X_garage = np.array(X_garage).reshape(-1,1)\n",
    "y_price = np.array(y_price).reshape(-1,1)\n",
    "\n",
    "print(X_garage.shape)\n",
    "print(y_price.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Splitting the data into training and testing sets</font>\n",
    "- We use the `train_test_split()` function to split the data into training and testing sets. \n",
    "- We train the model with 80% of the samples and test with the remaining 20%. \n",
    "- We do this to assess the model’s performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, Y_train_1, Y_test_1 = \\\n",
    "             train_test_split(X_garage, y_price, \n",
    "                              test_size = 0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of the training features: {X_train_1.shape}\")\n",
    "print(f\"Shape of the training target: {Y_train_1.shape}\")\n",
    "print(f\"Shape of the test features: {X_test_1.shape}\")\n",
    "print(f\"Shape of the test target: {Y_test_1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Training and testing the model</font>\n",
    "- We use scikit-learn’s LinearRegression to train our model on both the training and check it on the test sets.\n",
    "- We check the model performance on the train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create the model with a `sklearn` estimator__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_1 = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train the model__\n",
    "\n",
    "- We use the `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_1.fit(X_train_1, Y_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Make a prediction on the training set__\n",
    "\n",
    "- We use the `predict()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict_1 = reg_1.predict(X_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Determine the performance of the model on the training set__\n",
    "\n",
    "- We use the root mean squared error and the R2 score (best possible R2 score is 1.0 and it can be negative because a model can be arbitrarily worse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = (np.sqrt(metrics.mean_squared_error(Y_train_1, y_train_predict_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train = round(reg_1.score(X_train_1, Y_train_1),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The model performance for training set\")\n",
    "print(f\"--------------------------------------\")\n",
    "print(f'RMSE is {rmse_train}')\n",
    "print(f'R2 score is {r2_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model evaluation on the test set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = reg_1.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test = (np.sqrt(metrics.mean_squared_error(Y_test_1, y_pred_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_test = round(reg_1.score(X_test_1, Y_test_1),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The model performance for test set\")\n",
    "print(f\"--------------------------------------\")\n",
    "print(f\"Root Mean Squared Error: {rmse_test}\")\n",
    "print(f\"R^2: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of determination: 1 is perfect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Coefficient of determination: {metrics.r2_score(Y_test_1, y_pred_1) :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">45-Degree plot</font>\n",
    "\n",
    "- A scatter plot comparing a model's predicted values on one axis to the actual, true values on the other.\n",
    "- A perfectly accurate model will have all its data points falling directly on the 45-degree line ($y=x$), indicating that the predictions perfectly match the actual values.\n",
    "- This plot is a key diagnostic tool to quickly assess a regression model's performance.\n",
    "- __Interpreting the plot__:\n",
    "   - _Points on the line_: If the data points cluster tightly around the 45-degree line, it indicates a good model with high accuracy.\n",
    "   - _Points deviating from the line_: If the points are widely scattered or form a pattern, it suggests that the model is not predicting accurately for some data points. The spread and pattern of these deviations can help diagnose problems with the model.\n",
    "   - _Mean error approaching zero_: When the points are closer to the 45-degree line, the model's average error is approaching zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5));\n",
    "plt.scatter(Y_test_1, y_pred_1);\n",
    "plt.plot(y_price, y_price, '--k');\n",
    "plt.axis('tight');\n",
    "plt.xlabel(\"Actual Sale Prices\");\n",
    "plt.ylabel(\"Predicted House Prices\");\n",
    "plt.title(\"Actual Prices vs Predicted prices\");\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Linear regression model with all features</font>\n",
    "- In the previous example, we used one feature (__GrLivArea__) to create a model for predicting the sale price (__SalePrice__).\n",
    "   - We observed that accuracy was not not good.\n",
    "- Now, we create a model using all the features in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create the training and testing sets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ames_df_nonan.drop('SalePrice', axis = 1)\n",
    "y = ames_df_nonan['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the `train_test_split` to split the data into random train and test subsets.\n",
    "- Everytime you run it without specifying `random_state`, you will get a different result.\n",
    "- If you use `random_state=some_number`, then you can guarantee the split will be always the same.\n",
    "- It doesn't matter what the value of `random_state` is:  42, 0, 21, ...\n",
    "- This is useful if you want reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a linear regression model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_all = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model evaluation on the training Set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = reg_all.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = (np.sqrt(metrics.mean_squared_error(y_train, y_train_predict)))\n",
    "r2 = round(reg_all.score(X_train, y_train),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The model performance for training set\")\n",
    "print(f\"--------------------------------------\")\n",
    "print(f'RMSE is {rmse}')\n",
    "print(f'R2 score is {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model evaluation on the test set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg_all.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = (np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "r2 = round(reg_all.score(X_test, y_test),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The model performance for training set\")\n",
    "print(f\"--------------------------------------\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R^2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of determination: 1 is perfect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Coefficient of determination: {metrics.r2_score(y_test, y_pred) :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Error distribution on the test set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test - y_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__45-Degree plot__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5));\n",
    "plt.scatter(y_test, y_pred);\n",
    "plt.plot(y, y, '--k');\n",
    "plt.axis('tight');\n",
    "plt.xlabel(\"Actual House Prices\");\n",
    "plt.ylabel(\"Predicted House Prices\");\n",
    "plt.title(\"Actual Prices vs Predicted Prices\");\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMS: %r \" % np.sqrt(np.mean((y_test - y_pred) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df2 = df1.head(10)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Choosing the Best Model:</font> k-Fold Cross-Validation\n",
    "\n",
    "- Cross-validation is a resampling procedure used to evaluate ML models on a limited data sample.\n",
    "- It is primarily used in applied ML to estimate the skill of a machine learning model on unseen data.\n",
    "- We use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.\n",
    "- The biggest advantage of this method is that every data point is used for validation exactly once and for training `k-1` times.\n",
    "- To choose the final model to use, **we select the one that has the lowest validation error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general procedure is as follows:\n",
    "\n",
    "1. Shuffle the dataset randomly.\n",
    "2. Split the dataset into `k` groups\n",
    "3. For each unique group:\n",
    "   \n",
    "   3.1 Take the group as a hold out or test data set\n",
    "   \n",
    "   3.2 Take the remaining `k-1` groups as a training data set\n",
    "   \n",
    "   3.3 Fit a model on the training set and evaluate it on the test set\n",
    "   \n",
    "   3.4 Retain the evaluation score and discard the model\n",
    "   \n",
    "5. Summarize the skill of the model using the sample of model evaluation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__How to choose the value of `k`?__\n",
    "- A poorly chosen value for `k` may result in a mis-representative idea of the skill of the model, such as a score with a high variance, or a high bias.\n",
    "- The choice of `k` is usually 5 or 10, but there is no formal rule. As `k` gets larger, the difference in size between the training set and the resampling subsets gets smaller. As this difference decreases, the bias of the technique becomes smaller.\n",
    "- A value of `k=10` is very common in the field of applied machine learning, and is recommend if you are struggling to choose a value for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the visualization of a k-fold validation when k=5.\n",
    "![FIG_kFold](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
    "Image Source: https://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Set parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed    = 9\n",
    "folds   = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Set the scoring metric__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric  = \"r2\" # \"neg_mean_squared_error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hold different regression models in a single dictionary__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "models[\"Linear\"]        = LinearRegression()\n",
    "models[\"Lasso\"]         = Lasso()\n",
    "models[\"ElasticNet\"]    = ElasticNet()\n",
    "models[\"Ridge\"]         = Ridge()\n",
    "models[\"BayesianRidge\"] = BayesianRidge()\n",
    "models[\"KNN\"]           = KNeighborsRegressor()\n",
    "models[\"DecisionTree\"]  = DecisionTreeRegressor()\n",
    "models[\"SVR\"]           = SVR()\n",
    "models[\"AdaBoost\"]      = AdaBoostRegressor()\n",
    "models[\"GradientBoost\"] = GradientBoostingRegressor()\n",
    "models[\"RandomForest\"]  = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loop over all the models to perform a 10-fold cross validation__\n",
    "\n",
    "- The scoring parameter in `sklearn.model_selection.cross_val_score` determines the metric used to evaluate the performance of an estimator during cross-validation.\n",
    "- We define the scoring metric using the `scoring` parameter. `sklearn` provides a wide range of predefined scoring metrics that can be passed as strings. Examples include:\n",
    "   - _Classification_: `'accuracy'`, `'precision'`, `'recall'`, `'f1'`, `'roc_auc'`, `'neg_log_loss'`, etc.\n",
    "   - _Regression_: `'r2'`, `'neg_mean_squared_error'`, `'neg_mean_absolute_error'`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = list()\n",
    "model_names   = list()\n",
    "\n",
    "print(f\"{'Model name':>20} {'Metric mean':>16} {'Metric std':>16}\")\n",
    "\n",
    "for model_name in models:\n",
    "    model   = models[model_name]\n",
    "    k_fold  = KFold(n_splits=folds, random_state=seed, shuffle=True)\n",
    "    results = cross_val_score(model, X_train, y_train, cv=k_fold, scoring=metric)\n",
    "    \n",
    "    model_results.append(results)\n",
    "    model_names.append(model_name)\n",
    "    print(f\"{model_name:>20}: {round(results.mean(), 3):16.2f} {round(results.std(), 3):16.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a box-whisker plot to compare regression models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(12, 9));\n",
    "figure.suptitle('Regression models comparison');\n",
    "ax = figure.add_subplot(111);\n",
    "plt.boxplot(model_results);\n",
    "ax.set_xticklabels(model_names, rotation = 45, ha=\"right\");\n",
    "ax.set_ylabel(\"Mean Squared Error (MSE)\");\n",
    "plt.margins(0.05, 0.1);\n",
    "#plt.savefig(\"model_mse_scores.png\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__\n",
    "\n",
    "- The best model is the one with the highest r2 score.\n",
    "- **Based on the above comparison, we can see that `Gradient Boosting Regression` model outperforms all the other regression models:** it has the largest r2 mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Model with Gradient Boosting Regression</font>\n",
    "\n",
    "```python\n",
    "GradientBoostingRegressor(*, loss='squared_error', learning_rate=0.1, \n",
    "                          n_estimators=100, subsample=1.0, criterion='friedman_mse', \n",
    "                          min_samples_split=2, min_samples_leaf=1, \n",
    "                          min_weight_fraction_leaf=0.0, max_depth=3, \n",
    "                          min_impurity_decrease=0.0, init=None, \n",
    "                          random_state=None, max_features=None, \n",
    "                          alpha=0.9, verbose=0, max_leaf_nodes=None, \n",
    "                          warm_start=False, validation_fraction=0.1, \n",
    "                          n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Define the `GradientBoostingRegressor` estimator__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Specify the parameter grid for `GridSearchCV`__\n",
    "\n",
    "Create a dictionary where keys are the hyperparameter names as strings and values are lists of the values to try for each hyperparameter. Common parameters for `GradientBoostingRegressor` to tune include: \n",
    "\n",
    "- `n_estimators`: Number of boosting stages.\n",
    "- `learning_rate`: Shrinks the contribution of each tree.\n",
    "- `max_depth`: Maximum depth of the individual regression estimators.\n",
    "- `subsample`: Fraction of samples to be used for fitting the individual base learners.\n",
    "- `loss`: The loss function to be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Initialize `GridSearchCV`__\n",
    "\n",
    "- `estimator`: The `GradientBoostingRegressor` object.\n",
    "- `param_grid`: The dictionary of hyperparameters and their values.\n",
    "- `cv`: Number of folds for cross-validation.\n",
    "- `scoring`: The metric to evaluate the models.\n",
    "- `n_jobs`: Number of CPU cores to use (-1 means all available cores).\n",
    "- `verbose`: Controls the verbosity of the outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=gbr, \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    scoring=metric, #'neg_mean_squared_error', \n",
    "    n_jobs=-1, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fit `GridSearchCV` to your training data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Retrieve the best parameters and best score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters found: \\n\\t {grid_search.best_params_}\")\n",
    "print(f\"Best score found: \\n\\t {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Retrieve the best estimator__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluate the best estimator on the test set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_predicted = best_gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = best_gbr.score(X_test, y_test)\n",
    "print(f\"R-squared on test set: {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Visualizing predictions__\n",
    "\n",
    "- Visualizing predictions helps us understand how well our model is performing and identify any patterns or discrepancies between the actual and predicted values.\n",
    "- By plotting the actual values against the predicted values, we can visually assess the model's accuracy and spot areas where the predictions may be off.\n",
    "- This is crucial for interpreting the effectiveness of our hyperparameter tuning and understanding the model's behavior.\n",
    "\n",
    "__The closer these points are together, the better the model's predictive performance.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(len(y_test)), y_test, label='Actual', alpha=0.7)\n",
    "plt.scatter(range(len(y_test)), gbr_predicted, label='Predicted', alpha=0.7)\n",
    "plt.title('Actual vs Predicted Values with Tuned Hyperparameters')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Error distribution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_expected = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(gbr_expected - gbr_predicted);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 45-Degree Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5));\n",
    "plt.scatter(gbr_expected, gbr_predicted)\n",
    "plt.plot(y, y, '--k');\n",
    "plt.axis('tight');\n",
    "plt.xlabel('True price ($1000s)');\n",
    "plt.ylabel('Predicted price ($1000s)');\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Feature importance__\n",
    "- Once we have a trained model, we can understand feature importance (or variable importance) of the dataset which tells us how important each feature is, to predict the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 11));\n",
    "\n",
    "feature_importance = best_gbr.feature_importances_\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos        = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "np_feature_names = np.array(feature_names)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center');\n",
    "plt.yticks(pos, np_feature_names[sorted_idx]);\n",
    "plt.xlabel('Relative Importance');\n",
    "plt.title('Variable Importance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot training deviance:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "# compute test set deviance\n",
    "test_score = np.zeros((n_estimators,), dtype=np.float64)\n",
    "\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "for i, y_pred in enumerate(gbr.staged_predict(X_test)):\n",
    "    test_score[i] =  mean_squared_error(gbr_expected, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 6));\n",
    "plt.subplot(1, 1, 1);\n",
    "plt.title('Deviance');\n",
    "plt.plot(np.arange(n_estimators) + 1,  gbr.train_score_, 'b-',\n",
    "         label='Training Set Deviance');\n",
    "plt.plot(np.arange(n_estimators) + 1, test_score, 'r-',\n",
    "         label='Test Set Deviance');\n",
    "plt.legend(loc='upper right');\n",
    "plt.xlabel('Boosting Iterations');\n",
    "plt.ylabel('Deviance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Useful links</font>\n",
    "\n",
    "- <a href=\"https://medium.com/towards-artificial-intelligence/calculating-simple-linear-regression-and-linear-best-fit-an-in-depth-tutorial-with-math-and-python-804a0cb23660\">Calculating Simple Linear Regression and Linear Best Fit an In-depth Tutorial with Math and Python</a>\n",
    "- <a href=\"https://scikit-learn.org/stable/tutorial/index.html\">scikit-learn Tutorials</a>\n",
    "- <a href=\"https://medium.com/@amitg0161/sklearn-linear-regression-tutorial-with-boston-house-dataset-cde74afd460a\">Sklearn Linear Regression Tutorial with Boston House Dataset</a>\n",
    "- <a href=\"https://www.dataquest.io/blog/sci-kit-learn-tutorial/\">Scikit-learn Tutorial: Machine Learning in Python</a>\n",
    "- <a href=\"https://davidburn.github.io/notebooks/mnist-numbers/MNIST%20Handwrititten%20numbers/\">MNIST handwritten number identification</a>\n",
    "- [K-Fold Cross-Validation in Python Using SKLearn](https://www.askpython.com/python/examples/k-fold-cross-validation)\n",
    "- [Ames Housing Price Prediction Project](https://github.com/sinhasagar507/Ames-house-price-prediction) by Sagar Sinha.\n",
    "- [Ames Housing Prediction](https://deepnote.com/app/suh-sean-8d86/Ames-Housing-Prediction-ca5b5a44-e02e-4bb5-9a81-8e2b89593d92) by Suh Sean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
