{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h1><font color=\"red\">Image Classification with Tensorflow</font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Reference\n",
    "\n",
    "- [MNIST digits classification with TensorFlow 2](https://github.com/antonio-f/TensorFlow2_digits_classification-Linear_Classifier-MLP/blob/master/TensorFlow2_digits_classification-Linear_Classifier-MLP/digits_classification.ipynb)\n",
    "- [Mnist handwritten digit classification using tensorflow](https://milindsoorya.site/blog/handwritten-digits-classification)\n",
    "- [A real example â€“ recognizing handwritten digits](https://subscription.packtpub.com/book/data/9781838823412/1/ch01lvl1sec08/a-real-example-recognizing-handwritten-digits)\n",
    "- [DIFFERENCE BETWEEN SOFTMAX FUNCTION AND SIGMOID FUNCTION](https://dataaspirant.com/difference-between-softmax-function-and-sigmoid-function/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Version of Numpy:      {np.__version__}\")\n",
    "print(f\"Version of Pandas:     {pd.__version__}\")\n",
    "#print(f\"Version of Keras:      {tf.keras.__version__}\")\n",
    "print(f\"Version of TensorFlow: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Image Classification</font> \n",
    "\n",
    "We use the [MNIST data set](http://yann.lecun.com/exdb/mnist/) (Modified National Institute of Standards and Technology database).\n",
    "\n",
    "* Is a large database of handwritten digits that is commonly used for training various image processing systems.\n",
    "* The database is also widely used for training and testing in the field of machine learning.\n",
    "* The dataset we will be using contains 70000 images of handwritten digits among which 10000 are reserved for testing.\n",
    "* It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TSF](https://static.javatpoint.com/tutorial/tensorflow/images/mnist-dataset-in-cnn.jpg)\n",
    "Image Source: [https://www.javatpoint.com/tensorflow-mnist-dataset-in-cnn](https://www.javatpoint.com/tensorflow-mnist-dataset-in-cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Load MNiST Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape train inputs:  \", x_train.shape)\n",
    "print(\"Shape train outputs: \", y_train.shape)\n",
    "print(\"Shape test  inputs:  \", x_test.shape)\n",
    "print(\"Shape test  outputs: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save image parameters to the constants that we will use later \n",
    "# for data re-shaping and for model traning.\n",
    "(_, IMAGE_WIDTH, IMAGE_HEIGHT) = x_train.shape\n",
    "print(f'IMAGE_WIDTH:  {IMAGE_WIDTH}')\n",
    "print(f'IMAGE_HEIGHT: {IMAGE_HEIGHT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Type train inputs:  \", x_train.dtype)\n",
    "print(\"Type train outputs: \", y_train.dtype)\n",
    "print(\"Type test  inputs:  \", x_test.dtype)\n",
    "print(\"Type test  outputs: \", y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Check an arbitrary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_index = 15657\n",
    "some_digit = x_train[some_index]\n",
    "some_digit_image = some_digit.reshape(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "plt.imshow(some_digit_image, \n",
    "           cmap = matplotlib.cm.binary, \n",
    "           interpolation='nearest')\n",
    "plt.axis=('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[some_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Preprocess the Training and Test Datasets</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Change the data type\n",
    "\n",
    "- Change the type from integer to floating point. \n",
    "- This will reduce our memory requirements by forcing the precision of the pixel values to be 32 bit, the default precision used by `Keras` anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train --> min = {np.min(x_train)} max = {np.max(x_train)}\")\n",
    "print(f\"Test  --> min = {np.min(x_test)} max = {np.max(x_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Normalize the data\n",
    "- The values are from 0.0 to 255.0.\n",
    "- We want to have values between 0.0 and 1.0.\n",
    "- Normalizing the data generally speeds up trainning and leads to faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train --> min = {np.min(x_train)} max = {np.max(x_train)}\")\n",
    "print(f\"Test  --> min = {np.min(x_test)} max = {np.max(x_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Reshape the data\n",
    "\n",
    "- The training and test datasets are structured as a 3-dimensional array of instance, image width and image height. \n",
    "- For a multi-layer perceptron model we must reduce the images down into a vector of pixels. In this case the `IMAGE_WIDTH*IMAGE_HEIGHT` sized images will be 784 pixel input values.\n",
    "- We can do this transform easily using the `reshape()` function on the NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of x_train: {x_train.shape}\")\n",
    "print(f\"Shape of x_test:  {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reshape = x_train.reshape(x_train.shape[0], \n",
    "                                  IMAGE_WIDTH*IMAGE_HEIGHT)\n",
    "x_test_reshape = x_test.reshape(x_test.shape[0], \n",
    "                                IMAGE_WIDTH*IMAGE_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of x_train_reshape: {x_train_reshape.shape}\")\n",
    "print(f\"Shape of x_test_reshape:  {x_test_reshape.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Convert class vectors to binary class matrices\n",
    "\n",
    "- The targets have 10 possible integer values: `0, 1, 2, ..., 9`.\n",
    "- We use the `to_categorical` function to convert integer targets into categorical.\n",
    "  - For instance, `2` would become `[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]` (itâ€™s zero-indexed).\n",
    "- We do it because `Keras` will expect the training targets to be 10-dimensional vectors, since there will be 10 nodes in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train_convert = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_convert = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_convert[some_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Model 1: Simple Sequential Model</font>\n",
    "\n",
    "Architecture of the Network is:\n",
    "\n",
    "1. Input layer for `IMAGE_WIDTH*IMAGE_HEIGHT = 28x28 = 784` images in MNiST dataset\n",
    "2. Dense layer with 128 neurons and ReLU activation function\n",
    "3. Output layer with 10 neurons for classification of input images as one of ten digits (0 to 9)\n",
    "\n",
    "#### Remarks\n",
    "- We add a regularization `Dropout` layer to randomly exclude a portion of the neurons (here 20%) in the layer in order to reduce overfitting.\n",
    "- A `softmax` activation function is used on the output layer to turn the outputs into probability-like values and allow one class of the 10 to be selected as the modelâ€™s output prediction.\n",
    "  - Converts the result into a probability distribution.\n",
    "  - Calculates probabilities of each target class over all possible target classes\n",
    "  - The values of the output vector are in range (0, 1) and sum to 1. \n",
    "  - `softmax` of input `x` is calculated by function `exp(x)/tf.reduce_sum(exp(x))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_model = tf.keras.models.Sequential()\n",
    "one_layer_model.add(tf.keras.layers.Dense(\n",
    "    128, \n",
    "    activation='relu', \n",
    "    input_shape=(IMAGE_WIDTH*IMAGE_HEIGHT,)))\n",
    "one_layer_model.add(tf.keras.layers.Dropout(0.2))\n",
    "one_layer_model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(one_layer_model,\n",
    "           show_shapes=True,\n",
    "           show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Compile the Model</font>\n",
    "\n",
    "Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n",
    "\n",
    "- Loss function This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n",
    "- Optimizer This is how the model is updated based on the data it sees and its loss function.\n",
    "- Metrics Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified.\n",
    "\n",
    "![MLP](https://m0nads.files.wordpress.com/2021/01/linear_classifier.png)\n",
    "Image Source: m0nads.wordpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_model.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=tf.keras.optimizers.RMSprop(),\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Training and Validation</font>\n",
    "\n",
    "The `one_layer_model.fit` method adjusts the model parameters to minimize the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "one_layer_history = one_layer_model.fit(\n",
    "    x_train_reshape, \n",
    "    y_train_convert,\n",
    "    batch_size = batch_size,\n",
    "    epochs = num_epochs,\n",
    "    verbose = 1, \n",
    "    validation_data = (x_test_reshape, y_test_convert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Plot the Deceasing Loss over Epochs</font>\n",
    "\n",
    "Use Pandas to plot a graph showing the decrease in mean squared error (mse) as training improves the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(one_layer_history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df[['loss', 'val_loss']].plot(xlabel='Epochs', \n",
    "                                   ylabel='Loss', \n",
    "                                   title='Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df[['accuracy', 'val_accuracy']].plot(xlabel='Epochs', \n",
    "                                   ylabel='Accuracy', \n",
    "                                   title='Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Evaluate the Model</font>\n",
    "\n",
    "The `mnist_model.evaluate` method checks the models performance, usually on a \"Validation-set\" or \"Test-set\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = one_layer_model.evaluate(x_test_reshape,  \n",
    "                                 y_test_convert, \n",
    "                                 verbose=0)\n",
    "print(f'Test loss:     {score[0]}')\n",
    "print(f'Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Visualize Predictions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digits(X, y):\n",
    "    \"\"\"\n",
    "      Given an array of images of digits X and \n",
    "      the corresponding values of the digit y,\n",
    "      this function plots the first 96 images and their values.\n",
    "    \"\"\"\n",
    "    # Figure size (width, height) in inches\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Adjust the subplots \n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(96):\n",
    "        # Initialize the subplots: \n",
    "        #    Add a subplot in the grid of 8 by 12, at the i+1-th position\n",
    "        ax = fig.add_subplot(8, 12, i + 1, xticks=[], yticks=[])\n",
    "        \n",
    "        # Display an image at the i-th position\n",
    "        ax.imshow(X[i].reshape(28, 28), cmap=plt.cm.binary, interpolation='nearest')\n",
    "       \n",
    "        # label the image with the target value\n",
    "        ax.text(0, 7, str(y[i]))\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = one_layer_model.predict(x_test_reshape, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `numpy.argmax` function to return the indices of the maximum values along an axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_predicted_labels = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_predicted_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_digits(x_test_reshape, one_layer_predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Confusion Matrix for Validation</font>\n",
    "\n",
    "- We can use the confusion matrix to have a picture of our prediction.\n",
    "- A number `n` in a cell means that we predicted the value in the truth row as the value in the predicted column, `n` times. \n",
    "- All the diagonal elements are correct predictions.\n",
    "- In the example below, the black cells, value shows the wrong predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(labels=y_test, \n",
    "                              predictions=one_layer_predicted_labels)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d');\n",
    "plt.xlabel('Predicted');\n",
    "plt.ylabel('Truth');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_accuracy(cmatrix):\n",
    "    cm_values = cmatrix.numpy()\n",
    "    l = cm_values.shape[0]\n",
    "    diag = [cm_values[i, i] for i in range(l)]\n",
    "    \n",
    "    pds = pd.Series(y_test)\n",
    "\n",
    "    org_total = pds.value_counts().sort_index()\n",
    "    org_percent = (pds.value_counts()/pds.count()).sort_values().sort_index()*100\n",
    "    pred_accu = (pd.Series(diag)/org_total)*100\n",
    "    idx = ['zero', 'one', 'two', 'three', 'four',\n",
    "          'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "    keys = ['Original Total', 'Predicted Total', 'Predicted Accuracy']\n",
    "    accu_data = pd.concat([org_total, pd.Series(diag), pred_accu], \n",
    "                             axis=1, keys=keys)\n",
    "\n",
    "    accu_data.index = idx\n",
    "    return accu_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_data = determine_accuracy(cm)\n",
    "accuracy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Save the Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_model.save('one_layer_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to reload the model later, we can use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('one_layer_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Model 2: Add a Hidden Layer</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_layer_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(IMAGE_WIDTH*IMAGE_HEIGHT, )),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.sigmoid),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.sigmoid),\n",
    "    tf.keras.layers.Dense(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(two_layer_model,\n",
    "           #to_file='keras_model_plot.png',\n",
    "           show_shapes=True,\n",
    "           show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_layer_model.compile(optimizer='adam',\n",
    "                        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "two_layer_history = two_layer_model.fit(\n",
    "    x_train_reshape, \n",
    "    y_train, \n",
    "    batch_size = batch_size,\n",
    "    epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(two_layer_history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df['loss'].plot(xlabel='Epochs', \n",
    "                     ylabel='Loss', \n",
    "                     title='Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df['accuracy'].plot(xlabel='Epochs', \n",
    "                     ylabel='Accuracy', \n",
    "                     title='Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = two_layer_model.evaluate(x_test_reshape,  \n",
    "                                 y_test, \n",
    "                                 verbose=0)\n",
    "print(f'Test loss:     {score[0]}')\n",
    "print(f'Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = two_layer_model.predict(x_test_reshape)\n",
    "two_layer_predicted_labels = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[:10])\n",
    "print(two_layer_predicted_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(labels=y_test, \n",
    "                              predictions=two_layer_predicted_labels)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d');\n",
    "plt.xlabel('Predicted');\n",
    "plt.ylabel('Truth');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_data = determine_accuracy(cm)\n",
    "accuracy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Model 2: Build a Convolutional Neural Network (CNN)</font>\n",
    "\n",
    "- CNNs work by extracting features from images using convolutional layers, pooling layers, and activation functions.\n",
    "- These layers allow CNNs to learn complex relationships between features, identify objects or features regardless of their position, and reduce the computational complexity of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convolution__ is the process if applying a filter that adds each pixel value of an image to its neighbors, weighted according to a kernel matrix.\n",
    "\n",
    "![fig_conv](https://developers.google.com/static/machine-learning/practica/image-classification/images/convolution_overview.gif)\n",
    "Image Source: developers.google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pooling__ reduces the size of an input by sampling from regions in the input.\n",
    "- max-pooling: Apply pooling by choosing the maximum value in each region. The filter aims to conserve the main features of the image while reducing the size.\n",
    "\n",
    "![fig_pooling](https://developers.google.com/static/machine-learning/practica/image-classification/images/maxpool_animation.gif)\n",
    "Image Source: developers.google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a network that use convolution to analyze the images:\n",
    "\n",
    "- A convolutional layer with 32 filters and a 3x3 kernel. This layer will use a `ReLU` activation function. \n",
    "   - The goal of this layer is to generate 32 different representations of an image, each one of 26x26. The 3x3 kernel will discard a pixel on each side of the original image and that's way we get 26x26 squares instead of 28x28.  \n",
    "- Use `MaxPool2D` is a downsampling filter that reduces the amount of information generated by the convolutional layer. It reduces 2x2 matrix of the image to a single pixel.\n",
    "   - We start with 32 filters of 26x26, so after this operation will have 32 filters of 13x13.\n",
    "- We then take the `(13, 13, 32)` vector and flatten it to a `(5408,)` vector. \n",
    "- Add a fully connected hidden layer with 128 nodes:\n",
    "  - `relu` activation function\n",
    "  - Dropout is a regularization layer: `50%` of the nodes in the layer are randomly ignores.\n",
    "- A `softmax` activation function is used on the output layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = tf.keras.models.Sequential([\n",
    " \n",
    "    # Convolutional layer. Learn 32 filters using a 3x3 kernel\n",
    "    tf.keras.layers.Conv2D(\n",
    "        32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)\n",
    "    ),  \n",
    " \n",
    "    # Max-pooling layer, using 2x2 pool size\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    " \n",
    "    # Flatten units\n",
    "    tf.keras.layers.Flatten(),\n",
    " \n",
    "    # Add a hidden layer with dropout\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    " \n",
    "    # Add an output layer with output units for all 10 digits\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(conv_model,\n",
    "           show_shapes=True,\n",
    "           show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "conv_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_array(myarray):\n",
    "    shape = myarray.shape\n",
    "    return myarray.reshape(shape[0], shape[1], shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.fit(reshape_array(x_train), \n",
    "               y_train_convert, \n",
    "               epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_loss, conv_accuracy = conv_model.evaluate(reshape_array(x_test),  \n",
    "                                               y_test_convert, \n",
    "                                               verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" loss: {conv_loss} \\n accuracy: {conv_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
