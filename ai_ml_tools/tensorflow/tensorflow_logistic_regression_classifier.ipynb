{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h1><font color=\"red\">Logistic Regression Classifier Model with Tensorflow</font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Objectives</font>\n",
    "\n",
    "In this presentation, we use a simple classification dataset to:\n",
    "\n",
    "- Build a TensorFlow model\n",
    "- Train the model\n",
    "- Evaluate the model\n",
    "\n",
    "We show the steps for building a Machine Learning (ML) model with PyTorch. The functions presented here can be used as reference for other ML applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Python packages used</font>\n",
    "\n",
    "- __Matplotlib__: Create visualization.\n",
    "- __Pandas__: Data (two-dimensional labelled array) manipulation and analysis.\n",
    "- __Seaborn__: Provide a high-level interface for creating attractive and informative statistical graphics. \n",
    "- __Scikit-Learn__:  Provide supervised and unsupervised Machine Learning algorithms.\n",
    "- __TensorFlow__: Used to to build, train, and evaluate a deep machine learning algorithm based on Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    print(\"Running in Google Colab\")\n",
    "except:\n",
    "    print(\"Not running in Google Colab\")\n",
    "else:\n",
    "    print(\"Installing modules in Google Colab\")\n",
    "    !pip install seaborn\n",
    "    !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Numpy version:      {np.__version__}\")\n",
    "print(f\"Pandas version:     {pd.__version__}\")\n",
    "print(f\"Seaborn version:    {sns.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Loading the dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Description of the data</font>\n",
    "\n",
    "- We have a dataset which features are points on a plane and the label has two values (classes).\n",
    "   - Each point is assigned a class (`0` or `1`).\n",
    "- We want to build a Machine Learning model to be able to predict the classes given a set of points.\n",
    "- We will use __logistic regression__ that is a statistical method for predicting binary classes.\n",
    "   - It is a special case of linear regression where the target variable is categorical in nature.\n",
    "   - It is one of the most simple and commonly used Machine Learning algorithms for two-class classification.\n",
    "   - The outcome or the target variable has only two possible classes.\n",
    "   - It predicts the probability of occurrence of a binary event utilizing a logit function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Read the data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/astg606/astg_pymaterials/refs/heads/main/ai_ml_tools/datasets/classifier_dataset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url, sep=\"\\s+\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=\"blue\"> Splitting the data into training and testing sets</font>\n",
    "- We split the data into training and testing sets. \n",
    "- We train the model with 70% of the samples and test with the remaining 30%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extract the train and test datasets as NumPy arrays__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"x1\", \"x2\"]].values, \n",
    "                                                    df[\"label\"].values, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Visualize the data</font>\n",
    "\n",
    "__Scatterplot of $x_1$ against $x_2$__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:,0], X_train[:,1])\n",
    "plt.xlabel(r\"Feature $x_1$\", fontsize=10)\n",
    "plt.ylabel(r\"Feature $x_2$\", fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scatterplot with the two classes: `y=0` and `y=1`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes(X: np.array, y: np.array, boundary: tuple=None) -> None:\n",
    "\n",
    "    plt.plot(X[y==0, 0], X[y==0, 1],\n",
    "        marker=\"D\", markersize=10,\n",
    "        linestyle=\"\", label=\"Class 0\",\n",
    "    )\n",
    "\n",
    "    plt.plot(X[y==1, 0], X[y==1, 1],\n",
    "        marker=\"^\", markersize=13,\n",
    "        linestyle=\"\", label=\"Class 1\",\n",
    "    )\n",
    "\n",
    "    if boundary:\n",
    "        plt.plot([boundary[0], boundary[1]], [boundary[2], boundary[3]], color=\"red\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlim([-5.5, 5.5])\n",
    "    plt.ylim([-5.5, 5.5])\n",
    "\n",
    "    plt.xlabel(r\"Feature $x_1$\", fontsize=12)\n",
    "    plt.ylabel(r\"Feature $x_2$\", fontsize=12)\n",
    "\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Normailized the Data</font> <a class=\"anchor\" id=\"sec_tf_norm\"></a>\n",
    "\n",
    "- In general, variables may not be a similar scale. High values would gain more importance in any distance-based calculations. \n",
    "- It is good practice to normalize features that use different scales and ranges. \n",
    "- Although the model might converge without feature normalization, it makes training more difficult, and it makes the resulting model dependent on the choice of units used in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = X_train.mean(axis=0)\n",
    "train_std = X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normalization of the train features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normalization of the test features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (X_test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Creating the ML model</font>\n",
    "\n",
    "## <font color=\"blue\">Set the hyperparameters</font>\n",
    "\n",
    "It is a good practice to declare the following parameters before creating the model for ease of change and understanding.\n",
    "\n",
    "__Dataset parameters__\n",
    "\n",
    "These parameters are defines by the dataset used:\n",
    "\n",
    "- number of features\n",
    "- number of classes to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model parameters__\n",
    "\n",
    "- batch size\n",
    "- number of epochs\n",
    "- learning rate (optimizer steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_epochs = 20\n",
    "learning_rate = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Convert class vectors to binary class matrices\n",
    "\n",
    "- The targets have 2 possible integer values: `0` and ` 1`.\n",
    "- We use the `to_categorical` function to convert integer targets into categorical:\n",
    "  - `0` would become `[1, 0]` (it’s zero-indexed).\n",
    "  - `1` would become `[0, 1]`.\n",
    "- We do it because `Keras` will expect the training targets to be 2-dimensional vectors, since there will be 2 nodes in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_convert = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_convert = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_convert[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_convert[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Build the TensorFlow model</font>\n",
    "\n",
    "### <font color=\"green\"> Instantiate a sequential model using `keras`\n",
    "\n",
    "We create a sequential Neural Network:\n",
    "\n",
    "- The model expects rows of data with `input_size` variables \n",
    "- The output layer has `num_classes` nodes.\n",
    "\n",
    "Ther are no hidden layer or activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(num_classes, input_shape=(input_size,)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Visualize the model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,\n",
    "           #to_file='keras_model_plot.png',\n",
    "           show_shapes=True,\n",
    "           show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">  Inspect the model\n",
    "\n",
    "`model.summary()` is a useful method if you want to get an overview of your model and see the total number of parameters.\n",
    "It prints:\n",
    "\n",
    "- Name and type of all layers in the model.\n",
    "- Output shape for each layer.\n",
    "- Number of weight parameters of each layer.\n",
    "-  If the model has general topology, the inputs each layer receives\n",
    "- The total number of trainable and non-trainable parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "\n",
    "print(f'        Total params: {trainable_count + non_trainable_count}')\n",
    "print(f'    Trainable params: {trainable_count}')\n",
    "print(f'Non-trainable params: {non_trainable_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">  Compile the model\n",
    "- Once you have specified the architecture of the network, you need to specify the method for back-propagation by choosing an optimizer and specify the loss.\n",
    "- Compiling the model uses the efficient numerical libraries (Theano or TensorFlow) in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required to provide a loss function and an optimizer: \n",
    "- We are asking the network to use the `rmsprop` optimizer to change weights in such a way that the loss `mse` (mean squared error) is minimized at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = optimizer,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Train the model</font>\n",
    "\n",
    "- We use the `fit` method to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train_convert,  \n",
    "    batch_size = batch_size,\n",
    "    epochs = num_epochs,\n",
    "    verbose = 1, \n",
    "    validation_data = (X_test, y_test_convert)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">  Visualize the model's training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Evaluate the Model on Test Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Compute the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test_convert, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test data:\")\n",
    "print(f\"\\t loss = {loss} \\n\\t accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">  Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t Model trainable parameters: \\n')\n",
    "print(f\"Weights: \\n {model.get_weights()[0]}\")\n",
    "print()\n",
    "print(f\"Biases:  \\n {model.get_weights()[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_boundary(model):\n",
    "\n",
    "    w1 = model.get_weights()[0][0][0]\n",
    "    w2 = model.get_weights()[0][0][1]\n",
    "    b = model.get_weights()[1][0]\n",
    "\n",
    "    print(f\"w1 = {w1}\")\n",
    "    print(f\"w2 = {w2}\")\n",
    "    print(f\" b = {b}\")\n",
    "    print()\n",
    "\n",
    "    x1_min = -20\n",
    "    x2_min = (-(w1 * x1_min) - b) / w2\n",
    "\n",
    "    x1_max = 20\n",
    "    x2_max = (-(w1 * x1_max) - b) / w2\n",
    "\n",
    "    return x1_min, x1_max, x2_min, x2_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary = comp_boundary(model)\n",
    "boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(X_test, y_test_pred, boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(X_test, y_test, boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Useful references</font>\n",
    "\n",
    "- <a href=\"https://www.mygreatlearning.com/blog/what-is-tensorflow-machine-learning-library-explained/\">What is TensorFlow? The Machine Learning Library Explained</a>\n",
    "- <a href=\"https://www.tensorflow.org/tutorials/keras/regression\">Basic regression: Predict fuel efficiency</a>\n",
    "- <a href=\"https://stackabuse.com/tensorflow-2-0-solving-classification-and-regression-problems/\">Tensorflow 2.0: Solving Classification and Regression Problems</a>\n",
    "- <a href=\"https://www.toptal.com/machine-learning/tensorflow-machine-learning-tutorial\">Getting Started with TensorFlow: A Machine Learning Tutorial</a>\n",
    "- <a href=\"https://sebastianraschka.com/faq/docs/tensorflow-vs-scikitlearn.html\">What is the main difference between TensorFlow and scikit-learn?</a>\n",
    "- <a href=\"https://adventuresinmachinelearning.com/python-tensorflow-tutorial/\">Python TensorFlow Tutorial – Build a Neural Network</a>\n",
    "- <a href=\"https://steadforce.com/en/first-steps-tensorflow-part-3/\">A simple neural network with TensorFlow</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
