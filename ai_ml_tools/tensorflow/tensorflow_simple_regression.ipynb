{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h1><font color=\"red\">Simple Regression with Tensorflow</font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Objective</font> <a class=\"anchor\" id=\"sec_obj\"></a>\n",
    "\n",
    "The objective if this presentation is to create a ML model with TensorFlow for a simple regression problem. We show the steps involved in creating and validating the model. \n",
    "\n",
    "\n",
    "__Target audience:__\n",
    "\n",
    "This document is meant for people who want to start building their own AI/ML models with TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Python packages used</font>\n",
    "\n",
    "- __Matplotlib__: Create visualization.\n",
    "- __Pandas__: Data (two-dimensional labelled array) manipulation and analysis.\n",
    "- __Seaborn__: Provide a high-level interface for creating attractive and informative statistical graphics. \n",
    "- __Scikit-Learn__:  Provide supervised and unsupervised Machine Learning algorithms.\n",
    "- __TensorFlow__: Used to to build, train, and evaluate a deep machine learning algorithm based on Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    print(\"Running in Google Colab\")\n",
    "except:\n",
    "    print(\"Not running in Google Colab\")\n",
    "else:\n",
    "    print(\"Installing modules in Google Colab\")\n",
    "    !pip install seaborn\n",
    "    !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Numpy version:      {np.__version__}\")\n",
    "print(f\"Pandas version:     {pd.__version__}\")\n",
    "print(f\"Seaborn version:    {sns.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Problem Statement</font>\n",
    "\n",
    "We consider the function: <br>\n",
    "$$\n",
    "f(x,y) = (1-(x^2 + y^3))e^{-\\frac{1}{2}(x^2 + y^2)}\n",
    "$$\n",
    "<br>\n",
    "defined in the domain $D=[-3,3] \\times [-3,3]$.\n",
    "<OL>\n",
    "<LI> We randomnly select $n$ points in the domain $D$ and compute the function on those points to create a (training) dataset containing $n$ pairs points/values.\n",
    "<LI> We use the dataset for training a ML algorithm.\n",
    "<LI> We generate a uniform set of points (testing set) in $D$ to test the algorithm.\n",
    "</OL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Generating the Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff(x,y):\n",
    "    return (1-(x**2+y**3))*np.exp(-(x**2+y**2)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Data\n",
    "\n",
    "- We wan to create $50\\times 30=1500$ random points in the domain $[-3,3] \\times [-3,3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dims = 2\n",
    "nx = 50\n",
    "ny = 30\n",
    "num_points = nx * ny\n",
    "\n",
    "# Boundary of the domain\n",
    "a_min = -3.0\n",
    "a_max = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(a_min, a_max, (num_points, num_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:9,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We determine the value of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ff(X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"x\": X[:,0], \"y\": X[:,1], \n",
    "                           \"TargetValues\": z[:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Data Gathering and Basic Analyses</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into training and testing sets\n",
    "- We split the data into training and testing sets. \n",
    "- We train the model with 80% of the samples and test with the remaining 20%. \n",
    "- We do this to assess the modelâ€™s performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_df = data.drop('TargetValues', axis = 1)\n",
    "z_df = data['TargetValues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xy_df, \n",
    "                                                    z_df, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train features shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test features shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the data to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()#.gca(projection='3d');\n",
    "threedee = fig.add_subplot(projection='3d')\n",
    "threedee.scatter(X_train['x'], X_train['y'], \n",
    "                 y_train);\n",
    "threedee.set_xlabel('x');\n",
    "threedee.set_ylabel('y');\n",
    "threedee.set_zlabel('f(x,y)');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(x=X_train['x'], y=X_train['y'], \n",
    "            cmap=\"Blues\", shade=True, bw_adjust=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the overall statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_train = X_train.describe()\n",
    "stats_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the joint distribution of the columns from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(X_train, diag_kind=\"kde\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">Add noise in the training targets</font>\n",
    "\n",
    "- The function `ff` is smooth.\n",
    "- We want to add noise to the targets.\n",
    "- We consider as noise a Gaussian normal distribution with `noise_mean` as mean and `noise_std` as standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = y_train.shape[0]\n",
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_mean = 0.0\n",
    "noise_std  = 1.0e-2\n",
    "noise = np.random.normal(noise_mean, noise_std, n_train)\n",
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = y_train + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Normailized the Data</font>\n",
    "\n",
    "- In general, variables may not be a similar scale. High values would gain more importance in any distance-based calculations. \n",
    "- It is good practice to normalize features that use different scales and ranges. \n",
    "- Although the model might converge without feature normalization, it makes training more difficult, and it makes the resulting model dependent on the choice of units used in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_train = X_train.describe().transpose()\n",
    "stats_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(x):\n",
    "    \"\"\"\n",
    "       Normalize the data\n",
    "    \"\"\"\n",
    "    return (x - stats_train['mean']) / stats_train['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize the data that will be used to train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normed = normalize_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We also need to normalize the test dataset by projecting it into the same distribution that the model has been trained on**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_normed = normalize_data(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**The same normalization will have to be applied to any other data used in this model.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Build the model</font>\n",
    "\n",
    "#### Determining the parameters of the Neural Network\n",
    "\n",
    "- We have two (2) features and one (1) target.\n",
    "   - The Neural Network will have `input_dim=2` input neurons and `output_dim=1` output neuron.\n",
    "- In each hidden layer:\n",
    "   - We want the number of hidden neurons to be less than twice the size of the input layer.\n",
    "   - We select three (3) neurons in the first hidden layer and three (3) in the second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dataset parameters__\n",
    "\n",
    "These parameters are defines by the dataset used:\n",
    "\n",
    "- number of features\n",
    "- number of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X_train.keys())\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model parameters__\n",
    "\n",
    "- batch size\n",
    "- number of epochs\n",
    "- learning rate (optimizer steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # not used here\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_nodes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate a sequential model using `keras`\n",
    "\n",
    "We create a sequential Neural Network:\n",
    "\n",
    "- The model expects rows of data with `input_dim` variables (the `input_shape=[input_dim]` argument)\n",
    "- The first hidden layer has `num_hidden_nodes` nodes and uses the `relu` activation function.\n",
    "- The second hidden layer has `num_hidden_nodes` nodes and uses the `relu` activation function.\n",
    "- The output layer has one node and uses no activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "             layers.Dense(num_hidden_nodes, activation=tf.nn.relu, \n",
    "                          input_shape=[input_dim]),\n",
    "             layers.Dense(num_hidden_nodes, activation=tf.nn.relu),\n",
    "             layers.Dense(output_dim) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model creation can also be written as:\n",
    "\n",
    "```python\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(num_hidden_nodes, activation=tf.nn.relu, \n",
    "                       input_shape=[input_dim]))\n",
    "model.add(layers.Dense(num_hidden_nodes, activation=tf.nn.relu))\n",
    "model.add(layers.Dense(output_dim))\n",
    "```\n",
    "\n",
    "Dense layers represent a function that maps the input tensor `x` to an output tensor `y` via the equation `y = Ax + b` where `A` (the kernel) and `b` (the bias) are parameters of the dense layer.\n",
    "\n",
    "![nn](../images/tensorflow_nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "- Once you have specified the architecture of the network, you need to specify the method for back-propagation by choosing an optimizer and specify the loss.\n",
    "- Compiling the model uses the efficient numerical libraries (Theano or TensorFlow) in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required to provide a loss function and an optimizer: \n",
    "- We are asking the network to use the `rmsprop` optimizer to change weights in such a way that the loss `mse` (mean squared error) is minimized at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse',\n",
    "              optimizer = optimizer,\n",
    "              metrics = ['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the model\n",
    "\n",
    "`model.summary()` is a useful method if you want to get an overview of your model and see the total number of parameters.\n",
    "It prints:\n",
    "\n",
    "- Name and type of all layers in the model.\n",
    "- Output shape for each layer.\n",
    "- Number of weight parameters of each layer.\n",
    "-  If the model has general topology, the inputs each layer receives\n",
    "- The total number of trainable and non-trainable parameters of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "\n",
    "print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n",
    "print('Trainable params: {:,}'.format(trainable_count))\n",
    "print('Non-trainable params: {:,}'.format(non_trainable_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Let](https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889):\n",
    "\n",
    "- **i**: input size (2 in this case)\n",
    "- **h**: size of hidden layers (3, 3 here)\n",
    "- **o**: output size (1 in this case)\n",
    "\n",
    "We have:\n",
    " \n",
    " $$\n",
    " \\begin{align*}\n",
    " num\\_params &=& connections\\_between\\_layers + biases\\_in\\_every\\_layer \\\\\n",
    "               &=& (i \\times h + h \\times o) + (h+o) \\\\\n",
    "               &=& (2\\times 3 + 3 \\times 3 + 3 \\times 1) + (3 + 3 + 1) \\\\\n",
    "               &=& (2 \\times 3 + 3) + (3 \\times 3 + 3) + (3 \\times 1 + 1) \\\\\n",
    "               &=& 9 + 12 + 3 \\\\\n",
    "               &=& 25\n",
    " \\end{align*}\n",
    " $$\n",
    " \n",
    " \n",
    " \n",
    "\n",
    "               \n",
    "   input = **Input**((None, 2))\n",
    "   <br>\n",
    "   dense = **Dense**(3)(input)\n",
    "      <br>\n",
    "   dense = **Dense**(3)(dense)\n",
    "    <br>\n",
    "  output = **Dense**(1)(dense)\n",
    "   <br>\n",
    "   model = Model(input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try the model\n",
    "\n",
    "10 samples from the training data and call `model.predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = X_train_normed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_result = model.predict(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be working, and it produces a result of the expected shape and type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Train the model</font>\n",
    "\n",
    "- We use the `fit` method to train the model.\n",
    "- A callback function is applied at given stages of the training procedure. We use it to get a view on internal states and statistics of the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training progress by printing a \n",
    "# single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch_id, logs):\n",
    "          if epoch_id % 100 == 0: \n",
    "             print('')\n",
    "          print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_normed, y_train,    \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    callbacks=[PrintDot()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the model's training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the stats stored in the history object.\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(history.history.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [Target]')\n",
    "    plt.plot(hist['epoch'], hist[keys[1]], label='Train Error')\n",
    "    plt.legend()\n",
    "    plt.ylim([min(hist[keys[1]]) ,max(hist[keys[1]])])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$Target^2$]')\n",
    "    plt.plot(hist['epoch'], hist[keys[2]], label='Train Error')            \n",
    "    plt.legend()\n",
    "    plt.ylim([0,max(hist[keys[2]])])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Evaluate the Model on Test Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae, mse = model.evaluate(X_test_normed, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test data:\")\n",
    "print(f\"\\t loss = {loss} \\n\\t  mae = {mae} \\n\\t  mse = {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test_normed).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(np.mean((y_test - y_test_pred) ** 2))\n",
    "\n",
    "print(f\"The model performance for test set\")\n",
    "print(f\"----------------------------------\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the 45-degree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_test_pred);\n",
    "plt.xlabel('True Values');\n",
    "plt.ylabel('Predictions');\n",
    "plt.axis('equal');\n",
    "plt.axis('square');\n",
    "plt.xlim([0,plt.xlim()[1]]);\n",
    "plt.ylim([0,plt.ylim()[1]]);\n",
    "_ = plt.plot([-100, 100], [-100, 100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test_pred - y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Function Using Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()#.gca(projection='3d');\n",
    "threedee = fig.add_subplot(projection='3d')\n",
    "threedee.scatter(X_test['x'], X_test['y'], y_test_pred);\n",
    "threedee.set_xlabel('x');\n",
    "threedee.set_ylabel('y');\n",
    "threedee.set_zlabel('f(x,y)');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Exercise</font> <a class=\"anchor\" id=\"sec_tf_ex\"></a>\n",
    "\n",
    "- You noticed that the model was underfitting. \n",
    "- Recreate the model by increasing the number of nodes in the two hidden layers till you get acceptable results without overfitting the model.\n",
    "- Also consider changing the batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Useful references</font>\n",
    "\n",
    "- <a href=\"https://www.mygreatlearning.com/blog/what-is-tensorflow-machine-learning-library-explained/\">What is TensorFlow? The Machine Learning Library Explained</a>\n",
    "- <a href=\"https://www.tensorflow.org/tutorials/keras/regression\">Basic regression: Predict fuel efficiency</a>\n",
    "- <a href=\"https://stackabuse.com/tensorflow-2-0-solving-classification-and-regression-problems/\">Tensorflow 2.0: Solving Classification and Regression Problems</a>\n",
    "- <a href=\"https://www.toptal.com/machine-learning/tensorflow-machine-learning-tutorial\">Getting Started with TensorFlow: A Machine Learning Tutorial</a>\n",
    "- <a href=\"https://sebastianraschka.com/faq/docs/tensorflow-vs-scikitlearn.html\">What is the main difference between TensorFlow and scikit-learn?</a>\n",
    "- <a href=\"https://adventuresinmachinelearning.com/python-tensorflow-tutorial/\">Python TensorFlow Tutorial â€“ Build a Neural Network</a>\n",
    "- <a href=\"https://steadforce.com/en/first-steps-tensorflow-part-3/\">A simple neural network with TensorFlow</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
