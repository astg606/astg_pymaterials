{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h1><font color=\"red\">Exploratory Data Analysis with Seaborn</font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Links\n",
    "\n",
    "- <a href=\"https://www.itl.nist.gov/div898/handbook/eda/eda.htm\"> Exploratory Data Analysis </a> (from NIST)\n",
    "- <a href=\"https://www.epa.gov/caddis-vol4/exploratory-data-analysis\"> Exploratory Data Analysis </a> (from EPA)\n",
    "- <a href=\"https://en.wikipedia.org/wiki/Exploratory_data_analysis\">Exploratory Data Analysis</a> (from Wikipedia)\n",
    "- <a href=\"https://www.edureka.co/blog/exploratory-data-analysis-in-python/\">The Why And How Of Exploratory Data Analysis In Python</a>\n",
    "- <a href=\"https://kite.com/blog/python/data-analysis-visualization-python/\"> Exploratory Data Analysis (EDA) and Data Visualization with Python</a>\n",
    "- <a href=\"https://datajournalism.com/read/handbook/one/understanding-data/using-data-visualization-to-find-insights-in-data\">Using Data Visualization to Find Insights in Data</a>\n",
    "- <a href=\"https://www.dataquest.io/blog/kaggle-getting-started/\">Getting Started with Kaggle: House Prices Competition</a>\n",
    "- <a href=\"https://jovian.ai/dhema100/housing-price-prediction\">House Price Prediction</a>\n",
    "- <a href=\"https://chriskhanhtran.github.io/minimal-portfolio/projects/ames-house-price.html\">Predict Ames House Price - Advanced Regression Techniques</a>\n",
    "\n",
    "![fig_cartoon](https://miro.medium.com/max/640/1*9EyGztXIjeQMTjgGWgKGGA.png)\n",
    "Image Source: https://in.pinterest.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> What is Seaborn?</font>\n",
    "- Python package for producing statistical graphics.\n",
    "- It comes equipped with preset styles and color palettes so you can create complex, aesthetically pleasing charts with a few lines of code.\n",
    "- It makes visualization a central part of exploring and understanding data.\n",
    "- Its dataset-oriented plotting functions operate on Pandas DataFrames and Numpy arrays containing whole datasets and internally perform the necessary semantic mapping and statistical aggregation to produce informative plots.\n",
    "- It is built on top of Matplotlib, but it's meant to serve as a complement, not a replacement.. Behind the scenes, Seaborn uses Matplotlib to draw plots.\n",
    "- **Seaborn is an important tool used in Exploratory Data Analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">What is Exploratory Data Analysis?</font>\n",
    "\n",
    "> Exploratory Data Analysis (EDA) is an attitude, a state of flexibility, a willingness to look for those things that we believe are not there, as well as those we believe to be there. -- John W. Tukey \n",
    "\n",
    "EDA is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. \n",
    "- EDA is an important step to first understand the data (identify the trends and patterns within the data, detect outliers or anomalous events, find interesting relations among the variables, points of interesct, etc.) before using them for modeling, machine learning, etc.\n",
    "- By skipping this first exploratory step, data scientists might not be able to immediately understand key issues in the data or be able to guide deeper analysis in the right direction. \n",
    "- The gathering of information on the data are:\n",
    "    + To make sure the data is valid\n",
    "    + To verify that there are no obvious problems.\n",
    "- EDA employs a variety of techniques (mostly graphical) to:\n",
    "    1. Maximize insight into a data set\n",
    "    2. Uncover underlying structure\n",
    "    3. Extract important variables\n",
    "    4. Detect outliers and anomalies\n",
    "    5. Test underlying assumptions\n",
    "    6. Develop parsimonious models, and\n",
    "    7. Determine optimal factor settings.\n",
    "\n",
    "![FIG_AXES](https://blog.camelot-group.com/wp-content/uploads/2019/03/Picture2-580x330.png)\n",
    "Image Source: <a href=\"https://blog.camelot-group.com/2019/03/exploratory-data-analysis-an-important-step-in-data-science/\">Frank Kienle</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Some Graphical Techniques in EDA</font>\n",
    "\n",
    "Graphical techniques employed in EDA are often quite simple, consisting of:\n",
    "\n",
    "- Plotting the raw data:\n",
    "     + <a href=\"https://www.itl.nist.gov/div898/handbook/eda/section3/runseqpl.htm\">Data traces</a>\n",
    "     + <a href=\"https://www.itl.nist.gov/div898/handbook/eda/section3/histogra.htm\">Histograms</a>\n",
    "     + <a href=\"https://www.itl.nist.gov/div898/handbook/eda/section3/bihistog.htm\">Bihistograms</a>\n",
    "     + <a href=\"https://www.itl.nist.gov/div898/handbook/eda/section3/probplot.htm\">Probability plots</a>\n",
    "     + <a href=\"https://www.itl.nist.gov/div898/handbook/eda/section3/lagplot.htm\">Lag plots</a>\n",
    "     + <a href=\"https://www.itl.nist.gov/div898/handbook/eda/section3/blockplo.htm\">Block plots</a>\n",
    "     + <a href=\"https://www.itl.nist.gov/div898/handbook/eda/section3/youdplot.htm\">Youden plots</a>.\n",
    "- Plotting simple statistics\n",
    "     + <a href=\"https://www.itl.nist.gov/div898/handbook/eda/section3/meanplot.htm\">Mean plots</a>\n",
    "     + <a href=\"https://www.itl.nist.gov/div898/handbook/eda/section3/sdplot.htm\">Standard deviation plots</a>\n",
    "     + <a href=\"https://www.itl.nist.gov/div898/handbook/eda/section3/boxplot.htm\">Box plots</a>\n",
    "     + Main effects plots of the raw data.\n",
    "- Positioning such plots so as to maximize our natural pattern-recognition abilities, such as using multiple plots per page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Basic Processes of Finding Insights in Data</font>\n",
    "\n",
    "![fig_insights](https://s3.eu-central-1.amazonaws.com/datajournalismcom/handbooks/Data-Handbook-1/using-data-visualization-to-find-insights-in-data/05-BB.png)\n",
    "Image Source: Gregor Aisch\n",
    "\n",
    "1. **Visualize the Data**\n",
    "     + Use tools to have a graphical representation of the data.\n",
    "2. **Analyze and Interpret**\n",
    "     + What can you learn from the different visualizations?\n",
    "3. **Transform the Data**: \n",
    "     + Take care of missing values\n",
    "     + Deal with outliers\n",
    "     + Do you need to perform any dimension reduction?\n",
    "4. **Document**\n",
    "     + Keep track of all the generated plots and statistics in order to better understand their meanings and their unsefulness in finding insights in the available data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Understanding the Data Types</font>\n",
    "\n",
    "There are two basic types of structured data:\n",
    "\n",
    "* **Numeric Data**\n",
    "    - Continuous: Data can take on any value in an interval.\n",
    "    - Discrete: Data can take only integer values, such as counts.\n",
    "* **Categorical Data**\n",
    "    - Nominal: Numbers are used simply to distinguish between different properties (for instance the marital status or the state name (Arizona, California, etc.). The numbers can only be compared but cannot be ordered.\n",
    "    - Ordinal: Numerical values serve to place categories in some meaningful order (for example, Customer Satisfaction Scales)\n",
    "    \n",
    "![fig_data](https://bioquest.org/numberscount/wp-content/blogs.dir//files//2010/01/Screen-shot-2010-01-04-at-1.12.19-PM.png)\n",
    "Image Source: bioquest.org \n",
    "    \n",
    "The data type you have will determine the EDA graphical method to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Goals</font>\n",
    "\n",
    "We want to use Pandas and Seaborn to:\n",
    "\n",
    "- Explore a **numerical dataset** and create visual distributions\n",
    "- Identify and eliminate outliers (if any)\n",
    "- Uncover correlations between two datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    print(\"Running in Google Colab\")\n",
    "except:\n",
    "    print(\"Not running in Google Colab\")\n",
    "else:\n",
    "    print(\"Installing modules in Google Colab\")\n",
    "    !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">[Obtain the Dataset]( https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)</font>\n",
    "- Contains information about different aspects of residential homes in Ames, Iowa.\n",
    "- There are 1460 observations and 79 feature variables in this dataset. \n",
    "\n",
    "#### [Attribute Information](data/housing_data_description.txt)\n",
    "\n",
    "| Acronym | Description |\n",
    "| --- | --- |\n",
    "| **MSSubClass** |      The type of dwelling involved in the sale |\n",
    "| **MSZoning** |        The general zoning classification of the sale |\n",
    "| **LotFrontage** |     Linear feet of street connected to property |\n",
    "| **LotArea** |         Lot size in square feet |\n",
    "| **Street** |          Type of road access to property   |   \t\n",
    "| **Alley** |           Type of alley access to property\t|\t\n",
    "| **LotShape** |        General shape of property     | \n",
    "| **LandContour** |     Flatness of the property\t\t|\n",
    "| **Utilities** |       Type of utilities available\t|\n",
    "| **LotConfig** |       Lot configuration\t|\n",
    "| **LandSlope** |       Slope of property\t|\n",
    "| **Neighborhood** |    Physical locations within Ames city limits |\n",
    "| **Condition1** |      Proximity to various conditions\t|\n",
    "| **Condition2** |      Proximity to various conditions (if more than one is present) |\n",
    "| **BldgType** |        Type of dwelling |\n",
    "| **HouseStyle** |      Style of dwelling\t|\n",
    "| **OverallQual** |     Rates the overall material and finish of the house\t|\n",
    "| **OverallCond** |     Rates the overall condition of the house\t|\t\n",
    "| **YearBuilt** |       Original construction date |\n",
    "| **YearRemodAdd** |    Remodel date (same as construction date if no remodeling or additions) |\n",
    "| **RoofStyle** |       Type of roof\t|\n",
    "| **RoofMatl** |        Roof material\t|\n",
    "| **Exterior1st** |     Exterior covering on house\t|\n",
    "| **Exterior2nd** |     Exterior covering on house (if more than one material)\t|\n",
    "| **MasVnrType** |      Masonry veneer type |\n",
    "| **MasVnrArea** |     Masonry veneer area in square feet |\n",
    "| **ExterQual** |       Evaluates the quality of the material on the exterior |\n",
    "| **ExterCond** |       Evaluates the present condition of the material on the exterior |\n",
    "| **Foundation** |      Type of foundation\t\t|\n",
    "| **BsmtQual** |        Evaluates the height of the basement\t|\n",
    "| **BsmtCond** |       Evaluates the general condition of the basement\t|\n",
    "| **BsmtExposure** |    Refers to walkout or garden level walls\t|\n",
    "| **BsmtFinType1** |    Rating of basement finished area\t|\n",
    "| **BsmtFinSF1** |      Type 1 finished square feet |\n",
    "| **BsmtFinType2** |    Rating of basement finished area (if multiple types) |\n",
    "| **BsmtFinSF2** |      Type 2 finished square feet |\n",
    "| **BsmtUnfSF** |       Unfinished square feet of basement area |\n",
    "| **TotalBsmtSF** |     Total square feet of basement area |\n",
    "| **Heating** |         Type of heating |\n",
    "| **HeatingQC** |       Heating quality and condition\t|\n",
    "| **CentralAir**  |        First Floor square feet |\n",
    "| **2ndFlrSF** |        Second floor square feet |\n",
    "| **LowQualFinSF** |    Low quality finished square feet (all floors) |\n",
    "| **GrLivArea** |       Above grade (ground) living area square feet |\n",
    "| **BsmtFullBath** |    Basement full bathrooms |\n",
    "| **BsmtHalfBath** |    Basement half bathrooms |\n",
    "| **FullBath** |        Full bathrooms above grade |\n",
    "| **HalfBath** |        Half baths above grade |\n",
    "| **Bedroom** |         Bedrooms above grade (does NOT include basement bedrooms) |\n",
    "| **Kitchen** |         Kitchens above grade |\n",
    "| **KitchenQual** |     Kitchen quality |\n",
    "| **TotRmsAbvGrd** |    Total rooms above grade (does not include bathrooms) |\n",
    "| **Functional** |     Home functionality (Assume typical unless deductions are warranted)\t|\n",
    "| **Fireplaces** |      Number of fireplaces |\n",
    "| **FireplaceQu** |     Fireplace quality |\n",
    "| **GarageType** |     Garage location\t\t|\n",
    "| **GarageYrBlt** |     Year garage was built\t|\t\n",
    "| **GarageFinish** |    Interior finish of the garage\t|\n",
    "| **GarageCars** |      Size of garage in car capacity |\n",
    "| **GarageArea** |      Size of garage in square feet |\n",
    "| **GarageQual** |      Garage quality\t\t|\n",
    "| **GarageCond** |      Garage condition\t|\n",
    "| **PavedDrive** |      Paved driveway\t|\n",
    "| **WoodDeckSF** |      Wood deck area in square feet |\n",
    "| **OpenPorchSF** |     Open porch area in square feet |\n",
    "| **EnclosedPorch** |   Enclosed porch area in square feet |\n",
    "| **3SsnPorch** |      Three season porch area in square feet |\n",
    "| **ScreenPorch** |     Screen porch area in square feet |\n",
    "| **PoolArea** |        Pool area in square feet |\n",
    "| **PoolQC** |         Pool quality\t |\n",
    "| **Fence** |          Fence quality |\n",
    "| **MiscFeature** |     Miscellaneous feature not covered in other categories |\n",
    "| **MiscVal** |         Value of miscellaneous feature |\n",
    "| **MoSold** |          Month Sold (MM) |\n",
    "| **YrSold** |          Year Sold (YYYY)|\n",
    "| **SaleType** |        Type of sale\t\t|\n",
    "| **SaleCondition** |   Condition of sale |\n",
    "\n",
    "**SalePrice** is the property’s sale price in dollars. This is the target variable that you’re trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/astg606/py_materials/refs/heads/master/machine_learning/data/housing_data.csv\"\n",
    "housing_df = pd.read_csv(url)\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Features of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Observations\n",
    "- The target is the `SalePrice` represented in the last column\n",
    "- 37 columns have numerical values\n",
    "- 43 columns have `object` as data type. Are we going to use them for our analysis?\n",
    "- There are many missing values. How are we going to treat them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exploratory Data Analysis</font>\n",
    "\n",
    "- Important step before training the model. \n",
    "- We use statistical analysis and visualizations to understand the relationship of the target variable with other features.\n",
    "\n",
    "![fig_EDA](https://editor.analyticsvidhya.com/uploads/92516EDA-Activities.png)\n",
    "Image Source: analyticsvidhya.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">STEP 1: Description of Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Overview of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This shows us the number of `non-null` cells for each column. \n",
    "- From the data that the following columns have far fewer quantities and may not not be relevant for the model we want to build:\n",
    "   - `MiscFeature` (54)\n",
    "   - `Fence` (281)\n",
    "   - `PoolQC` (7)\n",
    "   - `Alley` (91) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = ['MiscFeature', 'Fence', 'PoolQC', 'Alley']\n",
    "housing_df.drop(dropped_cols, axis=1, inplace=True)\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate the analysis, we are only going to consider columns with numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df_num = housing_df.select_dtypes(include=['float64', 'int64'])\n",
    "housing_df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(housing_df_num.columns)\n",
    "feature_names.pop(-1)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive Statistics\n",
    "- A helpful way to understand characteristics of the data and to get a quick summary of it.\n",
    "- Provide basic statistical computations on the dataset like extreme values, count of data points, maximum value, minimum value, mean, standard deviation, etc.\n",
    "- Any missing value or `NaN` value is automatically skipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df_num.describe(include='all').transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The average sale price of a house in our dataset is close to $\\$180,921$, with most of the values falling within the $\\$129,975$ to $\\$214,000$ range.\n",
    "- The fact the sale price standard deviation is $\\$79442$ indicates a large spread of the sale price and the exisitence of outliers.\n",
    "- There might be many mixing values in `LotFrontage` (Linear feet of street connected to property). Do we need to keep this column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the method `value_counts` to get count of each category in a categorical attributed series of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df_num.SalePrice.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the number of unique elements in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing_df_num.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">STEP 2: Dealing with Missing Data </font>\n",
    "\n",
    "- Missing values in the dataset refer to those fields which are empty or no values assigned to them, these usually occur due to data entry errors, faults that occur with data collection processes.\n",
    "- They need to be handled carefully because they reduce the quality of the data.\n",
    "- They can lead to wrong prediction or classification and can also cause a high bias for any given model being used. \n",
    "- It is a good practice to see if there are any missing values in the data. \n",
    "- The way to handle missing values depends on the nature of our data and the missing values. Techniques may include:\n",
    "     + Drop NULL or missing values\n",
    "     + Fill Missing Values\n",
    "     + Predict Missing values with an ML Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of missing values for each column**\n",
    "\n",
    "- We use the Pandas `isnull` method that takes a scalar or array-like object and indicates whether values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df_num.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also determine the perecentage of missing values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = housing_df_num.isnull().sum().sort_values(ascending=False)\n",
    "percent = (housing_df_num.isnull().sum()/housing_df_num.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, \n",
    "                         keys=['Total', 'Percent'])\n",
    "missing_data.head(housing_df_num.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are we going to do with the missing values in?\n",
    "- `LotFrontage` (259): Linear feet of street connected to property\n",
    "- `GarageYrBlt` (81): Year garage was built\n",
    "- `MasVnrArea` (8): Masonry veneer area in square feet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop NULL or Missing Values\n",
    "- Fastest and easiest step to handle missing values.\n",
    "- Not generally advised for it can deteriorate the quality of the model as it reduces sample size because it works by deleting all other observations where any of the variables is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas `dropna` method can be used to remove missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df_nonan = housing_df_num.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df_nonan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill Missing Values\n",
    "- Most common method of handling missing values.\n",
    "- Missing values are replaced with a test statistic like mean, median or mode of the particular feature the missing value belongs to. \n",
    "- We can use the Pandas `fillna` method to fill missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a missing value of `MasVnrArea` in the data set. Then the below code will fill the missing value with the the mean vale of `MasVnrArea`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = housing_df_num.MasVnrArea.mean()\n",
    "housing_df_num.MasVnrArea = housing_df_num.MasVnrArea.fillna(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df_num.MasVnrArea.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict the Missing Values with a ML Algorithm\n",
    "- Best and most efficient methods for handling missing data.\n",
    "- Depending on the class of data that is missing, one can either use a regression or classification model to predict missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">STEP 3: Handling Outliers </font>\n",
    "\n",
    "- An outlier is something which is separate or different from the crowd.\n",
    "- Outliers can be a result of a mistake during data collection or it can be just an indication of variance in your data. \n",
    "- It is wise to be correct or remove any outlier from the data before calculating summary statistics or deriving insights from the data.\n",
    "- Failing to properly handle outliers might lead to incorrect analysis.\n",
    "- For detecting and handling outliers, we can consider the following techniques:\n",
    "     + Scatterplot\n",
    "     + BoxPlot\n",
    "     + IQR (Inter-Quartile Range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoxPlot\n",
    "- Pictorial representation of distribution of data which shows extreme values, median and quartiles.\n",
    "- Boxplots show robust measures of location and spread as well as providing information about symmetry and outliers.\n",
    "    + The range of the data provides us with a measure of spread and is equal to a value between the smallest data point (min) and the largest one (Max)\n",
    "    + The interquartile range (IQR), which is the range covered by the middle 50% of the data.\n",
    "    + IQR = Q3 – Q1, the difference between the third and first quartiles. The first quartile (Q1) is the value such that one quarter (25%) of the data points fall below it, or the median of the bottom half of the data. The third quartile is the value such that three quarters (75%) of the data points fall below it, or the median of the top half of the data.\n",
    "    + The IQR can be used to detect outliers using the 1.5(IQR) criteria. Outliers are observations that fall below Q1 – 1.5(IQR) or above Q3 + 1.5(IQR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(list(housing_df_nonan.SalePrice)); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,  ax = plt.subplots(len(list(housing_df_nonan.columns)), figsize=(7,50))\n",
    "\n",
    "for i, feature_name in enumerate(list(housing_df_nonan.columns)):\n",
    "    sns.boxplot(y=housing_df_nonan[feature_name], ax=ax[i]);\n",
    "    ax[i].set_xlabel(feature_name, fontsize=8);\n",
    "    #ax[i].set_title(\"Box plot {} \".format(feature_name), fontsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplot\n",
    "- A mathematical diagram using Cartesian coordinates to display values for two variables for a set of data. \n",
    "- The data are displayed as a collection of points, each having the value of one variable determining the position on the horizontal axis and the value of the other variable determining the position on the vertical axis. \n",
    "- **The points that are far from the population can be termed as an outlier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_name in feature_names:\n",
    "    plt.figure(figsize=(5, 4));\n",
    "    ax = sns.scatterplot(x=feature_name, y=\"SalePrice\", data=housing_df_nonan)\n",
    "    ax.set_ylabel('Price', size=12);\n",
    "    ax.set_xlabel(feature_name, size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The prices increase as the values of `1stFlrSF`, `TotalBsmtSF`, `GrLiveArea` and `GarageArea` increase linearly. \n",
    "- There are outliers in the `SalePrice` data.\n",
    "- We can use the **seaborn** `lmplot` function to clearly see the relationship between `TotalBsmtSF` and `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'TotalBsmtSF', y = 'SalePrice', data = housing_df_nonan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IQR\n",
    "- The interquartile range (IQR) is a measure of statistical dispersion, being equal to the difference between 75th and 25th percentiles, or between upper and lower quartiles.\n",
    "- **IQR = Q3 - Q1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = housing_df_nonan.quantile(0.25)\n",
    "Q3 = housing_df_nonan.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have IQR scores below code will remove all the outliers in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_outlier_IQR = housing_df_nonan[~((housing_df_nonan < (Q1 - 1.5 * IQR)) | \n",
    "                                 (housing_df_nonan > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "housing_outlier_IQR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Understanding Relationships and New Insights Through Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram\n",
    "- Great tool for quickly assessing a probability distribution that is easy for interpretation.\n",
    "- We use the Seaborn `distplot` function that shows a histogram with a line on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (10, 8)});\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "ax = sns.distplot(housing_df_nonan['SalePrice'], kde=False)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "ax = sns.distplot(housing_df_nonan['SalePrice'], kde=True)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "ax = sns.distplot(housing_df_nonan['SalePrice'], rug=False, hist=False, vertical=True)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "ax = sns.kdeplot(housing_df_nonan['SalePrice'], shade=True, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "sns.distplot(housing_df_nonan['SalePrice'], fit=stats.norm);\n",
    "plt.figure(figsize=(8, 6));\n",
    "res = stats.probplot(housing_df_nonan['SalePrice'], plot=plt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can see that the values of PRICE is normally distributed with some of the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot (histograms and the estimated PDF) the univariate distribution of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,  ax = plt.subplots(len(list(housing_df_nonan.columns)), figsize=(12,46))\n",
    "\n",
    "for i, feature_name in enumerate(list(housing_df_nonan.columns)):\n",
    "    sns.distplot(housing_df_nonan[feature_name], hist=True, ax=ax[i]);\n",
    "    ax[i].set_ylabel('Count', fontsize=8);\n",
    "    ax[i].set_xlabel(\" {}\".format(feature_name), fontsize=8);\n",
    "       #ax[i].set_title(\"Freq dist \"+feature_name, fontsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The bivariate distribution plots help us to study the relationship between two variables by analyzing the scatter plot.\n",
    "- We can use the `pairplot` function to plot multiple pairwise bivariate distributions in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(housing_df_nonan);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select a few features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "for i in range(0, len(housing_df_nonan.columns), n):\n",
    "    sns.pairplot(data=housing_df_nonan,\n",
    "                x_vars=housing_df_nonan.columns[i:i+n],\n",
    "                y_vars=['SalePrice']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `seaborn.kdeplot()` function is used to plot the data against a single/univariate variable. \n",
    "- It represents the probability distribution of the data values as the area under the plotted curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6)); # define plot area\n",
    "ax = fig.gca(); # define axis \n",
    "sns.set_style(\"whitegrid\");\n",
    "sns.kdeplot(data=housing_df_nonan, \n",
    "            x='TotalBsmtSF',\n",
    "            y='SalePrice', \n",
    "            ax = ax, \n",
    "            cmap=\"Accent\", \n",
    "            fill=True,\n",
    "           )\n",
    "\n",
    "ax.set_title('KDE plot of TotalBsmtSF and SalePrice'); # Give the plot a main title\n",
    "ax.set_xlabel('TotalBsmtSF');  # Set text for the x axis\n",
    "ax.set_ylabel('SalePrice'); # Set text for y axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap: Two-Dimensional Graphical Representation\n",
    "- Represent the individual values that are contained in a matrix as colors.\n",
    "- Create a correlation matrix that measures the linear relationships between the variables.\n",
    "- The pairs which are highly correlated represent the same variance of the dataset thus we can further analyze them to understand which attribute among the pairs are most significant for building the model.\n",
    "- A number on the map indicates a strong inverse relationship, no relationship, and a strong direct relationship, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22, 11));\n",
    "correlation_matrix = housing_df_nonan.corr().round(1);\n",
    "sns.heatmap(correlation_matrix, cmap=\"YlGnBu\", annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may choose to select only correlations that verify specific conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22, 11));\n",
    "sns.heatmap(correlation_matrix[(correlation_matrix >= 0.5) | (correlation_matrix <= -0.4)], \n",
    "            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
    "            annot=True, annot_kws={\"size\": 8}, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `OverallQual` and `GrLivArea` have a strong positive correlation with `SalePrice` (0.8 and 0.7 respectively).\n",
    "- The features `GrLivArea` & `2ndFlrSF`, `BsmtFullBath` & `BsmtFinSF1` and `TotRmsAbvGrrd` & `BedroomAbvGrd` have a correlation of at least 0.7. These feature pairs are strongly correlated to each other. This can affect the model. \n",
    "- The predictor variables such as `1stFlrSF`, `TotalBsmtSF`, `GarageArea`, `GarageCars`, etc., have good positive correlation with the target. Increase in any of them leads to the increase in the price of the house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can also calculate the correlation between individual features and SalePrice:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "individual_features_df = []\n",
    "for i in range(0, len(housing_df_nonan.columns) - 1): # -1 because the last column is PRICE\n",
    "    tmpDf = housing_df_nonan[[housing_df_nonan.columns[i], 'SalePrice']]\n",
    "    #tmpDf = tmpDf[tmpDf[housing_df.columns[i]] != 0] # remove values that are zero\n",
    "    individual_features_df.append(tmpDf)\n",
    "\n",
    "all_correlations = {feature.columns[0]: feature.corr()['SalePrice'][0] for feature in individual_features_df}\n",
    "all_correlations = sorted(all_correlations.items(), key=operator.itemgetter(1))\n",
    "for (key, value) in all_correlations:\n",
    "    print(\"{:>15}: {:>15}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can select which feautures you might consider for your model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_features_list = [(key, value) for key, value in all_correlations if abs(value) >= 0.5]\n",
    "n = len(golden_features_list)\n",
    "print(\"There is {} strongly correlated values with PRICE:\".format(n))\n",
    "for var in golden_features_list:\n",
    "    print(f\"\\t {var[0]}: \\t {var[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `corr()` function to determine correlation between the sale price and the feature variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = housing_df_nonan.corr()['SalePrice']\n",
    "print(corr.sort_values(ascending=False)[1:13], '\\n')\n",
    "print(corr.sort_values(ascending=False)[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Interpreting the correlation values</font>\n",
    "\n",
    "__The correlation matrix attempts to identify only possible linear correlations among variables__. It measures linear relationships.\n",
    "\n",
    "- A strong positive correlation (close to 1) means that if one variable increases, the other also tends to increase. \n",
    "- A strong negative correlation (close to -1) means that if one variable increases, the other tends to decrease. \n",
    "- A value near 0 indicates that the variables are likely not linearly related.\n",
    "\n",
    "Identifying highly correlated relationships can help in reducing redundancy and improving model performance. We might consider removing one of the correlated features or creating a new feature based on the correlation. \n",
    "\n",
    "It is possible to have non-linear correlations that are not shown in the correlation matrix. If the relationship between variables is non-linear, other techniques like scatter plots or calculating non-linear correlations might be needed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Use Pandas Profiling</font>\n",
    "- Simple and fast EDA of a Pandas dataframe\n",
    "- Automatically perform operations such as:\n",
    "     + boxplot and histogram for a continous variable\n",
    "     + Measure missing values\n",
    "     + Calculate frequency if it's categorical variable\n",
    "- Generate an interactive HTML report containing statistical data on each feature.\n",
    "\n",
    "![fig_prof](https://skappal7.files.wordpress.com/2019/07/eda-cycle.jpg?w=748)\n",
    "Image Source: Sunil Kappal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "pandas_profiling.ProfileReport(housing_df_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Other Seaborn Features</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Identifying Statistical Relationships</font>\n",
    "\n",
    "- Statistical analysis is a process of understanding how variables in a dataset relate to each other and how those relationships depend on other variables. \n",
    "- When data are visualized properly, the human visual system can see trends and patterns that indicate a relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = sns.load_dataset(\"mpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `scatterplot`\n",
    "\n",
    "- The relationship between `x` and `y` can be shown for different subsets of the data using the `hue`, `size`, and `style` parameters. \n",
    "- These parameters control what visual semantics are used to identify the different subsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()  \n",
    "\n",
    "sns.scatterplot(x=\"horsepower\", y=\"mpg\", \n",
    "                hue=\"origin\", size=\"weight\",  \n",
    "                sizes=(400, 40), palette=\"muted\",  \n",
    "                data=mpg);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `lineplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"horsepower\", y=\"mpg\", \n",
    "            hue=\"origin\", palette=\"muted\",  \n",
    "            data=mpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `relplot`\n",
    "\n",
    "- Designed to visualize many different statistical relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")  \n",
    "\n",
    "# Plot miles per gallon against horsepower with other semantics  \n",
    "sns.relplot(x=\"horsepower\", y=\"mpg\", \n",
    "            hue=\"origin\", size=\"weight\",  \n",
    "            sizes=(400, 40), alpha=.5, palette=\"muted\",  \n",
    "            height=6, data=mpg)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Manipulating Categorical Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `stripplot`\n",
    "\n",
    "- Draw a scatterplot where one variable is categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Melt\" the dataset to \"long-form\" or \"tidy\" representation  \n",
    "iris_m = pd.melt(iris, \"species\", var_name=\"measurement\")  \n",
    "  \n",
    "# Initialize the figure  \n",
    "f, ax = plt.subplots()  \n",
    "sns.despine(bottom=True, left=True)  \n",
    "  \n",
    "# Show each observation with a scatterplot  \n",
    "sns.stripplot(x=\"measurement\", y=\"value\", hue=\"species\",  \n",
    "              data=iris_m, dodge=True, jitter=True,  \n",
    "              alpha=.25, zorder=1)  \n",
    "  \n",
    "# Show the conditional means  \n",
    "sns.pointplot(x=\"measurement\", y=\"value\", hue=\"species\",  \n",
    "              data=iris_m, dodge=.532, join=False, palette=\"dark\",  \n",
    "              markers=\"d\", scale=.75, ci=None)  \n",
    "  \n",
    "# Improve the legend   \n",
    "handles, labels = ax.get_legend_handles_labels()  \n",
    "ax.legend(handles[3:], labels[3:], title=\"species\",  \n",
    "          handletextpad=0, columnspacing=1,  \n",
    "          loc=\"lower right\", ncol=3, frameon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `swarmplot`\n",
    "\n",
    "- Draw a categorical scatterplot with non-overlapping points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", palette=\"muted\") \n",
    "\n",
    "# \"Melt\" the dataset to \"long-form\" or \"tidy\" representation  \n",
    "iris_m = pd.melt(iris, \"species\", var_name=\"measurement\")  \n",
    "  \n",
    "# Draw a categorical scatterplot to show each observation  \n",
    "sns.swarmplot(x=\"value\", y=\"measurement\", hue=\"species\",  \n",
    "              palette=[\"r\", \"c\", \"y\"], data=iris_m); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `regplot`\n",
    "\n",
    "- Plot data and a linear regression model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.regplot(x=\"sepal_length\", y=\"sepal_width\",  \n",
    "                 data=iris) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `lmplot`\n",
    "\n",
    "- Enhance a scatterplot to include a linear regression model (and its uncertainty). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sepal with as a function of sepal_length across days  \n",
    "g = sns.lmplot(x=\"sepal_length\", y=\"sepal_width\", hue=\"species\",  \n",
    "               truncate=True, height=5, data=iris)  \n",
    "  \n",
    "# Use more informative axis labels than are provided by default  \n",
    "g.set_axis_labels(\"Sepal length (mm)\", \"Sepal width (mm)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `jointplot`\n",
    "- Draw a plot of two variables with bivariate and univariate graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.jointplot(x=\"sepal_length\", y=\"sepal_width\", data=iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.jointplot(x=\"sepal_length\", y=\"sepal_width\", data=iris, \n",
    "                  kind=\"reg\", space=0, color=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `boxplot`\n",
    "- Draw a box plot to show distributions with respect to categories.\n",
    "- A box plot shows the distribution of quantitative data in a way that facilitates comparisons between variables or across levels of a categorical variable. \n",
    "- The box shows the quartiles of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets = sns.load_dataset(\"planets\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")  \n",
    "  \n",
    "# Initialize the figure with a logarithmic x axis  \n",
    "f, ax = plt.subplots(figsize=(7, 6))  \n",
    "ax.set_xscale(\"log\")   \n",
    "  \n",
    "# Plot the orbital period with horizontal boxes  \n",
    "sns.boxplot(x=\"distance\", y=\"method\", data=planets,  \n",
    "            whis=\"range\", palette=\"vlag\")  \n",
    "  \n",
    "# Tweak the visual presentation  \n",
    "ax.xaxis.grid(True)  \n",
    "ax.set(ylabel=\"\")  \n",
    "sns.despine(trim=True, left=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `violinplot`\n",
    "- Draw a combination of boxplot and kernel density estimate.\n",
    "- It shows the distribution of quantitative data across several levels of one (or more) categorical variables such that those distributions can be compared. \n",
    "- This can be an effective and attractive way to show multiple distributions of data at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=planets[\"distance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `boxenplot`\n",
    "- Draw an enhanced box plot for larger datasets.\n",
    "- This style of plot was originally named a “letter value” plot because it shows a large number of quantiles that are defined as “letter values”.\n",
    "- It is similar to a box plot in plotting a nonparametric representation of a distribution in which all features correspond to actual observations. \n",
    "- By plotting more quantiles, it provides more information about the shape of the distribution, particularly in the tails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxenplot(x=planets[\"distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13, 7))\n",
    "\n",
    "sns.boxenplot(x=\"method\", y=\"distance\", data=planets) \n",
    "# Finalize the figure  \n",
    "ax.set(ylim=(-10, 9000))  \n",
    "sns.despine(left=True, bottom=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pointplot`\n",
    "- Show point estimates and confidence intervals using scatter plot glyphs.\n",
    "- A point plot represents an estimate of central tendency for a numeric variable by the position of scatter plot points and provides some indication of the uncertainty around that estimate using error bars.\n",
    "- Point plots can be more useful than bar plots for focusing comparisons between different levels of one or more categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pointplot(x=\"class\", y=\"survived\", hue=\"who\", \n",
    "                   data=titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `countplot`\n",
    "- Show the counts of observations in each categorical bin using bars.\n",
    "- A count plot can be thought of as a histogram across a categorical, instead of quantitative, variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"class\", hue=\"who\", data=titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"class\", hue=\"who\", col=\"survived\",\n",
    "                data=titanic, kind=\"count\",\n",
    "                height=4, aspect=.7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `barplot`\n",
    "- Show point estimates and confidence intervals as rectangular bars.\n",
    "- A bar plot represents an estimate of central tendency for a numeric variable with the height of each rectangle and provides some indication of the uncertainty around that estimate using error bars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"class\", y=\"survived\", data=titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"class\", y=\"survived\", hue=\"who\", data=titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise</font>\n",
    "\n",
    "Visit the <a href=\"https://archive.ics.uci.edu/ml/datasets.php\">UCI Machine Learning Repository</a> or the <a href=\"http://www.ee.columbia.edu/~cylin/course/bigdata/getdatasetinfo.html\">Columbia University Big Data Analytics</a> to select a dataset you want to perform EDA on.\n",
    "\n",
    "An alternative is to Perform EDA on the automobile price dataset which description is available at the <a href=\"https://archive.ics.uci.edu/ml/datasets/automobile\">UCI Machine Learning Repository</a>.\n",
    "- You may want to follow the link: <a href=\"https://www.kaggle.com/toramky/eda-for-automobile-dataset\">kaggle.com</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/StephenElston/ExploringDataWithPython/master/PlottingWithPytonTools/Automobile%20price%20data.csv'\n",
    "import pandas as pd\n",
    "automobile = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
