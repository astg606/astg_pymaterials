{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhdP-jQAdkXV"
   },
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "<h1>\n",
    "<font color=\"red\"> \n",
    "Overview of Reading and Writing Files in Python\n",
    "</font> \n",
    "</h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">Introduction</font>\n",
    "\n",
    "\n",
    "- Files are named locations on disk to store related information.\n",
    "- A file can be seen as a contiguous set of bytes used to store data.\n",
    "- Data in a file are organized in a specific format and can be anything as simple as a text file or as complicated as a program executable. \n",
    "\n",
    "Typically, a file operation takes place in the following order:\n",
    "\n",
    "1. Open a file\n",
    "2. Read or write (perform operation)\n",
    "3. Close the file\n",
    "\n",
    "Before attempting to open an existing file be ensure that it exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">Manipulating ASCII Files</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ra57zfMzggrh"
   },
   "source": [
    "### Create a file\n",
    "\n",
    "To create a file, you need to use the `open()` function that takes two arguments: the file name and the mode.\n",
    "\n",
    "First formulation:\n",
    "\n",
    "```python\n",
    "f = open(file_name, 'w')\n",
    "f.write(data) \n",
    "f.close()\n",
    "```\n",
    "\n",
    "In this second formulation, the file is automatically closed:\n",
    "\n",
    "```python\n",
    "with open(file_name, 'w') as f:\n",
    "     f.write(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = [105.5, 67.25, 13.75, 86.20, 45.80, 150.5, -37.2]\n",
    "lats = [-22.72, -43.56, 30.41, 75.57, 11.60, 17.3, 32.98]\n",
    "num_lats = len(lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'sample_text_file.txt'\n",
    "\n",
    "with open(file_name, 'w') as f:\n",
    "     for a, b in zip(lons,lats):\n",
    "         f.write('{} \\t {} \\n'.format(a,b)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file\n",
    "\n",
    "First formulation:\n",
    "\n",
    "```python\n",
    "f = open(file_name, 'r')\n",
    "data = f.read() \n",
    "f.close()\n",
    "```\n",
    "\n",
    "Second formulation:\n",
    "\n",
    "```python\n",
    "with open(file_name, 'r') as f:\n",
    "     data = f.read() \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'r') as f:\n",
    "     lines = f.readlines()\n",
    "        \n",
    "#print(lines)\n",
    "for line in lines:\n",
    "    a,b = line.split()\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\"> Manipulating Binary Files</font>\n",
    "\n",
    "- We can use the same `open` function with the `'rb'` or `'wb'` mode to manipulate binary files.\n",
    "- The <a href=\"https://docs.python.org/3/library/struct.html\">struct</a> module in Python is used to convert native Python data types such as strings and numbers into a string of bytes and vice versa. \n",
    "- We can use the `struct` module to parse binary files of data stored in C structs in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'sample_text_file.bin'\n",
    "\n",
    "import struct\n",
    "with open(file_name, 'wb') as f:\n",
    "     for i in range(len(lons)):\n",
    "         f.write(struct.pack('d', lons[i]))\n",
    "         f.write(struct.pack('d', lats[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya = []\n",
    "with open(file_name, 'rb') as fid:\n",
    "     i = 0\n",
    "     nBytes = struct.calcsize('d')\n",
    "     while True:\n",
    "           rec = fid.read(nBytes)\n",
    "           if len(rec) != nBytes:\n",
    "              break\n",
    "           (y,) = struct.unpack('d', rec)\n",
    "           ya.append(y)\n",
    "           i += 1\n",
    "\n",
    "import numpy as np\n",
    "ya = np.array(ya)\n",
    "ya.shape = (num_lats,2)\n",
    "print(ya)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manipulating `JPEG` Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = \"https://raw.githubusercontent.com/astg606/py_materials/master/input_output/\"\n",
    "file_name = \"cat.jpg\"\n",
    "urllib.request.urlretrieve(url+file_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cat.jpg', 'rb') as f:\n",
    "    data = f.readline()\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#':'.join(x.encode('hex') for x in data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hex dump is useful for debugging. In a hex dump, each byte (8-bits) is represented as a two-digit hexadecimal number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cat.jpg', 'rb') as f:\n",
    "    data = f.read()\n",
    " \n",
    "    if data.startswith(b'\\xff\\xd8'):\n",
    "        info = 'This is a jpeg file (%d bytes long)'\n",
    "    else:\n",
    "        info = 'This is a random file (%d bytes long)'\n",
    "\n",
    "    print (info % len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "jpgfile = Image.open(\"cat.jpg\")\n",
    "\n",
    "print(jpgfile.bits, jpgfile.size, jpgfile.format, jpgfile.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#jpgfile.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "kitty = Image(filename = 'cat.jpg')\n",
    "kitty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\"> Manipulating CSV Files</font>\n",
    "\n",
    "- A CSV (Comma Separated Values) file is a text file that uses specific structuring to arrange tabular data.\n",
    "- CSV files use a comma (or space, or tabs) to separate each specific data value. \n",
    "- They are a convenient way to manipulate data from spreadsheets and databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the CSV Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'sample_text_file.csv'\n",
    "\n",
    "with open(file_name, 'w') as f:\n",
    "     for a, b in zip(lons,lats):\n",
    "         f.write('{}, {}\\n'.format(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "cr = csv.reader(open(file_name))\n",
    "\n",
    "for line in cr:\n",
    "    print(line)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsvzMjiYm8Qh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "coords = np.loadtxt(file_name, delimiter=',', unpack=True)\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(file_name, names=[\"lons\", \"lats\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also read remote files with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lZx8nO85l1wu"
   },
   "source": [
    "# <font color=\"blue\"> Manipulating JSON Files</font>\n",
    "\n",
    "* JSON (JavaScript Object Notation) is a popular data format used for representing structured data. \n",
    "* It is a text format that is language independent and can be used in Python, Perl among other languages. \n",
    "* JSON format is used for data communications between servers and web applications.\n",
    "* It is built on two structures:\n",
    "\n",
    "     - A collection of name/value pairs. This is realized as an object, record, dictionary, hash table, keyed list, or associative array.\n",
    "     - An ordered list of values. This is realized as an array, vector, list, or sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('http://data.nba.net/prod/v2/2018/teams.json') as response:\n",
    "     source = response.read()\n",
    "     data = json.loads(source)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_teams = [team for team in data['league']['standard'] if team['isNBAFranchise']]\n",
    "print(nba_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nba_teams.json', 'w') as f:\n",
    "     json.dump(nba_teams, f, indent = 4, sort_keys = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat nba_teams.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\"> Manipulating Excel Files</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create URL to Excel file (alternatively this can be a filepath)\n",
    "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/data.xlsx'\n",
    "\n",
    "df = pd.read_excel(url)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\"> Manipualting Scientific Data Format Files</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> NetCDF Files </font>\n",
    "\n",
    "- NetCDF (network Common Data Form) is a file format for storing multidimensional scientific data (variables) such as temperature, humidity, pressure, wind speed, and direction.\n",
    "- A NetCDF file contains a header which describes the layout of the rest of the file, in particular the data arrays, as well as arbitrary file metadata in the form of name/value attributes. \n",
    "- The format is platform independent.\n",
    "- The data are stored in a fashion that allows efficient subsetting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UM0PjOROHILD"
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "#from numpy.random import uniform\n",
    "\n",
    "#------------------\n",
    "# Creating the file\n",
    "#------------------\n",
    "with Dataset('my_file.nc4', mode='w', format='NETCDF4') as ncFid:\n",
    "     print(ncFid.file_format)\n",
    "\n",
    "     #------------------------\n",
    "     # Defining the dimensions\n",
    "     #------------------------\n",
    "     time = ncFid.createDimension('time', None)\n",
    "     lev  = ncFid.createDimension('lev', 72)\n",
    "     lat  = ncFid.createDimension('lat', 91)\n",
    "     lon  = ncFid.createDimension('lon', 144)\n",
    "\n",
    "     print(ncFid.dimensions)\n",
    "\n",
    "     #------------------------------------------\n",
    "     # Creating variables and Setting attributes\n",
    "     #------------------------------------------\n",
    "     times = ncFid.createVariable('time','f8',('time',))\n",
    "     times.units = 'hours since 0001-01-01 00:00:00.0'\n",
    "     times.calendar = 'gregorian'\n",
    "\n",
    "     levels = ncFid.createVariable('lev','i4',('lev',))\n",
    "     levels.units = 'hPa'\n",
    "\n",
    "     latitudes = ncFid.createVariable('lat','f4',('lat',))\n",
    "     latitudes.units = 'degrees north'\n",
    "\n",
    "     longitudes = ncFid.createVariable('lon','f4',('lon',))\n",
    "     longitudes.units = 'degrees east'\n",
    "\n",
    "     temp = ncFid.createVariable('temp','f4',('time','lev','lat','lon',))\n",
    "     temp.units = 'K'\n",
    "\n",
    "     ncFid.description = 'Sample netCDF file'\n",
    "     ncFid.source      = 'netCDF4 python tutorial'\n",
    "     ncFid.history     = 'Created on June 18, 2019'\n",
    "\n",
    "     #---------------\n",
    "     # Setting values\n",
    "     #---------------\n",
    "     latitudes[:]  =  np.arange(-90,91,2.0)\n",
    "     longitudes[:] =  np.arange(-180,180,2.5)\n",
    "     levels[:]     =  np.arange(0,72,1)\n",
    "     temp[0:5,:,:,:] = 300*np.random.uniform(\\\n",
    "         size=(5,levels.size,latitudes.size, longitudes.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Dataset('my_file.nc4', mode='r') as ncFid:\n",
    "     temp = ncFid.variables['temp'][:]\n",
    "\n",
    "print(temp.shape)\n",
    "print(np.mean(temp), np.std(temp), np.max(temp), np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "cs = plt.contourf(temp[0,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> HDF5 Files </font>\n",
    "\n",
    "- The Hierarchical Data Format version 5 (HDF5), is an open source file format that supports large, complex, heterogeneous data. \n",
    "- HDF5 uses a \"file directory\" like structure that allows you to organize data within the file in many different structured ways, as you might do with files on your computer.\n",
    "- The HDF5 format also allows for embedding of metadata making it self-describing.\n",
    "\n",
    "![hdf5](https://www.neonscience.org/sites/default/files/images/HDF5/hdf5_structure4.jpg)\n",
    "Image Source: https://www.neonscience.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVgxsmdTpr53"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# gzip compression flag\n",
    "comp = 6\n",
    "\n",
    "#------------------\n",
    "# Creating the file\n",
    "#------------------\n",
    "with h5py.File('my_file.h5', 'w') as hFid:\n",
    "     #----------------\n",
    "     # File attributes\n",
    "     #----------------\n",
    "     hFid.attrs['source']      = 'H5Py Tutorial'\n",
    "     hFid.attrs['history']     = 'Created on June 18, 2019'\n",
    "     hFid.attrs['description'] = 'Sample HDF5 file'\n",
    "\n",
    "     #------------------------\n",
    "     # Defining the dimensions\n",
    "     #------------------------\n",
    "     lat = np.arange(-90,91,2.0)\n",
    "     dset = hFid.require_dataset('lat', \n",
    "                                 shape=lat.shape, \n",
    "                                 dtype=np.float32, compression=comp)\n",
    "     dset[...] = lat\n",
    "     dset.attrs['name'] = 'latitude'\n",
    "     dset.attrs['units'] = 'degrees north'\n",
    "\n",
    "     lon = np.arange(-180,180,2.5)\n",
    "     dset = hFid.require_dataset('lon', shape=lon.shape, dtype=np.float32, compression=comp)\n",
    "     dset[...] = lon\n",
    "     dset.attrs['name'] = 'longitude'\n",
    "     dset.attrs['units'] = 'degrees east'\n",
    "\n",
    "     lev = np.arange(0,72,1)\n",
    "     dset = hFid.require_dataset('lev', shape=lev.shape, dtype=np.int, compression=comp)\n",
    "     dset[...] = lev\n",
    "     dset.attrs['name'] = 'vertical levels'\n",
    "     dset.attrs['units'] = 'hPa'\n",
    "\n",
    "     time = np.arange(0,5,1)\n",
    "     dset = hFid.require_dataset('time', shape=time.shape, maxshape=(None), dtype=np.float32, compression=comp)\n",
    "     dset[...] = time\n",
    "     dset.attrs['name'] = 'time'\n",
    "     dset.attrs['units'] = 'hours since 2013-01-01 00:00:00.0'\n",
    "     dset.attrs['calendar'] = 'gregorian'\n",
    "\n",
    "     #------------------------------------------\n",
    "     # Creating variables and Setting attributes\n",
    "     #------------------------------------------\n",
    "     arr = np.zeros((5,lev.size,lat.size,lon.size))\n",
    "     arr[0:5,:,:,:] = 300*np.random.uniform(\n",
    "                    size=(5,lev.size,lat.size,lon.size))\n",
    "     dset = hFid.require_dataset('temp', shape=arr.shape, \n",
    "                                 dtype=np.float32, compression=comp)\n",
    "     dset[...] = arr\n",
    "     dset.attrs['name'] = 'temperature'\n",
    "     dset.attrs['units'] = 'K'\n",
    "\n",
    "     #---------------\n",
    "     # Creating Groups \n",
    "     #---------------\n",
    "     gpData2D = hFid.create_group('2D_Data')\n",
    "     sgpLand  = gpData2D.create_group('2D_Land')\n",
    "     sgpSea   = gpData2D.create_group('2D_Sea')\n",
    "\n",
    "     gpData3D = hFid.create_group('3D_Data')\n",
    "\n",
    "     #----------------------\n",
    "     # Write data in a group\n",
    "     #----------------------\n",
    "     temp = gpData3D.create_dataset('temp', data=arr)\n",
    "     temp.attrs['name'] = 'temperature'\n",
    "     temp.attrs['units'] = 'K'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('my_file.h5', 'r') as hFid:\n",
    "     print(hFid.keys())\n",
    "\n",
    "     lev  = hFid['lev'].value\n",
    "     lat  = hFid['lat'].value\n",
    "     lon  = hFid['lon'].value\n",
    "     time = hFid['time'].value\n",
    "\n",
    "     temp1 = hFid['temp'].value\n",
    "     print(temp1[0,0,0,0], temp1[4,6,7,15])\n",
    "\n",
    "     temp2 = hFid['3D_Data']['temp'].value\n",
    "     print(temp2[0,0,0,0], temp2[4,6,7,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pGGxrwWEqbA0"
   },
   "source": [
    "In addition to this hierarchical raw data format for Earth Science data, there is also GIS application data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> Shapefile Files </font>\n",
    "\n",
    "The shapefile format:\n",
    "* Is a digital vector storage format for storing geometric location and associated attribute information.\n",
    "* Geographic features in a shapefile can be represented by points, lines, or polygons (areas).\n",
    "* Is non-topological. It does not maintain spatial relationship information such as connectivity, adjacency, and area definition.\n",
    "* Because the structure of points, lines, and polygons are different, each individual shapefile can only contain one vector type (all points, all lines or all polygons). You will not find a mixture of point, line and polygon objects in a single shapefile.\n",
    "* Was introduced with ArcView GIS version 2 in the early 1990s.\n",
    "\n",
    "#### Representation of the geographic features of a shapefile\n",
    "\n",
    "![features](https://www.earthdatascience.org/images/courses/earth-analytics/spatial-data/points-lines-polygons-vector-data-types.png)\n",
    "Image Source: Colin Williams (NEON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "\n",
    "# Get the file name from the natural_earth database\n",
    "shpfilename = shpreader.natural_earth(resolution='110m',\n",
    "                                      category='cultural',\n",
    "                                      name='admin_0_countries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and get countries \n",
    "reader = shpreader.Reader(shpfilename)\n",
    "countries = reader.records()\n",
    "next_country = next(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(next_country.attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print features of a country\n",
    "for key in next_country.attributes:\n",
    "    print(\"{:} --> {:}\".format(key,next_country.attributes[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define a function which returns the population given the country\n",
    "population = lambda country: country.attributes['POP_EST']\n",
    "\n",
    "# Countries sorted py population\n",
    "countries_sorted_by_population = sorted(reader.records(), \\\n",
    "                                         key=population)\n",
    "\n",
    "num_countries = len(countries_sorted_by_population)\n",
    "n = 5\n",
    "\n",
    "# Get the first 5 most populated\n",
    "most_populated = countries_sorted_by_population[num_countries-n:]\n",
    "\n",
    "print(\"Most Populated Countries\")\n",
    "for nation in most_populated:\n",
    "    print(\"   {:>} --> {:>}\".format(nation.attributes['NAME_LONG'], \\\n",
    "                               nation.attributes['POP_EST']))\n",
    "\n",
    "# Get the 5 least populated\n",
    "least_populated = countries_sorted_by_population[:n]\n",
    "\n",
    "print()\n",
    "print(\"Least Populated Countries\")\n",
    "for nation in least_populated:\n",
    "    print(\"   {:>} --> {:>}\".format(nation.attributes['NAME_LONG'], \\\n",
    "                               nation.attributes['POP_EST']))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "\n",
    "# Select the map projection\n",
    "#----------------------\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    " \n",
    "# Select the area of interest\n",
    "#-----------------------\n",
    "ax.set_extent([-150, 60, -25, 60])\n",
    " \n",
    "for country in countries:\n",
    "    if country.attributes['ADM0_A3'] == 'USA':\n",
    "        ax.add_geometries(country.geometry, ccrs.PlateCarree(), \\\n",
    "                          facecolor=(0, 0, 1),\n",
    "                          label=country.attributes['ADM0_A3'])\n",
    "    else:\n",
    "        ax.add_geometries(country.geometry, \\\n",
    "                          ccrs.PlateCarree(), \\\n",
    "                          facecolor=(0, 1, 0), \\\n",
    "                          label=country.attributes['ADM0_A3'])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSZCyMEbqBLk"
   },
   "source": [
    "# <font color=\"blue\"> Manipulating FITS Files </font>\n",
    "\n",
    "- FITS (Flexible Image Transport System) is a portable file standard widely used in the astronomy community to store images and tables.\n",
    "- Most FITS files when opened from a web browser shows a header of ASCII (human readible) giving the details or descriptions of the data contained within the file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "url = 'http://data.astropy.org/tutorials/FITS-images/HorseHead.fits'\n",
    "fits_image = fits.open(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_image.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_image[0].header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = fits_image[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(image_data))\n",
    "print(image_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1TFR0o0M-Cn9"
   },
   "source": [
    "**Viewing the Image Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nooB3qYG-j5Z"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from astropy.visualization import astropy_mpl_style\n",
    "plt.style.use(astropy_mpl_style)\n",
    "\n",
    "plt.imshow(image_data, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJemDmy2-o31"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print('Min:   ', np.min(image_data))\n",
    "print('Max:   ', np.max(image_data))\n",
    "print('Mean:  ', np.mean(image_data))\n",
    "print('Stdev: ', np.std(image_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0BxpYzmsqZhq"
   },
   "source": [
    "# <font color=\"blue\"> Manipulating Audio Files</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Playing Audio Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://tinyurl.com/yx3k5kw5\", \"beat.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpleaudio as sa\n",
    "\n",
    "file_name = 'beat.wav'\n",
    "wave_obj = sa.WaveObject.from_wave_file(file_name)\n",
    "play_obj = wave_obj.play()\n",
    "play_obj.wait_done()  # Wait until sound has finished playing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze the Audio File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate, data = wavfile.read(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[:4*samplerate]) #plot first 4 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft,fftfreq\n",
    "\n",
    "datafft = fft(data)\n",
    "#Get the absolute value of real and complex component:\n",
    "fftabs = abs(datafft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.shape[0]\n",
    "freqs = fftfreq(samples, 1/samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freqs,fftabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">Summary</font>\n",
    "\n",
    "\n",
    "| File Type | Python Package | Reader/Writer |\n",
    "| --- | --- | --- |\n",
    "| **text** | | `open` |\n",
    "| **binary** | | `open` |\n",
    "| **binary (pickle)** | pickle | `load`/`dump`  |\n",
    "|                 | Pandas |  `read_pickle`/`to_pickle` |\n",
    "| **csv**    | Pandas | `read_csv`/`to_csv` |\n",
    "|        | csv    | `open` |\n",
    "|        | Numpy  | `genfromtxt`   |\n",
    "| **Excel** | Pandas | `read_excel`/`to_excel` |\n",
    "|            | xlrd | `open_workbook` |\n",
    "|            | xlwt | `Workbook` |\n",
    "| **JSON**   | json |    `load`/`dump`  |\n",
    "|        | Pandas | `read_json`/`to_json` |\n",
    "| **nc4**    | netCDF4 | `Dataset` |\n",
    "| **HDF5**   | h5py    |  `File`  |\n",
    "|        | Pandas  | `read_hdf`/`to_hdf` |\n",
    "| **FITS**   | fits (astropy) | `open` |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "io.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
