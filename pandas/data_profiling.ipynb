{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center><h1><font color=\"red\" size=\"+3\">Data Profiling with Pandas</font></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Objectives</font>\n",
    "In this presentation, we will cover the following topics:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Useful References</font>\n",
    "\n",
    "- [What is data profiling?](https://www.ibm.com/think/topics/data-profiling) from IBM\n",
    "- R. A. Ruddle, J. Cheshire and S. J. Fernstad, [Tasks and Visualizations Used for Data Profiling: A Survey and Interview Study](https://ieeexplore.ieee.org/document/10008084), in IEEE Transactions on Visualization and Computer Graphics, vol. 30, no. 7, pp. 3400-3412, July 2024, doi: 10.1109/TVCG.2023.3234337."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">What is Data Profiling?</font>\n",
    "\n",
    ">Data profiling is the practice of looking closely at a dataset to understand its overall structure and quality. This means reviewing things, like the types of data it contains, how the data is distributed, whether any information is missing, and if everything is consistent.\n",
    "\n",
    "- It involves reviewing, analyzing, and cleansing data to understand its structure, characteristics, integrity, and quality. \n",
    "- It helps you gain insights into your data, identify potential issues, and make informed decisions about how to use it.\n",
    "- The main purpose of data profiling is to make sure the data is correct, well-organized, and ready to be used for analysis or important decisions.\n",
    "   - It helps choosing the right algorithms by gaining an initial high-level understanding of the dataset.\n",
    "- It is a crucial preliminary step before using the data in a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Purpose of data profiling</font>\n",
    "\n",
    "The purpose of data profiling is to:\n",
    "\n",
    "- Identify and correct issues with the quality of the data\n",
    "- Explore and understand how the data was generated (i.e., from which source)\n",
    "- Identify missing values in the data\n",
    "- Identify duplicate records in the dataset\n",
    "- Identify how frequently each attribute occurs\n",
    "- Identify how unique the values on each attribute\n",
    "- Identify outliers in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data profiling serves as a data hygiene process resulting in a collection of information about data, also known as metadata and its overall health. This could include:\n",
    "\n",
    "- Data types: Are the values in a column numbers, text, dates, etc.?\n",
    "- Value ranges: What are the minimum and maximum values a field can hold?\n",
    "- Missing values: How many data points are missing in a specific column?\n",
    "- Data distributions: How are the values distributed across a column?\n",
    "- Data relationships: Are there any connections between different data points or columns?\n",
    "- Data quality issues: Are there any inconsistencies, anomalies, duplicates, or errors present?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Common techniques for data profiling</font>\n",
    "\n",
    "Data profiling relies on a set of activities, including discovery and analytical techniques to collect statistics or informative summaries about the data. \n",
    "\n",
    "The most common methods used are:\n",
    "\n",
    "- __Column profiling__: Analyze individual columns to understand their data type, distribution, unique values, and missing values.\n",
    "- __Data type profiling__: Identify the data types of each column and checking for inconsistencies.\n",
    "- __Pattern profiling__: Identifyi patterns and anomalies in the data.\n",
    "- __Relationship profiling__: Examine the relationships between different columns and tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Information generated by data profiling</font>\n",
    "\n",
    "The analysis performed by data profiling tools exposes:\n",
    "\n",
    "- data rule (for instance, identifies dependencies that represent business rules embedded within the data).\n",
    "- anomalies that exist within the data sets.\n",
    "\n",
    "Data profiling tools can generate information about: \n",
    "\n",
    "- Data patterns\n",
    "- Numeric statistics\n",
    "- Data domains\n",
    "- Dependencies\n",
    "- Relationships, and\n",
    "- Anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the column level, reports focus on statistical measures and metadata to provide insights into the distribution and quality of the data. These reports include information on:\n",
    "\n",
    "- Minimum and maximum values: indicate the range of the data. Limiting a value set range also helps to determine outliers. \n",
    "- Mean and mode: reveal the average and most common values.\n",
    "- Percentiles: show the data distribution across intervals.\n",
    "- Standard deviation: indicates data variability.\n",
    "- Frequency: highlights the repetition of specific values.\n",
    "- Variation: shows data diversity and the aggregated sum of values within a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Benefits of data profiling</font>\n",
    "\n",
    "- Identify inaccuracies and inconsistencies, resulting in cleaner datasets and reduced errors.\n",
    "- Improve data credibility and quality.\n",
    "- Minimize the risk of data errors or inaccurate results.\n",
    "- Make better sense of the relationships between different data sets and sources\n",
    "- Improve users' understanding of data.\n",
    "- Can help quickly identify and address problems, often before they arise.\n",
    "\n",
    "__The result of data profiling is a constructive process of information inference to prepare a data set for later integration, analysis and modeling__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Some data profiling tools</font>\n",
    "\n",
    "We will rely on two profiling tools in this presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">[Data Profiler](https://github.com/capitalone/DataProfiler)</font>\n",
    "\n",
    "- Created by the financial company Capital One.\n",
    "- Designed to make data analysis, monitoring and sensitive data detection easy.\n",
    "- It is mainly meant to analyze datasets and detect if any of the information contained within is sensitive data, such as bank account numbers, credit card information, or social security numbers.\n",
    "- It can be used to generate basic statistical reports on science related datasets too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">[ydata-profiling](https://docs.profiling.ydata.ai/)</font>\n",
    "\n",
    "- Provides a one-line Exploratory Data Analysis (EDA) experience in a consistent and fast solution. \n",
    "- Automates and standardizes the generation of detailed reports, complete with statistics and visualizations.\n",
    "- Delivers an extended analysis of a DataFrame while allowing the data analysis to be exported in different formats such as __html__ and __json__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Packages Used</font>\n",
    "\n",
    "We will use the followin packages:\n",
    "\n",
    "- `Matplolib`: for visualization\n",
    "- `Seaborn`: for visualization settings\n",
    "- `Plotly`:\n",
    "- `NumPy`: for array creation.\n",
    "- `Pandas`: for creating and manipulating Series and DataFrames, and for visualization.\n",
    "- `Skimpy`:\n",
    "- `DataProfiler`:\n",
    "- `ydata-profiling`:\n",
    "- `great_table`: for dispalying tables.\n",
    "\n",
    "In addition, we will use the `datetime` module to manipulate dates and times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataprofiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_tables import GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Using Numpy version:  {np.__version__}')\n",
    "print(f'Using Pandas version: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 5 rows of data will be displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print floating point numbers using fixed point notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are five preset Seaborn themes: `darkgrid` (default), `whitegrid`, `dark`, `white`, and `ticks`.\n",
    "- They are each suited to different applications and personal preferences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The four preset contexts, in order of relative size, are `paper`, `notebook` (default), `talk`, and `poster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove spine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Perform data profiling in real applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Breakout 1</font>\n",
    "\n",
    "1. Create a Series using:\n",
    "\n",
    "```python\n",
    "   data = {'Course': \"Pandas\", 'Setting': \"Virtual\", 'Duration': \"3 hours\"}\n",
    "```\n",
    "\n",
    "2. Create a new Series with the above `data` and with the index as:\n",
    "\n",
    "```python\n",
    "   my_index = ['Course_Name', 'Course_Setting', 'Course_Duration']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"green\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "   data = {'Course': \"Pandas\", 'Setting': \"Virtual\", 'Duration': \"3 hours\"}\n",
    "   sr1 = pd.Series(data)\n",
    "   my_index = ['Course_Name', 'Course_Setting', 'Course_Duration']\n",
    "   sr2 = pd.Series(data, index=my_index)\n",
    "``` \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Breakout 2</font>\n",
    "In the above Pandas dataframe, relabel the index as `['Row0', 'Row1', 'Row2']`.\n",
    "\n",
    "<p>\n",
    "<p>\n",
    "    \n",
    "<details><summary><b><font color=\"green\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "df1.index = ['Row0', 'Row1', 'Row2']\n",
    "``` \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Breakout 4</font>\n",
    "* Read the weather data so that the indices are the dates\n",
    "* Plot the max and min tempatures on the same axes with the dates (ranging from November to March) as x-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"green\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "weather_data1 = weather_data\n",
    "\n",
    "# Make the date (datetime object) as index\n",
    "weather_data1.set_index(\"date\",inplace=True) \n",
    "\n",
    "# Select the date range\n",
    "df = weather_data1[(weather_data1.index > '2015-11-01') & \\\n",
    "                   (weather_data1.index <= '2016-03-31')]\n",
    "ax = df.max_temp.plot(title=\"Min and Max Temperatures\", \n",
    "                                figsize=(12,6));\n",
    "df.min_temp.plot(style=\"red\", ax=ax);\n",
    "ax.set_ylabel(\"Temperature (F)\");\n",
    "``` \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Arctic Oscillation and North Atlantic Oscillation  Datasets</font>\n",
    "\n",
    "__[Arctic oscillation](https://en.wikipedia.org/wiki/Arctic_oscillation)__\n",
    "\n",
    "- The Arctic oscillation (AO) or Northern Annular Mode/Northern Hemisphere Annular Mode (NAM) is a weather phenomenon at the Arctic poles north of 20 degrees latitude.\n",
    "- It describes how pressure patterns are distributed over the Arctic region and the middle latitudes of the Northern Hemisphere.\n",
    "- It is an important mode of climate variability for the Northern Hemisphere.\n",
    "- A negative AO index causes the jet stream to weaken and dip into the mid-latitudes, allowing Arctic air to spill out and creating cold-air outbreaks.\n",
    "- A positive AO index causes the jet stream to move farther north than normal.\n",
    "\n",
    "\n",
    "__[North Atlantic Oscillation](https://en.wikipedia.org/wiki/North_Atlantic_oscillation)__\n",
    "\n",
    "- The North Atlantic Oscillation (NAO) is a weather phenomenon in the North Atlantic Ocean of fluctuations in the difference of atmospheric pressure at sea level (SLP) between the Icelandic Low and the Azores High.\n",
    "- The NAO determines the speed and direction of the westerly winds across the North Atlantic, as well as winter sea surface temperature.\n",
    "   - A negative NAO leads to a weaker westerly flow into Western Europe; the more negative, the more this is true.\n",
    "   - When the NAO index is positive, enhanced westerly flow across the North Atlantic during winter moves relatively warm (and moist) maritime air over much of Europe and far downstream across Asia, while stronger northerlies over Greenland and northeastern Canada carry cold air southward and decrease land temperatures and SST over the northwest Atlantic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ao_url = \"http://www.cpc.ncep.noaa.gov/products/precip/CWlink/daily_ao_index/monthly.ao.index.b50.current.ascii\"\n",
    "nao_url = \"http://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.nao.monthly.b5001.current.ascii\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Read the North Atlantic Oscillation (NAO) data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nao_df = pd.read_table(nao_url, sep='\\s+', \n",
    "                       parse_dates={'dates':[0, 1]}, \n",
    "                       header=None)\n",
    "nao_df.columns = [\"dates\", \"NAO\"]\n",
    "nao_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Read the Atlantic Oscillation (AO) data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ao_df = pd.read_table(ao_url, sep='\\s+', \n",
    "                      parse_dates={'dates':[0, 1]}, \n",
    "                      header=None)\n",
    "ao_df.columns = [\"dates\", \"AO\"]\n",
    "ao_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a Pandas DataFrame by combining the two Pandas objects__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aonao_df = pd.concat([ao_df, nao_df[\"NAO\"]], axis=1)\n",
    "aonao_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain basic information on the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aonao_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Quick observations__\n",
    "\n",
    "- There appears to be no missing values.\n",
    "- There is a consistency in the data type of each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aonao_df[['AO', 'NAO', 'Diff']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimpy.skim(aonao_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Time series plots\n",
    "\n",
    "__Plot AO and NAO__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(aonao_df, x=\"dates\", y=[\"AO\", \"NAO\"],\n",
    "              hover_data={\"dates\": \"|%b %Y\"},\n",
    "              title='AO and NAO')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plot NAO only__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(aonao_df, x='dates', y=\"NAO\", \n",
    "              color=aonao_df[\"NAO\"]>=0, \n",
    "              color_discrete_map={True: \"red\", False: \"blue\"},\n",
    "              range_y=[-4, 4])\n",
    "# Set white background\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"white\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Change grid color and axis colors\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', gridcolor='lightgrey')\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', gridcolor='lightgrey')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plot AO only__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(aonao_df, x='dates', y=\"AO\", \n",
    "              color=aonao_df[\"AO\"]>=0, \n",
    "              color_discrete_map={True: \"red\", False: \"blue\"},\n",
    "              range_y=[-4, 4])\n",
    "# Set white background\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"white\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Change grid color and axis colors\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', gridcolor='lightgrey')\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', gridcolor='lightgrey')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(aonao_df, x=\"NAO\", color=aonao_df[\"NAO\"]>0)\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"white\",\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(aonao_df, x=\"AO\", color=aonao_df[\"AO\"]>0)\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"white\",\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = aonao_df[['AO', 'NAO', 'Diff']].corr()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(correlation_matrix);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap by year/month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aonao_df[\"Year\"] = aonao_df.dates.apply(lambda x: x.year)\n",
    "aonao_df[\"Month\"] = aonao_df.dates.apply(lambda x: x.strftime(\"%b\"))\n",
    "aonao_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nao_pt = aonao_df.pivot_table(index=\"Year\", columns=\"Month\", values=\"NAO\")\n",
    "fig, ax = plt.subplots(figsize=(9, 8))\n",
    "sns.heatmap(nao_pt, \n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            annot_kws={\"size\": 6},\n",
    "            linewidths=.5,\n",
    "            ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ao_pt = aonao_df.pivot_table(index=\"Year\", columns=\"Month\", values=\"AO\")\n",
    "fig, ax = plt.subplots(figsize=(9, 8))\n",
    "sns.heatmap(ao_pt, \n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            annot_kws={\"size\": 6},\n",
    "            linewidths=.5,\n",
    "            ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `Data Profiler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aonao_profile1 = dataprofiler.Profiler(aonao_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the report using json to prettify.\n",
    "aonao_report = aonao_profile1.report(report_options={\"output_format\":\"pretty\"})\n",
    "print(json.dumps(aonao_report, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a specified column, in this case it is labeled 0:\n",
    "print(json.dumps(aonao_report[\"data_stats\"][0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a specified column, in this case it is labeled 1:\n",
    "print(json.dumps(aonao_report[\"data_stats\"][1], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `ydata-profiling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aonao_profile2 = ProfileReport(aonao_df, title=\"Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aonao_profile2.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">AERONET Observations at Goddard</font>\n",
    "\n",
    "- [AERONET](https://aeronet.gsfc.nasa.gov/) (AErosol RObotic NETwork) is a globally distributed network of identical robotically controlled ground-based sun/sky scanning radiometers. \n",
    "- Each instrument measures the intensity of sun and sky light throughout daylight hours from the ultraviolet through the near-infrared. \n",
    "- The program provides a longterm, continuous, and accessible public domain database of aerosol optical, microphysical, and radiative properties for aerosol research including, aerosol characterization, validation of satellite retrievals and model predictions, and synergism with other databases.\n",
    "- Here are some Science benefits of AERONET:\n",
    "     - AERONET measurements are used to validate and advance algorithm development of satellite retrievals of aerosols.\n",
    "     - Aerosol transport models use aerosol data from AERONET to validate and improve model algorithms.\n",
    "     - Aerosol assimilation models as well as weather prediction models use real time AERONET data to improve predictions.\n",
    "     - Long-term commitment to AERONET sites worldwide provides assessment of the regional climatological impact of aerosols (e.g., aerosol amount, size, and heating or cooling effects).\n",
    "- Over 840 stations worldwide.\n",
    "- Here, we analyze the measurements (Aerosol Optical Depth (AOD)) at the [NASA GSFC](https://aeronet.gsfc.nasa.gov/new_web/photo_db_v3/GSFC.html) site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://portal.nccs.nasa.gov/datashare/astg/training/python/pandas/aeronet/\"\n",
    "\n",
    "filename = url+\"19930101_20210102_GSFC.lev20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: datetime.datetime.strptime(x, '%d:%m:%Y %H:%M:%S')\n",
    "aeronet_df = pd.read_csv(filename, skiprows=6, na_values=-999,\n",
    "                 parse_dates={'datetime': [0, 1]}, \n",
    "                 #date_parser=dateparse, # date_parser=dateparse\n",
    "                 index_col=0) \n",
    "                 #squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeronet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic information on each column__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeronet_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of unique values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = aeronet_df.nunique()\n",
    "print(unique_counts.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Quick observations__\n",
    "\n",
    "- There are 6835 data points.\n",
    "- Many columns only have `NaN` and need to be deleted.\n",
    "- Many columns only have one value and need to be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Identify and delete columns with all `NaN` values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = aeronet_df.isnull().sum()\n",
    "print(var.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns = aeronet_df.columns[aeronet_df.isna().all()].tolist()\n",
    "nan_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeronet_df.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeronet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Identify and delete columns with only one unique value__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_value_columns = list()\n",
    "for col in aeronet_df.columns:\n",
    "    if aeronet_df[col].nunique() == 1:\n",
    "        unique_value_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_value_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeronet_df.drop(unique_value_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeronet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeronet_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Quick observations__\n",
    "\n",
    "- We initially started with 79 columns but we now have 37.\n",
    "- We still have missing values in some of the columns.\n",
    "- More than half of the values of the column `AOD_1640nm` are missing values. We can remove the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeronet_df.drop(['AOD_1640nm'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeronet_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimpy.skim(aeronet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Scatterplot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(aeronet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the heatmap with `Plotly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = px.imshow(aeronet_df.corr(), x=aeronet_df.columns, \n",
    "                 y=aeronet_df.columns, title=\"Correlation matrix\", width=900, height=900)\n",
    "mat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Quick observations__\n",
    "\n",
    "- Based on the scatterplot matrix and the heatmap, there appears to be three groups of fields:\n",
    "  1. Group 1 that has `AOD_1640nm` to `AOD_340nm`. The fields are strongly correlated to each other. They all have float as data type.\n",
    "  2. Group 2 that has `N[AOD_1640nm]` to `N[340-440_Angstrom_Exponent]`. The fields are strongly correlated to each other. They all have int as data type.\n",
    "  3. Group 3 with the remaining fields not including `Day_of_Year`, `Precipitable_Water(cm)`, and `AERONET_Instrument_Number`. The fields here have moderate to strong correlation with each other.\n",
    "- `Precipitable_Water(cm)` has a moderate positive correlation with fields in Group 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `Data Profiler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeronet_profile1 = dataprofiler.Profiler(aeronet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the report using json to prettify.\n",
    "aeronet_report = aeronet_profile1.report(report_options={\"output_format\":\"pretty\"})\n",
    "print(json.dumps(aeronet_report, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a specified column, in this case it is labeled 1:\n",
    "print(json.dumps(aeronet_report[\"data_stats\"][1], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `ydata-profiling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeronet_profile2 = ProfileReport(aeronet_df, title=\"Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeronet_profile2.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Analyzing CME activities</font>\n",
    "\n",
    "We read a file (in JSON format) that contains a collection of CME activities. For each recorded CME, we want to extract the following parameters:\n",
    "\n",
    "- `start_time`\n",
    "- `speed`\n",
    "- `longitude`\n",
    "- `latitude`\n",
    "- `halfAngle`\n",
    "- The list of instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cme_filename = \"all_cmes.json\"\n",
    "cme_url = f\"https://raw.githubusercontent.com/barbarajthompson/TCMM_Maps/refs/heads/main/{cme_filename}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(cme_url, cme_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cme_filename, \"r\") as fid: \n",
    "     cme_activities = json.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cme_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cme_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cme_activities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cme_activities[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CME_parameters(cme_activity: dict):\n",
    "    \"\"\"\n",
    "    From a dictionary containing CME activity data on a specific date/time,\n",
    "    extract the following parameters:\n",
    "\n",
    "    - starting date/time\n",
    "    - latitude\n",
    "    - longitude\n",
    "    - halfAngle\n",
    "    - speed\n",
    "    \"\"\"\n",
    "\n",
    "    latitude = cme_activity['cmeAnalyses'][0]['latitude']\n",
    "    longitude = cme_activity['cmeAnalyses'][0]['longitude']\n",
    "    half_angle = cme_activity['cmeAnalyses'][0]['halfAngle']\n",
    "    speed = cme_activity['cmeAnalyses'][0]['speed']\n",
    "    start_time = cme_activity['startTime']\n",
    "    list_instruments = list()\n",
    "    for item in cme_activity['instruments']:\n",
    "        list_instruments.append(item['displayName'])\n",
    "    return start_time, speed, latitude, longitude, half_angle, tuple(sorted(list_instruments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(cme_activities: list):\n",
    "    \"\"\"\n",
    "    Using a list of CME activities, create a Pandas DataFrame\n",
    "    with columns:\n",
    "    \n",
    "    - star_time\n",
    "    - latitude\n",
    "    - longitude\n",
    "    - half_angle\n",
    "    - speed\n",
    "    - instruments\n",
    "    \"\"\"\n",
    "    columns = [\"start_time\", \"speed\", \"latitude\", \"longitude\", \"half_angle\", \"instruments\"]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Loop over the CME event\n",
    "    for cme_activity in cme_activities:\n",
    "        # Only process when a CME activity was recorded.\n",
    "        if cme_activity['cmeAnalyses']:   # This mean that an activity was recorded\n",
    "            df.loc[len(df)] = get_CME_parameters(cme_activity)\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cme_df = create_df(cme_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cme_df['start_time'] = pd.to_datetime(cme_df['start_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cme_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We can use `great_tables` to better display the content of the DataFrame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT(cme_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cme_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cme_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimpy.skim(cme_df[[\"speed\", \"latitude\", \"longitude\", \"half_angle\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(cme_df[[\"speed\", \"latitude\", \"longitude\", \"half_angle\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cme_df[[\"speed\", \"latitude\", \"longitude\", \"half_angle\"]]\n",
    "mat = px.imshow(df.corr(), x=df.columns, \n",
    "                 y=df.columns, title=\"Correlation matrix\", width=900, height=900)\n",
    "mat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
