{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center><h1><font color=\"red\" size=\"+3\">Introduction to Pandas</font></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Objectives</font>\n",
    "In this presentation, we will cover the following topics:\n",
    "1. Pandas data structures (Series and DataFrames)\n",
    "2. Inspecting data in DataFrames\n",
    "3. Important functions\n",
    "     - `grouby()`\n",
    "     - `apply`\n",
    "     - `concat()`, `join()`, `merge()`\n",
    "     - `compare()`\n",
    "4. Reading remote CSV files and tables.\n",
    "5. Cleaning and formatting data\n",
    "6. Manipulating time series data\n",
    "7. Performing statistical calculations\n",
    "8. Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Useful References</font>\n",
    "- [Learn Pandas](https://bitbucket.org/hrojas/learn-pandas/src/master/) by Hernan Rojas.\n",
    "- [Python Pandas Tutorial: A Complete Introduction for Beginners](https://www.learndatasci.com/tutorials/python-pandas-tutorial-complete-introduction-for-beginners/) by George McIntire, Brenda Martin and Lauren Washington.\n",
    "- [Introduction into Pandas](https://www.python-course.eu/pandas.php) by Bernd Klein.\n",
    "- [Time series analysis with pandas](http://earthpy.org/pandas-basics.html) from EarthPy.\n",
    "- [Working with Time Series](https://jakevdp.github.io/PythonDataScienceHandbook/03.11-working-with-time-series.html) from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas.\n",
    "- [Introduction to data analysis](https://pythongis.org/part1/chapter-03/index.html)\n",
    "- [Unlocking Data Manipulation in Python: Key Pandas Techniques](https://www.dasca.org/world-of-data-science/article/unlocking-data-manipulation-in-python-key-pandas-techniques) from the Data Science Council of America."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig_logo](https://miro.medium.com/max/3200/1*9v51-jsfHtk6fgAIYLoiHQ.jpeg)\n",
    "Image Source: pandas.pydata.org\n",
    "\n",
    "# <font color=\"red\">What is Pandas?</font>\n",
    "+ `Pandas` is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "+ Some key features:\n",
    "    - Fast and efficient DataFrame object with default and customized indexing.\n",
    "    - Tools for loading data into in-memory data objects from different file formats.\n",
    "    - Data alignment and integrated handling of missing data.\n",
    "    - Reshaping and pivoting of data sets.\n",
    "    - Label-based slicing, indexing and subsetting of large data sets.\n",
    "    - Columns from a data structure can be deleted or inserted.\n",
    "    - Group by data for aggregation and transformations.\n",
    "    - High performance merging and joining of data.\n",
    "    - Time Series functionality.\n",
    "+ Able to manipulate several <a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html\">types of files</a>, including CSVs, TSVs , JSONs, HTML, xlsx, HDF5, Python Pickle, among others.\n",
    "* Is compatible with many of the other data analysis libraries, like Scikit-Learn, Matplotlib, NumPy, and more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of key features of `Pandas` are captured in the diagram below:\n",
    "\n",
    "![fig_features](https://favtutor.com/resources/images/uploads/mceu_16841658121636696850726.png)\n",
    "Image Source: [favtutor.com](https://favtutor.com/blogs/numpy-vs-pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Packages Used</font>\n",
    "\n",
    "We will use the followin packages:\n",
    "\n",
    "- `Matplolib`: for visualization\n",
    "- `Seaborn`: for visualization settings\n",
    "- `NumPy`: for array creation.\n",
    "- `Pandas`: for creating and manipulating Series and DataFrames, and for visualization.\n",
    "\n",
    "In addition, we will use the `datetime` module to manipulate dates and times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Using Numpy version:  {np.__version__}')\n",
    "print(f'Using Pandas version: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 5 rows of data will be displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print floating point numbers using fixed point notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are five preset Seaborn themes: `darkgrid` (default), `whitegrid`, `dark`, `white`, and `ticks`.\n",
    "- They are each suited to different applications and personal preferences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The four preset contexts, in order of relative size, are `paper`, `notebook` (default), `talk`, and `poster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove spine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig_pandas](https://www.dasca.org/content/images/main/essential-data-manipulation-techniques-in-pandas.jpg)\n",
    "Image Source: dasca.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">`pandas` Data Structures\n",
    "\n",
    "There are three data structures provided by the Pandas, which are as follows:\n",
    "\n",
    "- **Series**: 1D size-immutable array like structure having homogeneous data.\n",
    "- **DataFrames**: 2D size-mutable tabular structure with heterogeneously typed columns.\n",
    "- **Panel**: 3D, size-mutable array (not covered here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">1D Data Structures: Series</font>\n",
    "\n",
    "- A <font color='red'>Series</font> is a one-dimensional <font color='green'>**labeled**</font> array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.).\n",
    "- It can be seen as a column in a table or a one-dimensional NumPy array (homogeneous data), but with an added index that allows you to access elements by their label.\n",
    "   - The row labels of Series are called the **index**.\n",
    "- Series support a wide range of data manipulation and analysis operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://portal.nccs.nasa.gov/datashare/astg/training/python/pandas/pandas_series.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Series\n",
    "\n",
    "A Series can be constructed with the `pd.Series` constructor (passing a list, array, dictionary or existing DataFrame).\n",
    "\n",
    "```python\n",
    "pd.Series(data=None, index=None, dtype=None, \n",
    "          name=None, copy=False)\n",
    "```\n",
    "\n",
    "- **data**: Array or dict or scalar value or iterables. It is used to populate the rows of the Series object.\n",
    "- **index**: Array or index. It is used to label the rows of the Series. It’s length must be the same as the object passed in the data parameter and all the values must be unique. `np.arrange(n)` is the default index.\n",
    "- **dtype**: Used to specify the data type of the Series which will be formed. If this parameter is not specified then the data type will be inferred from the values present in the series.\n",
    "- **copy**: Boolean used to copy the input data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation from a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [5, 8, 13, 0.1, -5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a list to create a Numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a list to create a Pandas Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = pd.Series(my_list)\n",
    "print(type(sr))\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...get default index values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy arrays as backend of Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains an array of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If nothing else is specified, the values are labeled with their index number. \n",
    "- The Pandas Series will then have an associated array of data labels from `0`, to `N-1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sr.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rows = list(range(5))\n",
    "print(my_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sr.index.values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain statistical information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More on the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the index values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.index = ['A','B','C','D','E']\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or pass the index values during Pandas series creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr1 = pd.Series(my_list, index=['A','B','C','D','E'])\n",
    "print(sr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy Array has an implicitly defined integer index used to access the values while the Pandas Series has an explicitly defined index associated with the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get value at position `n` in series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sr[3])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `iloc` (integer location) to get value at position `n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sr.iloc[3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value at given index using dictionary-like syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sr.loc['D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr[sr > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other ways to create Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a Pandas Series from a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr2 = pd.Series(dict(A=5, B=8, C=13, D=0.1, E=-5))\n",
    "sr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also, create a Pandas Series from a scalar data. But, if you pass a single value with multiple indexes, the value will be same for all the indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr3 = pd.Series(10.5, index=['A','B','C','D','E'])\n",
    "print(sr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Breakout 1</font>\n",
    "\n",
    "1. Create a Series using:\n",
    "\n",
    "```python\n",
    "   data = {'Course': \"Pandas\", 'Setting': \"Virtual\", 'Duration': \"3 hours\"}\n",
    "```\n",
    "\n",
    "2. Create a new Series with the above `data` and with the index as:\n",
    "\n",
    "```python\n",
    "   my_index = ['Course_Name', 'Course_Setting', 'Course_Duration']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"green\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "   data = {'Course': \"Pandas\", 'Setting': \"Virtual\", 'Duration': \"3 hours\"}\n",
    "   sr1 = pd.Series(data)\n",
    "   my_index = ['Course_Name', 'Course_Setting', 'Course_Duration']\n",
    "   sr2 = pd.Series(data, index=my_index)\n",
    "``` \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">2D data structures</font>\n",
    "\n",
    "Pandas: <font color='red'>DataFrame</font> is a 2-dimensional labeled data structure with columns of potentially different types. It is generally the most commonly used pandas object.\n",
    "\n",
    "A <font color='red'>DataFrame</font> is like a sequence of aligned <font color='red'>Series</font> objects, i.e. they share the same index.\n",
    "\n",
    "![title](https://portal.nccs.nasa.gov/datashare/astg/training/python/pandas/pandas_df.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features of DataFrames\n",
    "\n",
    "A DataFrame:\n",
    "- Is a way to represent and work with tabular data.\n",
    "- Can be thought of as a __generalization of a two-dimensional NumPy array, where both the rows and columns have a generalized index for accessing the data__.\n",
    "- Rows and columns of a DataFrame are labelled and can be named.\n",
    "- Can be seen as a dictionary of one-dimensional NumPy arrays, lists, dictionaries or Series.\n",
    "- Supports hetrogenous collections of data where data in each column is homogeneous.\n",
    "- Can perform arithmetic operations on rows and columns.\n",
    "- Its size is mutable.\n",
    "   - We can add/remove rows or columns as needed.\n",
    "- Supports reading flat files like `CSV`, `Excel`, `JSON` and also reading `SQL` tables\n",
    "- Handles missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A pandas dataframe can be seen as a collection of pandas series**\n",
    "![fig_objects](https://doit-test.readthedocs.io/en/latest/_images/base_01_pandas_5_0.png)\n",
    "Image Source: doit-test.readthedocs.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Create DataFrame</font>\n",
    "\n",
    "- We can create a DataFrame using a list, a NumPy Array or a dictionary\n",
    "\n",
    "__Creation with a list__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[\n",
    "    [5, True, 'x', 2.7],\n",
    "    [8, True, 'y', 3.1],\n",
    "    [13,False,'z', np.NaN],\n",
    "    [1, False, 'a', 0.1],\n",
    "    [-5, True, 'b', -2]\n",
    "]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data=data,\n",
    "    index=['A','B','C','D','E'],\n",
    "    columns=['num', 'bool', 'str', 'real']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creation with NumPy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = np.array([5, 8, 13, 1, -5])\n",
    "bool_col = np.array([True, True, False, False, True])\n",
    "str_col = np.array(['x', 'y', 'z', 'a', 'b'])\n",
    "real_col = np.array([2.7, 3.1, np.NaN, 0.1, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    dict(num=num_col, bool=bool_col, str=str_col, real=real_col),\n",
    "    index=['A','B','C','D','E'],\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creation with a dictionary__\n",
    "\n",
    "- The keys are the column names\n",
    "- The corresponding values are lists of numbers, bools, strings and floats respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"num\": [5, 8, 13, 1, -5],\n",
    "    \"bool\": [True, True, False, False, True],\n",
    "    \"str\": ['x', 'y', 'z', 'a', 'b'],\n",
    "    \"real\": [2.7, 3.1, np.NaN, 0.1, -2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_dict, index=['A','B','C','D','E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Inspecting data in DataFrame</font>\n",
    "\n",
    "__Display the first few rows__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Display the last few rows__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get the number of rows and columns as a tuple__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get the type of each column__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get list of column names__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get the index values__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Obtain basic data information</font>\n",
    "\n",
    "We can get the column count, number of values in each column, data type of each column, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Obtain descriptive statistics</font> \n",
    "\n",
    "- Can only be done on each numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass the argument `include='object'` to return the descriptive statistics of categorical (object) columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Sorting records</font>\n",
    "\n",
    "- We can sort records by any column using `df.sort_values()` function.\n",
    "- For example, we can sort the \"str\" column in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('str', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Slicing data</font>\n",
    "\n",
    "__Get specific column(s)__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['num','real']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Label-based selection</font>\n",
    "\n",
    "__Get specific row(s) by name(s)__: use `loc[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[['B', 'D']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['A':'E':2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get specific row(s) and column(s) by name(s)__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['A':'D':2, ['num', 'real']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['A':'C', 'num':'real']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Index-based selection</font>\n",
    "\n",
    "__Get specific row(s) by position(s)__: use `iloc[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get specific row(s) and column(s) by position(s)__: use `iloc[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[2,4], [1,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Display one random row__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select columns based on data type__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Filtering data</font>\n",
    "\n",
    "__Apply masking__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.real > 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.real == 3.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Problem with `NaN`__:\n",
    "- In Python (and NumPy), the `nan`'s don’t compare to equal. \n",
    "- Pandas/NumPy uses the fact that `np.nan != np.nan`, and treats `None` like `np.nan`.\n",
    "- A scalar equality comparison versus a `None/np.nan` doesn’t provide useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.real == np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `isnull()` method to find out which DataFrame entries are `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine if there is at least one `NaN` in your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine which column has at least a `NaN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color=\"green\">Dealing with missing values</font>\n",
    "\n",
    "- One of the most common issues encountered in datasets is the presence of missing values.\n",
    "- In Pandas, missing data can be represented in various forms, such as `NaN` (Not a Number) or `None`.\n",
    "- Understanding how to manage missing data ensures the integrity of the datasets and reinforces the accuracy of any conclusions drawn from them.\n",
    "- How do we deal with missing values in our dataset? There are at least three (3) options we can consider:\n",
    "    - Remove the rows and or columns with missing values: use `dropna()` method.\n",
    "    - Replace the missing values with specified values, such as the mean or median of the column: use the `fillna()` method.\n",
    "    - Fill missing values with interpolated values: use the `interpolate()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Drop rows with missing values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Drop columns with missing values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Drops rows/columns with at least one missing value__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Drops rows/columns with all values missing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Replace missing values using `fillna()`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With any number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_number = df['real'].mean()\n",
    "df.fillna(my_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward fills missing values with the last non-missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back fills missing values with the next non-missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fill missing values using interpolation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.interpolate(method=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.interpolate(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Breakout 2</font>\n",
    "\n",
    "Use the above DataFrame `df` to create a new one with the values in the `bool` column to be True and the values in the `num` column to be less than 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"orange\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "df[(df.num < 10) & (df[\"bool\"])]\n",
    "``` \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Important Operations on DataFrames</font>\n",
    "\n",
    "- Operations on rows and/or columns\n",
    "   - `apply()`\n",
    "   - `map()`\n",
    "   - `replace()`\n",
    "- Merging\n",
    "   - `concat()` \n",
    "   - `join()` \n",
    "   - `merge()`\n",
    "- Comparing\n",
    "   - `compare()`\n",
    "- Grouping\n",
    "   - `groupby()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Applying</font>\n",
    "\n",
    "- `replace()`: Use for targeted value substitutions.\n",
    "- `map()`: Use for simple value mappings on a single Series.\n",
    "- `apply()`: Use for complex transformations involving multiple columns or rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> `replace()` Function</font>\n",
    "\n",
    "The `replace()` method is a convenient way to replace specific strings in a entire DataFrame or a specific column (Series) with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'student1': ['D', 'A', 'B', 'C'], \n",
    "        'student2': ['B', 'C', 'B', 'A']\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'A': 1, 'B': 2, 'C': 3, 'D': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> `map()` Function</font>\n",
    "\n",
    "- The `map()` method takes a dictionary as an argument, where the keys are the strings to be replaced and the values are the replacement values.\n",
    "- It is used on one column only (Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymapping = {'A': 1, 'B': 2, 'C': 3, 'D': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['student1'].map(mymapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> `apply()` Function</font>\n",
    "- Allows us to use an external function to manipulate every row or column.\n",
    "- The function can be any Python function that takes a single argument and returns a single value.\n",
    "- Can be used to perform a wide range of operations on your data, including filtering, sorting, and grouping.\n",
    "- You used the `axis` parameter to determine if you want to apply to a row (`axis=1`) or a column (`axis=0`).\n",
    "\n",
    "```python\n",
    "DataFrame.apply(func, axis=0, broadcast=None, raw=False, \n",
    "                reduce=None, result_type=None, args=(), **kwds)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(-13, 5, 7), (2, 4, -6), (7.5, -5, 8),(-2, 3, 9)]\n",
    "df = pd.DataFrame(data, \n",
    "                  columns=['col1', 'col2', 'col3'],\n",
    "                  index=['row1', 'row2', 'row3', 'row4']\n",
    "                 )\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Apply to all entries__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_func(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(square_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Apply to a specific column__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col3'].apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calculation along axis__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(sum, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df.apply(sum, axis=1)\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using multiple arguments__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(x, y, z):\n",
    "    return (x+y**2)/z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: my_func(x['col1'], x['col2'], x['col3']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Breakout 3</font>\n",
    "The code below creates a Pandas DataFrame of students' grades.\n",
    "\n",
    "```python\n",
    "columns = [\"Students\", \"Engl\", \"Phys\", \"Math\", \"Comp\"]\n",
    "students = [\"Julia\", \"Jules\", \"Julio\"]\n",
    "engl_grades = [\"A\", \"D\", \"B\"]\n",
    "phys_grades = [\"A\", \"A\", \"C\"]\n",
    "math_grades = [\"C\", \"A\", \"A\"]\n",
    "comp_grades = [\"B\", \"B\", \"C\"]\n",
    "\n",
    "zipped = list(zip(students, engl_grades, phys_grades, \n",
    "                  math_grades, comp_grades))\n",
    "student_df = pd.DataFrame(zipped, columns = columns)\n",
    "```\n",
    "\n",
    "Do the following:\n",
    "1. Set the `Students` as index.\n",
    "2. Replace the letters (`A`, `B`, `C`, `D`) with numbers (`4`, `3`, `2`, `1`). You may want to do a Google search on how to replace a string with an integer in a Pandas DataFrame.\n",
    "3. Compute the GPA of each student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"orange\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "# Question 1\n",
    "student_df = student_df.set_index(columns[0])\n",
    "    \n",
    "# Question 2\n",
    "mymap = {'A': 4, 'B': 3, 'C': 2, 'D': 1}\n",
    "\n",
    "new_student_df = student_df.replace(mymap)\n",
    "\n",
    "new_student_df = student_df.applymap(lambda s: mymap.get(s) if s in mymap else s)\n",
    "    \n",
    "# Question 3\n",
    "new_student_df.mean(axis=1)\n",
    "``` \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Merging</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the DataFrame which rows are students' grades and columns are the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Engl\", \"Phys\", \"Math\", \"Comp\"]\n",
    "students = [\"Julia\", \"Jules\", \"Julio\"]\n",
    "engl_grades = [\"A\", \"D\", \"B\"]\n",
    "phys_grades = [\"A\", \"A\", \"C\"]\n",
    "math_grades = [\"C\", \"A\", \"A\"]\n",
    "comp_grades = [\"B\", \"B\", \"C\"]\n",
    "\n",
    "zipped = list(zip(engl_grades, phys_grades, \n",
    "                  math_grades, comp_grades))\n",
    "student_grades = pd.DataFrame(zipped, columns = columns, index=students)\n",
    "student_grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new DataFrame with one row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_student_name = ['Jean']\n",
    "new_student_grade = pd.DataFrame([['C', 'A', 'B', 'A']], \n",
    "                                 columns = columns, \n",
    "                                 index=new_student_name)\n",
    "new_student_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new DataFrame with two new courses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_courses = ['Psy', 'Bio']\n",
    "new_grades = [\n",
    "    ['C', 'A'], \n",
    "    ['A', 'B'], \n",
    "    ['A','A'], \n",
    "    ['B', 'C']]\n",
    "new_course_grades = pd.DataFrame(new_grades, \n",
    "                                 columns = new_courses, \n",
    "                                 index=students+new_student_name)\n",
    "new_course_grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">`concat()` function</font>\n",
    "\n",
    "- Append either columns or rows from one DataFrame to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades2 = pd.concat([student_grades, new_student_grade])\n",
    "student_grades2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">`join()` function</font>\n",
    "\n",
    "- Used to combine two DataFrame on row indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_grades3 = student_grades2.join(new_course_grades)\n",
    "student_grades3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">`merge()` function</font>\n",
    "\n",
    "Combines or joins two DataFrames with the same columns or indices.\n",
    "\n",
    "```python\n",
    "merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "      left_index=False, right_index=False, sort=True,\n",
    "      suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "```\n",
    "\n",
    "- The column to be keyed: `on`, `left_on`, `right_on`\n",
    "- The merging method: `how`\n",
    "   - INNER JOIN: `how='inner'`\n",
    "   - LEFT JOIN: `how='left'`\n",
    "   - RIGHT JOIN: `how='right'`\n",
    "   - OUTER JOIN: `how='outer'`\n",
    "   - CROSS JOIN: `how='cross'`\n",
    "\n",
    "\n",
    "![fig_merge](https://datacomy.com/data_analysis/pandas/merge/types-of-joins.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_df1 = pd.DataFrame([['Jules',100,85,90], ['Julio',89,97,85], ['Julia',91,75,95]], \n",
    "                         columns=['Student', 'Math', 'Eng', 'Phys'])\n",
    "grade_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_df2 = pd.DataFrame([['Jules',100,92,93], ['Julio',93,94,87], ['Julia',93,82,95]], \n",
    "                         columns=['Student', 'Math', 'Eng', 'Phys'])\n",
    "grade_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_df1.merge(grade_df2, on='Student')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_df1.merge(grade_df2, on='Math')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_df1.merge(grade_df2, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_df1.merge(grade_df2, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates all possible combinations of `left` and `right`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_df1.merge(grade_df2, how='cross')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> `compare()` function</font>\n",
    "\n",
    "- Compares two DataFrames row-by-row and column-by-column.\n",
    "- Displays the differences next to each other.\n",
    "\n",
    "```python\n",
    "df1.compare(df2, align_axis=1, keep_shape=False, keep_equal=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grade_df1.compare(grade_df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the argument `keep_equal=True` if you want to keep the corresponding values that are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grade_df1.compare(grade_df2, keep_equal=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grade_df1.compare(grade_df2, align_axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `align_axis=0` the `DataFrame.compare()` method returns DataFrame that are stacked vertically with rows drawn alternately from self and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grade_df1.compare(grade_df2, align_axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `keep_shape=True`, all rows and columns in the resulted DataFrame will be shown. Otherwise, only the ones with different values will be shown in the resulted DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grade_df1.compare(grade_df2, keep_shape=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `groupby()` Function\n",
    "\n",
    "Will be covered in a furure section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Pandas DateTime</font>\n",
    "- Being able to handle and work with temporal information is extremely important when doing data analysis. \n",
    "- Time information in the data allows us to see patterns through time (trends) as well as to make predictions into the future (at varying level of confidence). \n",
    "- Many data points we collect are obtained at different time intervals and ordered chronologically. They are referred as time series data.\n",
    "- The [datetime](https://docs.python.org/3/library/datetime.html) provides functionalities for manipulating dates and times.\n",
    "- Pandas provides a number to tools to handle times series data by including methods for manipulation `datetime` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate sequences of fixed-frequency dates and time spans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti = pd.date_range('2022-01-01', periods=15, freq='H')\n",
    "print(type(dti))\n",
    "dti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulating and converting date times with timezone information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti = dti.tz_localize(\"UTC\")\n",
    "dti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the sequence to create a Pandas series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(range(len(dti)), index=dti)\n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample or convert the time series to a particular frequency:\n",
    "\n",
    "- Sample every two hours and compute the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.resample('2H').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas series where the index is the time component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_periods = 67\n",
    "ts = pd.Series(np.random.random(num_periods),\n",
    "               index=pd.date_range('2021-01', \n",
    "                                   periods=num_periods, \n",
    "                                   freq='W'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas DataFrame where the index is the time component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_periods = 2500\n",
    "df = pd.DataFrame(dict(X = np.random.random(num_periods), \n",
    "                       Y = -5+np.random.random(num_periods)),\n",
    "                  index=pd.date_range('2000', \n",
    "                                      periods=num_periods, \n",
    "                                      freq='D'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resampling**\n",
    "- The `resample()` function is used to resample time-series data.\n",
    "- It groups data by a certain time span. \n",
    "- You specify a method of how you would like to resample.\n",
    "- Pandas comes with many in-built options for resampling, and you can even define your own methods.\n",
    "\n",
    "Here are some time period options:\n",
    "\n",
    "| Alias | Description |\n",
    "| --- | --- |\n",
    "| 'D' |\tCalendar day |\n",
    "| 'W' |\tWeekly |\n",
    "| 'M' |\tMonth end |\n",
    "| 'Q' |\tQuarter end |\n",
    "| 'A' |\tYear end |\n",
    "\n",
    "Here are some method options for resampling:\n",
    "\n",
    "| Method | Description |\n",
    "| --- | --- |\n",
    "| max |\tMaximum value |\n",
    "| mean |\tMean of values in time range |\n",
    "| median |\tMedian of values in time range |\n",
    "| min |\tMinimum data value |\n",
    "| sum |\tSum of values |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.X.resample('Y').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Y.resample('W').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.X.resample('Q').median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Applications</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Report on UFO Sightings</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://bit.ly/uforeports'\n",
    "df_ufo = pd.read_csv(url)            \n",
    "df_ufo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Time column to datetime format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ufo['Time'] = pd.to_datetime(df_ufo.Time)\n",
    "df_ufo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the column to Date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ufo.rename(columns={'Time':'Date'}, inplace=True)\n",
    "df_ufo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the Date column as the DataFrame index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ufo.set_index(['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ufo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**: How to determine the number of sightings between two dates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_ufo.loc['1978-01-01 09:00:00':'1980-01-01 11:00:00']\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: How to extract the sightings at a specific month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_ufo[df_ufo.index.month == 2]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: How to extract the sightings at a specific year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df_ufo[df_ufo.index.year == 1999]\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: How to extract the sightings in a given State?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df_ufo[df_ufo['State']== 'CA']\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**: How to get the sightings with shape `TRIANGLE`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df_ufo[df_ufo['Shape Reported']== 'TRIANGLE']\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**: How to count the number of sightings in each state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df_ufo.groupby(['State']).count()\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['City'].plot(kind='barh', \n",
    "                 figsize=(18,17));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Population Data</font>\n",
    "\n",
    "### Using the `groupby` Function and Related Functions to Aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from url as pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_url = 'http://bit.ly/2cLzoxH'\n",
    "\n",
    "pop_data = pd.read_csv(pop_url)\n",
    "pop_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `year` values as datetime objects and make the `year` as index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data['year'] = pd.to_datetime(pop_data.year, format=\"%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data.rename(columns={'year': 'Year'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data.set_index(['Year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a new dataframe by selecting the `continent` and `pop` columns only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_pop = pop_data[['continent', 'pop']]\n",
    "continent_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas `groupby()` Function\n",
    "\n",
    "- It is used to group rows that have the same values.\n",
    "- It is used with **aggregate functions** (`count`, `sum`, `min`, `max`, `mean`) to get the statistics based on one or more column values.\n",
    "- It is also called **Split-Apply-Combine** process:\n",
    "    - The `groupby()` function splits the data into groups based on some criteria.\n",
    "    - The aggregate function is applied to each of the groups.\n",
    "    - The groups are combined together to create a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop = continent_pop.groupby(\"continent\")\n",
    "grouped_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could then print the new DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain statistical description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterating through Groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in grouped_pop:\n",
    "    print(f\"Key is: {str(key)}\")\n",
    "    print(f\"{str(item)} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting a Group\n",
    "\n",
    "A single group can be selected using `get_group()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.get_group('Oceania')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions To Aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`mean()`** computes mean values for each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.aggregate(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`sum()`** adds of values within each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`size()`** computes the size per each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.aggregate(np.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each group, you can similarly use:\n",
    "    \n",
    "- `count()`: computes the number of values.\n",
    "- `max()`: gets maximum value.\n",
    "- `min()`: gets minimum value.\n",
    "- `std()`: computes standard deviation of the values.\n",
    "- `var()`: computes variance, an estimate of variability.\n",
    "- `sem()`: computes standard error of the mean values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying several functions at once**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.agg([np.sum, np.mean, np.std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`describe()`** computes a quick summary of values per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`first()`** gets the first row value within each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`last()`** gets the last row value within each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.last()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`nth()`** gives nth value, in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pop.nth(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Read HTML Table</font>\n",
    "\n",
    "We want to be able to read the **United States presidential election results for Minnesota** table from:\n",
    "\n",
    "[https://en.wikipedia.org/wiki/Minnesota](https://en.wikipedia.org/wiki/Minnesota)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.read_html('https://en.wikipedia.org/wiki/Minnesota')\n",
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read all the tables from the webpage. We can select the specific table we want to read by using the `match` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.read_html('https://en.wikipedia.org/wiki/Minnesota', \n",
    "                        match='United States presidential election results for Minnesota')\n",
    "\n",
    "df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the result is a list containing one DataFrame. We can then extract the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_table[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us gather basic information on rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the column names\n",
    "- For readability and easy manipulation, we want to column names to be one words only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['Year', 'GOP_Num', 'GOP_Perc', \n",
    "               'DNC_Num', 'DNC_Perc', 'Others_Num', 'Others_Perc']\n",
    "df.columns = new_columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that the columns `GOP_Perc`, `DNC_Perc` and `Others_Perc` more likely have the string type. \n",
    "- We want them to have numerical values.\n",
    "- We can use the `regex=True` parameter to replace the string `%` with an empty space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'%': ''}, regex=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Columns `GOP_Perc`, `DNC_Perc` and `Others_Perc` are still strings.\n",
    "- We need to convert them into floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['GOP_Perc', 'DNC_Perc', 'Others_Perc']] = df[['GOP_Perc', 'DNC_Perc', 'Others_Perc']].apply(pd.to_numeric)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Make the `Year` values as a datetime objects and set `Year` as index__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = pd.to_datetime(df['Year'], format=\"%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Year', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GOP_Num'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DNC_Num'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do timeseries plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['GOP_Num', 'DNC_Num']].plot(color=['red', 'blue']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['GOP_Perc', 'DNC_Perc']].plot(color=['red', 'blue']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Weather Data</font>\n",
    "\n",
    "<center>https://www.wunderground.com/cgi-bin/findweather/getForecast?query=KDAA</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas <font color='red'>read_csv</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://portal.nccs.nasa.gov/datashare/astg/training/python/pandas/weather/hampton_10-10-15_10-10-16.csv\"\n",
    "weather_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the column labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get basic information on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `Events` may have missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Descriptive statistics__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Access values of a column like in a dictionary__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_df[\"Max TemperatureF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[\"EDT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access column data like a \"method\" is nicer because you can autocomplete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.EDT  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select multiple columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[[\"EDT\", \"Mean TemperatureF\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.EDT.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[\"Mean TemperatureF\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename columns\n",
    "\n",
    "- Some column names have multiple words. It is easier to manipulate the DataFrame when each column name is one word only.\n",
    "- Assign a new list of column names to the columns property of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.columns = [\n",
    "    \"date\", \"max_temp\", \"mean_temp\", \"min_temp\", \"max_dew\",\n",
    "    \"mean_dew\", \"min_dew\", \"max_humidity\", \"mean_humidity\",\n",
    "    \"min_humidity\", \"max_pressure\", \"mean_pressure\",\n",
    "    \"min_pressure\", \"max_visibilty\", \"mean_visibility\",\n",
    "    \"min_visibility\", \"max_wind\", \"mean_wind\", \"min_wind\",\n",
    "    \"precipitation\", \"cloud_cover\", \"events\", \"wind_dir\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use `.` dot: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.mean_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.mean_temp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.mean_temp.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_df.mean_temp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_df[['max_temp','min_temp']].plot(subplots=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weather_df = weather_df[['max_temp','min_temp']]\n",
    "new_weather_df.plot(subplots=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify column labels in the loc method to retrieve columns by label instead of by position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weather_df = weather_df.loc[50:125,['max_temp','min_temp']]\n",
    "new_weather_df.plot(subplots=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <font color='red'>plot()</font> function returns a matplotlib <font color='red'>AxesSubPlot</font> object. You can pass this object into subsequent calls to plot() in order to compose plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = weather_df.max_temp.plot(title=\"Min and Max Temperatures\", \n",
    "                                figsize=(12,6));\n",
    "weather_df.min_temp.plot(style=\"red\", ax=ax);\n",
    "ax.set_ylabel(\"Temperature (F)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weather_df.plot(kind='scatter', x='max_temp', y='min_temp');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\"> Breakout 4</font>\n",
    "Take the `weather_df` DataFrame to:\n",
    "\n",
    "1. Convert the `date` column values into datetime objects.\n",
    "2. Make the `date` column as the index.\n",
    "3. Plot the times series max and min temperatures on the same axes with the dates (ranging from November 2015 to March 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"green\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "\n",
    "# Question 1\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "\n",
    "# Question 2: Make the date (datetime object) as index\n",
    "weather_df.set_index(\"date\", inplace=True) \n",
    "\n",
    "# Question 3:\n",
    "#Select the date range\n",
    "slice_weather_df = slice_weather_df = weather_df['2015-11-01':'2016-04-01']\n",
    "\n",
    "# Plot\n",
    "ax = slice_weather_df.max_temp.plot(title=\"Min and Max Temperatures\", \n",
    "                                figsize=(12,6));\n",
    "slice_weather_df.min_temp.plot(style=\"red\", ax=ax);\n",
    "ax.set_ylabel(\"Temperature (F)\");\n",
    "``` \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Climate data</font>\n",
    "\n",
    "### <center>Global Surface Temperature Change based on Land and Ocean Data</center>\n",
    "\n",
    "Web scraping:\n",
    "\n",
    "[https://www.columbia.edu/~mhs119/Temperature/](https://www.columbia.edu/~mhs119/Temperature/)\n",
    "\n",
    "\n",
    "#### Reference\n",
    "\n",
    "- [http://pubs.giss.nasa.gov/docs/2010/2010_Hansen_ha00510u.pdf](http://pubs.giss.nasa.gov/docs/2010/2010_Hansen_ha00510u.pdf)\n",
    "- [https://data.giss.nasa.gov/gistemp/graphs_v4/](https://data.giss.nasa.gov/gistemp/graphs_v4/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
