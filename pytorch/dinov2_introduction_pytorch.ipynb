{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee93059e-f5a3-41c6-ade1-403dfadeea34",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Course Series</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h1><font color=\"red\">Introduction with DINOv2 with PyTorch</font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a6001-4b96-4469-850b-695c5858fdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1f453-e187-4de6-b104-9020f3d6cb33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81dde6eb-fba1-45ef-822a-19551972c42a",
   "metadata": {},
   "source": [
    "# <font color=\"blue\"> References</font>\n",
    "\n",
    "- [01.Meta-DinoV2-Getting Started](https://www.kaggle.com/code/shravankumar147/01-meta-dinov2-getting-started)\n",
    "- [DINOv2](https://huggingface.co/docs/transformers/en/model_doc/dinov2) from hugginface.co\n",
    "- [Building the DINO model from Scratch with PyTorch: Self-Supervised Vision Transformer](https://medium.com/thedeephub/self-supervised-vision-transformer-implementing-the-dino-model-from-scratch-with-pytorch-62203911bcc9) by Shubh Mishra\n",
    "- [How to Classify Images with DINOv2](https://blog.roboflow.com/how-to-classify-images-with-dinov2/) by James Gallagher (May 30, 2023\n",
    "- [Deploying DINOv2 to A Rest API Endpoint for Image Classification | Modelbit](https://colab.research.google.com/github/write-with-neurl/modelbit-09/blob/main/notebook/Deploying_DINOv2_for_Image_Classification_with_Modelbit.ipynb#scrollTo=q06RxQlCzQnG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a5f26-5033-4444-a129-adff062cdfa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a473f-5cde-41e6-8e94-a40d5ac67298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b6ef1-3d00-48fe-8188-2e314e6424cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee9121-22b9-49ec-95ef-daa5f6d64171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397cdb4e-ffbf-4e31-ae6a-aaebc7de842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DINOv2 model\n",
    "dinov2_vits14 = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vits14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c96753-645b-4e60-a2c7-d3f7f60a4fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CUDA if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c479ec-fd54-4f43-bf0c-ebd226166db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dinov2_vits14.to(device)\n",
    "dinov2_vits14.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca4d56-2fc2-4999-9b76-70ded2e27008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example image\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff97cf4-1f4c-46d6-8e0c-88c3ac15588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1fc78-fe5a-4bad-af8c-5a81be544867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_image = transform(image).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75e214-d3a0-43f4-91ba-3ade141fa4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "with torch.no_grad():\n",
    "    features = dinov2_vits14(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67abd99a-8884-4b4a-b38c-ca38a4fdff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(features.shape)\n",
    "# Expected output: torch.Size([1, 384]) for dinov2_vits14 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc5fb3-36a0-425c-a42f-6b10e9834fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
