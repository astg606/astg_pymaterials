{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71bce70-9dc3-448b-9f9a-8896e83b6d09",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Course Series</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "    <h1><font color=\"red\">Logistic Regression Classifier Model with PyTorch</font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770304be-1156-418e-b457-f70049a3f028",
   "metadata": {},
   "source": [
    "<h4>\n",
    "This presentation was adapted from the materials \n",
    "    (created by Sebastian Raschka) available at:\n",
    "\n",
    "<p>\n",
    "\n",
    "<center>\n",
    "<a href=\"https://github.com/rasbt/pycon2024\">PyCon US 2024: The Fundamentals of Modern Deep Learning with PyTorch</a>\n",
    "</center>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df4d162-122d-47d2-bdf4-45895a93bc6b",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Objectives</font>\n",
    "\n",
    "In this presentation, we:\n",
    "\n",
    "- Introduce the basic concept of PyTorch\n",
    "- Use a simple classification dataset to:\n",
    "   - Build a PyTorch model\n",
    "   - Train the model\n",
    "   - Evaluate the model\n",
    "\n",
    "We show the steps for building a Machine Learning (ML) model with PyTorch. The functions presented here can be used as reference for other ML applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec71f2-3cbc-42eb-a080-3b987b707390",
   "metadata": {},
   "source": [
    "# <font color=\"red\">References</font>\n",
    "\n",
    "- [PyTorch](https://pytorch.org/)\n",
    "- [What is PyTotch?](https://www.nvidia.com/en-us/glossary/pytorch/) from NVIDIA.\n",
    "- [What is PyTorch](https://www.ibm.com/think/topics/pytorch) by IBM\n",
    "- [Efficiently Building PyTorch Models: A Step-by-Step Guide](https://myscale.com/blog/efficient-pytorch-model-building-step-by-step-guide/) from myscale.com\n",
    "- [The Good and Bad of PyTorch Machine Learning Library](https://www.altexsoft.com/blog/pytorch-library/) from altexsoft.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0239364b-112d-4dae-9454-9e32a93e3c23",
   "metadata": {},
   "source": [
    "# <font color=\"red\">What is PyTorch?</font>\n",
    "\n",
    "- Open-source deep learning framework.\n",
    "- Povide a flexible and efficient platform for building and training neural networks.\n",
    "   - It has a dynamic computational graph that allows users to modify the architecture during runtime, making debugging and experimentation easier.\n",
    "- Written in Python and integrated with popular Python libraries like NumPy (for scientific computing), SciPy, and Cython (for compiling Python to C for better performance). \n",
    "- Support CPU, GPU, and parallel processing, as well as distributed training.\n",
    "   - PyTorch’s intuitive API and support for GPU acceleration make it ideal for building efficient feedforward networks, particularly in tasks such as image classification and digit recognition.\n",
    "- Excellent tool to learn and use for creating machnine learning models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f9f81-2937-4d2b-b501-98faaf162eb8",
   "metadata": {},
   "source": [
    "![fig_pytorch](https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/pytorch/img-1.png)\n",
    "Image reference: [https://pytorch.org/features/](https://pytorch.org/features/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5865fe-c542-470d-b862-7dc58f6956fb",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">How PyTorch works</font>\n",
    "\n",
    "The core components of PyTorch are:\n",
    "\n",
    "- __Tensors__\n",
    "   - A core PyTorch data type, similar to a multidimensional array, used to store and manipulate the inputs and outputs of a model, as well as the model’s parameters.\n",
    "   - They are similar to NumPy’s ndarrays, except that tensors can run on GPUs to accelerate computing.\n",
    "- __Graphs__\n",
    "   - Graphs are data structures consisting of connected nodes (called vertices) and edges.\n",
    "   - Neural Networks are represented as a graph structure of computations. They transform input data by applying a collection of nested functions to input parameters.\n",
    "   - The goal of deep learning is to optimize these parameters (weights and biases) by computing their partial derivatives (gradients) with respect to a loss metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f64c95-e3c9-44db-9198-ccb78bbc24a2",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">PyTorch main modules</font>\n",
    "\n",
    "- PyTorch uses modules as the building blocks of deep learning models, which allows for the quick and straightforward construction of neural networks without the tedious work of manually coding each algorithm.\n",
    "- There are three primary classes of modules used to build and optimize deep learning models in PyTorch:\n",
    "   - __nn modules__ are deployed as the layers of a neural network.\n",
    "      - The `torch.nn` package contains a large library of modules that perform common operations like convolutions, pooling and regression.\n",
    "   - The __autograd module__ provides a simple way to automatically compute gradients, used to optimize model parameters via gradient descent, for any function operated within a neural network.\n",
    "   - __Optim modules__ apply optimization algorithms to those gradients.\n",
    "      - The `torch.optim` package provides modules for various optimization methods, like stochastic gradient descent (SGD) or root mean square propagation (RMSprop), to suit specific optimization needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276aeca8-dff9-4cdf-8b2d-b61ad82c7ce9",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Basics of PyTorch model</font>\n",
    "\n",
    "A PyTorch model is constructed using two fundamental components that play crucial roles in defining and executing the neural network: \n",
    "\n",
    "- __init()__ Method:\n",
    "   - Serves as the constructor function for your model.\n",
    "   - Where you define all the layers that will be used in your neural network architecture. That is need to establish the structure of the model and initialize parameters such as weights and biases. \n",
    "- __forward()__ Method:\n",
    "   - Defines the actual computation that takes place when input data passes through each layer of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0b9ad8-ca26-418a-b051-7c24c787296d",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Steps for building a PyTorch model workflow</font>\n",
    "\n",
    "Implementating the following steps into building your first PyTorch model sets a solid foundation for creating sophisticated neural networks tailored to diverse applications.\n",
    "\n",
    "1. Define your model architecture\n",
    "   - Set the numbers of nodes in the input and output layers. The two parameters are the sizes of the features and the labels.\n",
    "   - Determine the number of layers and the function (linear, convolutional, or recurrent) associated to each layers.\n",
    "2. Data preprocessing to prepare the data\n",
    "   - Splitting into training and validation sets\n",
    "   - Normalizing the data (if needed)\n",
    "   - Creating data loaders\n",
    "3. Train your model\n",
    "   - Define the loss function\n",
    "   - Define the optimizer\n",
    "   - Write a loop to:\n",
    "      - Feed batches of data through your model\n",
    "      - Compute loss functions\n",
    "      - Optimize parameters with backpropagation\n",
    "      - Monitor performance metrics iteratively.\n",
    "4. Evaluate the model performance\n",
    "   - Test the model using unseen data and evaluate the performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242d89f-d9eb-4e8e-b05f-7a28aac277a3",
   "metadata": {},
   "source": [
    "![fig_workflow](https://www.scaler.com/topics/images/this-detailed-resource.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e02d09-9b14-4830-8973-f268ec8c2bb0",
   "metadata": {},
   "source": [
    "# <font color=\"red\"> Python packages used</font>\n",
    "\n",
    "- __Matplotlib__: Create visualization.\n",
    "- __Pandas__: Data (two-dimensional labelled array) manipulation and analysis.\n",
    "- __Scikit-Learn__:  Provide supervised and unsupervised Machine Learning algorithms.\n",
    "- __PyTorch__: Used to to build, train, and evaluate a deep machine learning algorithm based on Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40223c7-e654-45b5-bd57-03f788418db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355bc5a3-aa20-4097-bd46-50d31762eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17763b-8baf-40a2-9d71-825d42d82b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee059fe1-47c6-4011-908d-3d338bf70173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06afe3c-f18d-4b68-9ce0-92a34a085094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn import metrics\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775d10f-4277-4a1a-a01c-261ee032b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9549676-2fa5-41a7-bbb9-ce03f5797c34",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Loading the dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2194fb57-a0a2-455d-a6a9-a411684fd058",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Description of the data</font>\n",
    "\n",
    "- We have a dataset which features are points on a plane and the label has two values (classes).\n",
    "   - Each point is assigned a class (`0` or `1`).\n",
    "- We want to build a Machine Learning model to be able to predict the classes given a set of points.\n",
    "- We will use __logistic regression__ that is a statistical method for predicting binary classes.\n",
    "   - It is a special case of linear regression where the target variable is categorical in nature.\n",
    "   - It is one of the most simple and commonly used Machine Learning algorithms for two-class classification.\n",
    "   - The outcome or the target variable has only two possible classes.\n",
    "   - It predicts the probability of occurrence of a binary event utilizing a logit function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2778b4-e2b3-4a7c-8b8f-07e0e08a4501",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Read the data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e234697-87a6-42de-931f-d48621c1ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"classifier_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609024c-3eae-4ad5-8cb8-b95b403b7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_name, sep=\"\\s+\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46ff77-a7b3-4631-88ac-53605afba77d",
   "metadata": {},
   "source": [
    "##  <font color=\"blue\"> Splitting the data into training and testing sets</font>\n",
    "- We split the data into training and testing sets. \n",
    "- We train the model with 70% of the samples and test with the remaining 30%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d6d511-2795-4b6c-be25-f3d5c5766d77",
   "metadata": {},
   "source": [
    "__Extract the train and test datasets as NumPy arrays__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f93ae-dbf6-4b58-9402-02cda89127bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"x1\", \"x2\"]].values, \n",
    "                                                    df[\"label\"].values, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319546d0-e9ed-4542-873e-395edc05ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = df[[\"x1\", \"x2\"]].values\n",
    "#y_train = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71792068-9926-41bb-81c0-2a46f6e956fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2571853-0be0-48b2-9985-8a6021d01276",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e5ffb-1bca-4f1b-b4cf-a78be1b07753",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfbbf9-4fed-4111-8391-15f2b338d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6800df4-98f6-401e-bb6c-9964c3b6e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4663a6-e8a7-472e-b9b0-c64f546a85e9",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Visualize the data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b209b-1769-49f4-8aad-ad7b543fd9d6",
   "metadata": {},
   "source": [
    "__Scatterplot of $x_1$ against $x_2$__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721071e6-70d2-4676-89af-03dd7e1413ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:,0], X_train[:,1])\n",
    "plt.xlabel(r\"Feature $x_1$\", fontsize=10)\n",
    "plt.ylabel(r\"Feature $x_2$\", fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e2ee57-d692-4adf-ac3d-62e46bdfab30",
   "metadata": {},
   "source": [
    "__Scatterplot with the two classes: `y=0` and `y=1`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa611f4-75d7-4c47-a943-aeb44f5ebd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes(X: np.array, y: np.array, boundary: tuple=None) -> None:\n",
    "\n",
    "    plt.plot(X[y==0, 0], X[y==0, 1],\n",
    "        marker=\"D\", markersize=10,\n",
    "        linestyle=\"\", label=\"Class 0\",\n",
    "    )\n",
    "\n",
    "    plt.plot(X[y==1, 0], X[y==1, 1],\n",
    "        marker=\"^\", markersize=13,\n",
    "        linestyle=\"\", label=\"Class 1\",\n",
    "    )\n",
    "\n",
    "    if boundary:\n",
    "        plt.plot([boundary[0], boundary[1]], [boundary[2], boundary[3]], color=\"red\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlim([-5.5, 5.5])\n",
    "    plt.ylim([-5.5, 5.5])\n",
    "\n",
    "    plt.xlabel(r\"Feature $x_1$\", fontsize=12)\n",
    "    plt.ylabel(r\"Feature $x_2$\", fontsize=12)\n",
    "\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64376c-74f1-4bf5-8d7f-b0a63976696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b374d7-a932-4cf9-a9d1-a65301438d64",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Normailized the Data</font> <a class=\"anchor\" id=\"sec_tf_norm\"></a>\n",
    "\n",
    "- In general, variables may not be a similar scale. High values would gain more importance in any distance-based calculations. \n",
    "- It is good practice to normalize features that use different scales and ranges. \n",
    "- Although the model might converge without feature normalization, it makes training more difficult, and it makes the resulting model dependent on the choice of units used in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5080b6-f78b-43b5-b960-3b949da1276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122a1b8-68de-47fb-80a8-d5cba2ca0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = X_train.mean(axis=0)\n",
    "train_std = X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1277bd-e81d-46a7-94a1-d9e77b5b9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138f810-069d-44f3-ae65-de3ba13f0d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364e4f3-36a7-4b3c-be31-8388547654ee",
   "metadata": {},
   "source": [
    "__Normalization of the train features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ee619-625f-4d4e-bd24-5d0ce2888cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94729c0a-2b7c-45e3-9da2-d1192edfea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b26d2-b305-4cf0-86ff-f6529f8f865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2ccf2-025e-42c8-9171-3208b2f8db7e",
   "metadata": {},
   "source": [
    "__Normalization of the test features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb85ee-2afc-42a7-89f8-45c45fd376ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (X_test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42acd45-028c-41bc-8e78-e233d1d720b6",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Creating the ML model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56965881-aa98-43ac-afaf-540b8e6ec15f",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Set the hyperparameters</font>\n",
    "\n",
    "It is a good practice to declare the following parameters before creating the model for ease of change and understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa170e6-c30f-4567-be4a-d731cc18e6d6",
   "metadata": {},
   "source": [
    "__Dataset parameters__\n",
    "\n",
    "These parameters are defines by the dataset used:\n",
    "\n",
    "- number of features\n",
    "- number of classes to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bcc8d-3b6c-463d-a5be-3555f9243279",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199bec34-dab6-4479-bc5f-a44f0ef646bb",
   "metadata": {},
   "source": [
    "__Model parameters__\n",
    "\n",
    "- batch size\n",
    "- number of epochs\n",
    "- learning rate (optimizer steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08230641-70fa-4058-9507-e0efe5b20a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_epochs = 20\n",
    "learning_rate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50db02-3696-4f86-b149-74baabeec6c4",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Building the PyTorch model</font>\n",
    "\n",
    "__Class to create a simple model with one linear layer.__\n",
    "\n",
    "- We define a neural network by subclassing `nn.Module`, and initialize the neural network layers in `__init__`.\n",
    "- Every `nn.Module` subclass implements the operations on input data in the `forward` method.\n",
    "   - The `__init()__`  method defines the layers and other components of a model.\n",
    "   - The `forward()` method is where the computation gets done.\n",
    "- The input layer has `num_features` nodes and the output layer `num_classes` nodes.\n",
    "- The most basic type of neural network layer is a linear or fully connected layer.\n",
    "   - This is a layer where every input influences every output of the layer to a degree specified by the layer’s weights.\n",
    "   - If a model has `m` inputs and `n` outputs, the weights will be an `m x n` matrix.\n",
    "- One of the most common places you will see linear layers is in classifier models, which will usually have one or more linear layers at the end, where the last layer will have `n` outputs, where `n` is the number of classes the classifier addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da86d9a-7cd5-467c-bf65-3388fe272bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear1(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e643a50-b6f7-45ff-9bbe-2534aab2e33e",
   "metadata": {},
   "source": [
    "Note that we do not have any activation function here because there is only one layer:\n",
    "- Activation functions make deep learning possible.\n",
    "   - Inserting non-linear activation functions between layers is what allows a deep learning model to simulate any function, rather than just linear ones.\n",
    "- The model defined above can be seen as a single matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4915d06-3ae5-461f-9791-c84401b262ec",
   "metadata": {},
   "source": [
    "__Create the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b360e-c33c-4724-b46f-58323a9a7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "model = LogisticRegression(num_features=input_size, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077a5f1-762d-406f-8aa3-e4f93711eb95",
   "metadata": {},
   "source": [
    "__Print model information__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861aa7ad-0923-4fee-aa7b-4a45baba9863",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t Model information: \\n')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04be5b-dec4-4adf-a02c-99c56fa2004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t Layer information: \\n')\n",
    "print(model.linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad06c9-38ac-4723-b56b-6f4460ac5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t Model parameters: \\n')\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d8ff34-57ee-40e2-b432-274319e96b38",
   "metadata": {},
   "source": [
    "__Basic testing of the model wityh arbitrary data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2923ae0-cf24-4252-bd19-cc326a39bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1.1, 2.1],\n",
    "                  [1.1, 2.1],\n",
    "                  [9.1, 4.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da5e98-4bbd-4190-9bfe-5dde46aec7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(x)\n",
    "    probas = F.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa7eeb-2782-477e-80d1-532a520cebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12068721-daf9-4ea1-9240-5bcc19c75ce9",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Defining a DataLoader</font>\n",
    "\n",
    "- We pass the dataset to our dataloader, and our `batch_size` hyperparameter as initialization arguments.\n",
    "- This creates an iterable data loader, so we can easily iterate over each batch using a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6376d80-e7cf-43b4-96eb-bfd99709b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "\n",
    "        self.features = torch.tensor(X, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.features[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a9d65-294d-4c70-ab48-8bb9b9d706d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_data(Xdata: np.array, \n",
    "                     ydata: np.array, \n",
    "                     batch_size: int, \n",
    "                     shuffle: bool=False) -> DataLoader:\n",
    "    \"\"\"\n",
    "    Take the NumPy arrays for the features and labels to\n",
    "    create a PyTorch DataLoader object. It also subdivide\n",
    "    the arrays into groups of size batch_size. \n",
    "    If shuffle is set to True (for the training set only),\n",
    "    the data will be shuffled. It allows for stable training \n",
    "    and faster convergence of our model parameters.\n",
    "    \"\"\"\n",
    "    dataset = MyDataset(Xdata, ydata)\n",
    "    dataloader = DataLoader(dataset=dataset, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=shuffle)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192f1c4-a457-498d-a6ba-840baf85d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = instantiate_data(X_train, y_train, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f8926-930c-4945-950a-31083608ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238283f-1d02-427e-ab52-e6489de69064",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = instantiate_data(X_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc16a0-ec59-4c54-a209-0a5e22406287",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">The training loop</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90a8f3-71f8-4f89-87fd-e17355b00a20",
   "metadata": {},
   "source": [
    "__Define the loss function__\n",
    "\n",
    "- We use the Cross-Entropy Loss that is primarily used for multi-label classification models.\n",
    "- It first applies softmax to the predictions and calculates the given target labels and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a202ec04-4ea6-4b75-ab5d-3494f3e4c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc0006a-5d3c-4d1a-b6f2-3d2d3c55e25d",
   "metadata": {},
   "source": [
    "__Define the optimizer__\n",
    "\n",
    "- We use the SGD optimizer that implements the stochastic gradient descent method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581766d-b3f3-4788-b6cf-81defa0d8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d13c2-c9ee-441e-9afa-e2359d7cbe53",
   "metadata": {},
   "source": [
    "__Feed train data into the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcaa2b1-4019-4128-9ff5-6a966c3abdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model = model.train()\n",
    "    for batch_idx, (features, class_labels) in enumerate(train_loader):\n",
    "        # Predict outputs\n",
    "        outputs = model(features)\n",
    "\n",
    "        # Compute the loss function\n",
    "        loss = loss_function(outputs, class_labels)\n",
    "\n",
    "        # Reset and calculate gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        ### LOGGING\n",
    "        print(f'Epoch: {epoch+1:03d}/{num_epochs:03d}'\n",
    "               f' | Batch {batch_idx:03d}/{len(train_loader):03d}'\n",
    "               f' | Loss: {loss:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d5821-7c8d-46b5-9e7d-02e72cac2acc",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Evaluating the results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d910ddbb-798f-47ab-8aab-e2dba4aa4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "    \"\"\"\n",
    "    Compute the percentage of correct classification.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "\n",
    "    for idx, (features, class_labels) in enumerate(dataloader):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(features)\n",
    "\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "\n",
    "        compare = class_labels == pred\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return correct / total_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb64f5d-72e6-4ee6-9042-568e105ff0f2",
   "metadata": {},
   "source": [
    "__Evaluation on the train dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27538c8d-61bc-47b0-8289-b6aab4aa16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = compute_accuracy(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ecf35-4745-43a8-8ea8-14f71cba5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train accuracy: {train_acc*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dedfa00-3246-43e7-aa55-564a33dd5653",
   "metadata": {},
   "source": [
    "__Evaluation on the test dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26992a7-23ba-46c5-b7b2-4ec2689ce9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = compute_accuracy(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd84261-ffab-4357-8beb-19a08edaacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test accuracy: {test_acc*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd412a-02c0-4d2c-835e-4b01368f53f8",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Visualize the decision boundary</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f1813-d232-4a7d-aebc-cfd5303fae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(model):\n",
    "\n",
    "    w1 = model.linear1.weight[0][0].detach()\n",
    "    w2 = model.linear1.weight[0][1].detach()\n",
    "    b = model.linear1.bias[0].detach()\n",
    "\n",
    "    x1_min = -20\n",
    "    x2_min = (-(w1 * x1_min) - b) / w2\n",
    "\n",
    "    x1_max = 20\n",
    "    x2_max = (-(w1 * x1_max) - b) / w2\n",
    "\n",
    "    return x1_min, x1_max, x2_min, x2_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684fbe21-fdd8-4466-a8f3-349585995bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary = plot_boundary(model)\n",
    "boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c602a-ba37-48df-8a0a-31cf502441e8",
   "metadata": {},
   "source": [
    "__Classification on the train dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb1bdd-66c6-4d44-9463-4019761ade82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(X_train, y_train, boundary=boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb020dc-5df6-44c2-96a0-a766d725177e",
   "metadata": {},
   "source": [
    "__Classification on the test dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd89b15-1179-43bb-b5be-3fbd99cd2737",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(X_test, y_test, boundary=boundary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
