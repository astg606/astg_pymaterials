{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<CENTER>\n",
    "<H1> <font color=\"red\" size=\"+3\">\n",
    "    Web Scraping with Python</font>\n",
    "    <br>\n",
    "    Earth Science Applications\n",
    "</H1>\n",
    "</CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Reference Documents</font>\n",
    "\n",
    "- [Web Scraping: What It Is and How to Use It](https://scrape-it.cloud/blog/web-scraping-what-it-is-and-how-to-use-it)\n",
    "- [What is web scraping](https://www.scrapehero.com/a-beginners-guide-to-web-scraping-part-1-the-basics/)\n",
    "- [Python Requests Tutorial](http://zetcode.com/python/requests/)\n",
    "- [Python’s Requests Library (Guide](https://realpython.com/python-requests/)\n",
    "- [Download Files with Python](https://stackabuse.com/download-files-with-python/)\n",
    "- [Building a Web Scraper from start to finish](https://hackernoon.com/building-a-web-scraper-from-start-to-finish-bb6b95388184)\n",
    "- [Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup](https://www.learndatasci.com/tutorials/ultimate-guide-web-scraping-w-python-requests-and-beautifulsoup/)\n",
    "- [Beautiful Soup: Build a Web Scraper With Python](https://realpython.com/beautiful-soup-web-scraper-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Objectives</font>\n",
    "\n",
    "In this presentation, we use web scraping procedures to extract useful data from websites containing Earth Science related information. The website contents have JSON and HTML formats.\n",
    "\n",
    "We cover the following applications:\n",
    "\n",
    "\n",
    "1. MODIS Aerosol Optical Thickness\n",
    "2. Earth Observatory Natural Event Tracker (EONET)\n",
    "3. GISS global temperature\n",
    "4. Meteorite landings\n",
    "5. Weather forecast at a US location\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Web Scraping</font>\n",
    "\n",
    "> Web scraping is the process of programmatically and systematically collecting information on the web and processing it into more easily analyzable formats that can be serialized (json, xml, etc) and stored for later use.\n",
    "\n",
    "\n",
    "![fig_scrape](https://hasdata.com/_astro/web-scraping-process2.CS0dB9VW_17OsYb.webp)\n",
    "Image Source: [Sergey Ermakovich](https://hasdata.com/blog/web-scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Required Packages</font>\n",
    "We will need the three main Python packages:\n",
    "\n",
    "- `requests`: for accessing servers and getting the contents of web pages.\n",
    "- `json`: for manipulating JSON documents.\n",
    "- `BeautifupSoup`: for parsing the content of a HTML document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pprint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Requests version:  {reqs.__version__}\")\n",
    "print(f\"JSON version:      {json.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RED = '\\033[91m'\n",
    "GREEN = '\\033[92m'\n",
    "BLUE = '\\033[94m'\n",
    "RESET = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Python `requests` Module</font>\n",
    "\n",
    "* Requests is a built-in Python module.\n",
    "* Requests is a simple and elegant Python HTTP (Hypertext Transfer Protocol) library. \n",
    "* It provides methods for accessing Web resources via HTTP. \n",
    "* The HTTP request returns a Response Object with all the response data (content, encoding, status, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sending Parmeters in URL\n",
    "\n",
    "- We often ant to send some sort of data in the URL’s query string.\n",
    "- The `get()` method takes a `params` keyword argument where we can specify the query parameters.\n",
    "     - The beginning of the query parameters is denoted by a question mark (`?`).\n",
    "     - The pieces of information constituting one query parameter are encoded in key-value pairs, where related keys and values are joined together by an equals sign (`key=value`).\n",
    "     - Every URL can have multiple query parameters, which are separated from each other by an ampersand (`&`)\n",
    "\n",
    "If:\n",
    "```python\n",
    "   {'key1': value1, 'key2': value2, 'key2': value3}\n",
    "```\n",
    "is the dictionary of the parameters, and `https://MyOwnWebsite.com/` is the url, then the final url to access will be:\n",
    "```\n",
    "    https://MyOwnWebsite.com/?key1=value1&key2=value2&key3=value3\n",
    "```\n",
    "\n",
    "The code to reach the webpage is:\n",
    "```Python\n",
    "payload = {'key1': value1, 'key2': value2, 'key2': value3}\n",
    "resp = reqs.get(\"https://MyOwnWebsite.com\", params=payload)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_website(url: str, payload: dict = None, timeout: int = 10):\n",
    "    \"\"\"\n",
    "    Attempt to access a server. If the attempt is successful,\n",
    "    return the response object, otherwise return an error message.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "       HTTP address of the web page we want to access\n",
    "    payload : dict\n",
    "       Parameters needed to construct the target url.\n",
    "    timeout : int\n",
    "       Maximum number of seconds to access the web page.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    resp : object\n",
    "       Object which has infomation on the web page of interest.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if payload:\n",
    "            resp = reqs.get(url, params=payload, timeout=timeout)\n",
    "        else:\n",
    "            resp = reqs.get(url, timeout=timeout)\n",
    "        resp.raise_for_status()\n",
    "    except reqs.exceptions.HTTPError as errh:\n",
    "        print(f\"Http Error: {errh}\")\n",
    "    except reqs.exceptions.ConnectionError as errc:\n",
    "        print(f\"Error Connecting: {errc}\")\n",
    "    except reqs.exceptions.Timeout as errt:\n",
    "        print(f\"Timeout Error: {errt}\")\n",
    "    except reqs.exceptions.RequestException as err:\n",
    "        print(f\"General Error: {err}\")\n",
    "    else:\n",
    "        print(f\"Successfully accessed the site: \\n\\t {resp.url}\")\n",
    "        print(f\"Content type: \\n\\t {resp.headers['content-type']}\")\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 1: <font color=\"red\"> MODIS Aerosol Optical Thickness</font>\n",
    "\n",
    "- Scientists use measurements from the MODIS sensor aboard NASA's Terra and Aqua satellites to map the amount of aerosol that is in the air all over the world. Because aerosols reflect visible and near-infrared light back to space, scientists can use satellites to make maps of where there are high concentrations of these particles.\n",
    "- Scientists call this measurement aerosol optical thickness (AOT). \n",
    "- It is a measure of how much light the airborne particles prevent from traveling through the atmosphere. \n",
    "- Aerosols absorb and scatter incoming sunlight, thus reducing visibility and increasing optical thickness. An optical thickness of less than 0.1 indicates a crystal clear sky with maximum visibility, whereas a value of 1 indicates the presence of aerosols so dense that people would have difficulty seeing the Sun, even at mid-day!\n",
    "\n",
    "\n",
    "In this example, we want to access the <a href=\"https://neo.gsfc.nasa.gov/\">NASA Earth Observations (NEO)</a> website to obtain the AOT measurements for a given day or a range of days (from 2000 to present)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Manipulating data for a day</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Access the website__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aot_url = \"https://neo.gsfc.nasa.gov/view.php\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'datasetId': 'MODAL2_M_AER_OD',\n",
    "    'date': '2024-12-01'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aot_source = access_website(aot_url, payload=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parse the webpage and print its content__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aot_soup = bso(aot_source.text, 'html.parser')\n",
    "print(aot_soup.prettify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gather all the lines with `href` tag__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "href_tags = aot_soup.find_all(href=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find the `http` address that has the word `CSV`. That will give us the remote location of the file we want to read.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in href_tags:\n",
    "    loc_url = tag[\"href\"]\n",
    "    if \"csv\" in loc_url.lower():\n",
    "        csv_url = loc_url\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Clean the url__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_after_substring(text: str, substring: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove all characters in text after the substring.\n",
    "    \"\"\"\n",
    "    index = text.find(substring)\n",
    "    if index != -1:\n",
    "        return \"\".join([text[:index], substring])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url = remove_after_substring(csv_url, 'CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Access the remote file and use `Pandas` to read its content__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = access_website(csv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = io.StringIO(resp.content.decode('utf-8'))\n",
    "pd.read_csv(file_object, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The labels for the columns are the longitude values.\n",
    "- The labels for the rows are the latitude values.\n",
    "- **It seems that `99999.0` corresponds to a missing value. We replace it with `NaN`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = io.StringIO(resp.content.decode('utf-8'))\n",
    "df = pd.read_csv(file_object, index_col=0, na_values=99999.0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We convert the Pandas `DataFrame` into a Xarray `DataArray`__\n",
    "\n",
    "- The dimensions are `latitude` and `longitude`.\n",
    "- The coordinates are the latitude values (row labels) and longitude values (column labels).\n",
    "- The data values are the DataFrame values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_values = [float(lat) for lat in df.index]\n",
    "lon_values = [float(lon) for lon in df.columns]\n",
    "\n",
    "da = xr.DataArray(\n",
    "    df.values,\n",
    "    coords = [lat_values, lon_values],\n",
    "    dims = ['latitude', 'longitude']\n",
    ")\n",
    "\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic plot__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"purple\">Breakout 1</font>\n",
    "\n",
    "- Take an arbitrary past date (`YYYY-MM-DD`).\n",
    "- Access the database to extract the CSV file.\n",
    "- Read the CSV file and create the Xarray object.\n",
    "- Plot the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Manipulating time series data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_link(href_tags: list) -> str:\n",
    "    for tag in href_tags:\n",
    "        loc_url = tag[\"href\"]\n",
    "        if \"csv\" in loc_url.lower():\n",
    "           csv_url = loc_url\n",
    "           break\n",
    "    csv_url = remove_after_substring(csv_url, 'CSV')\n",
    "    return csv_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(url: str, payload: dict):\n",
    "    aot_source = access_website(url, payload=payload)\n",
    "    aot_soup = bso(aot_source.text, 'html.parser')\n",
    "    time.sleep(1)\n",
    "    href_tags = aot_soup.find_all(href=True)\n",
    "    csv_url = get_csv_link(href_tags)\n",
    "    \n",
    "    resp = access_website(csv_url, timeout=25)\n",
    "    file_object = io.StringIO(resp.content.decode('utf-8'))\n",
    "    df = pd.read_csv(file_object, index_col=0, na_values=99999.0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_da(df):\n",
    "    lat_values = [float(lat) for lat in df.index]\n",
    "    lon_values = [float(lon) for lon in df.columns]\n",
    "\n",
    "    da = xr.DataArray(\n",
    "        df.values,\n",
    "        coords = [lat_values, lon_values],\n",
    "        dims = ['latitude', 'longitude']\n",
    "    )\n",
    "    return da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Combine the data into a Xarray Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_date = '2024-12-01'\n",
    "end_date = '2024-12-02'\n",
    "\n",
    "dates = pd.date_range(start=beg_date, end=end_date, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = list()\n",
    "\n",
    "for date in dates:\n",
    "    print(f'\\t Working on: {date}')\n",
    "    payload = {'datasetId': 'MODAL2_M_AER_OD', 'date': date.strftime('%Y-%m-%d')}\n",
    "    df = create_df(aot_url, payload)\n",
    "    da = create_da(df)\n",
    "    da = da.assign_coords(time = date)\n",
    "    da = da.expand_dims(dim=\"time\")\n",
    "    arrays.append(da)\n",
    "    time.sleep(3)\n",
    "\n",
    "ds = xr.combine_by_coords(arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.plot(x=\"longitude\", y=\"latitude\",\n",
    "                col=\"time\", col_wrap=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Time average__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.mean(dim='time').plot(figsize=(10, 6), cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Zoom over the USA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = ds.sel(latitude=slice(50.05, 20.05),\n",
    "                 longitude=slice(-125.05, -66.50))\n",
    "usa.mean(dim='time').plot(cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 2: <font color=\"red\">Global temperature</font>\n",
    "\n",
    "- The [GISS Surface Temperature Analysis ](https://data.giss.nasa.gov/gistemp/) is an estimate of global surface temperature change.\n",
    "- Graphs and tables are updated about the 10th of every month using current data files from a variety of sources.\n",
    "\n",
    "__Objectives__\n",
    "\n",
    "- Read the data available at the [Monthly and Annual Temperature Tables](https://www.columbia.edu/~mhs119/Temperature/Table_Ts.1880-2024vs1880-1920.txt)\n",
    "- Perform visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Access the webpage__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_url = \"https://www.columbia.edu/~mhs119/Temperature/Table_Ts.1880-2024vs1951-1980.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_response = access_website(temp_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We observe that the content type is `text/plain`, i.e. we are dealing we are dealing with simple text (string)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__View the content of the webpage__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(temp_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temp_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extract the content to create a Pandas DataFrame__\n",
    "\n",
    "- We use the `io.StringIO` function to takes a string and returns a file object.\n",
    "- The file object is passed to the `pd.read_csv` function to return a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = io.StringIO(temp_response.text)\n",
    "temp_df = pd.read_csv(\n",
    "    file_object, \n",
    "    sep=r\"\\s+\", \n",
    "    skiprows=3,           # skip the first 3 rows\n",
    "    skipfooter=7,         # skip the last 7 rows\n",
    "    index_col=0,          # make the first column as index (labels of the rows)\n",
    "    na_values=\"*****\",    # deal with missing values\n",
    "    engine='python'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plot the temperature data for each year__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[list(temp_df.columns)[:-1]].T.plot(xlabel=\"Month\", ylabel=\"Temperature\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(i) for i in range(1880, 2024, 20)]\n",
    "years.append('2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf2 = temp_df[list(temp_df.columns)[:-1]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycolumns = [\"\".join([\"_\", str(y)]) for y in mydf2.columns]\n",
    "columns = list()\n",
    "for c in mycolumns:\n",
    "    if c[1:] in years:\n",
    "        columns.append(c[1:])\n",
    "    else:\n",
    "        columns.append(c)\n",
    "mydf2.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = mydf2.plot(xlabel=\"Month\", ylabel=\"Temperature\")\n",
    "ax.legend(bbox_to_anchor=(1.25, 1.02), loc='upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plot the temperature data for selected years__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [i for i in range(1880, 2024, 20)]\n",
    "years.append(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = temp_df.loc[years][list(temp_df.columns)[:-1]].T.plot(xlabel=\"Month\", \n",
    "                                                           ylabel=\"Temperature\")\n",
    "ax.legend(bbox_to_anchor=(1.25, 1.02), loc='upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Temperature plots by month__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[list(temp_df.columns)[:-1]].plot(figsize=(10, 13), subplots=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plot time series of annual temperatures__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots()\n",
    "\n",
    "mydf = temp_df[\"Annual\"].iloc[:-1].astype(float)\n",
    "axes.scatter(mydf.index, mydf.values, marker='o', c='k', s=3)\n",
    "axes.plot(mydf.index, mydf.values, label='12-month Running Mean')\n",
    "axes.set_xlabel(\"Year\")\n",
    "axes.set_ylabel(r\"Temperature analomaly ($^o$C)\");\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application 3: <font color=\"red\">Earth Observatory Natural Event Tracker (EONET)</font>\n",
    "\n",
    "- EONET is a repository of metadata about natural events.\n",
    "- We want to be able to browse the webpage [https://eonet.gsfc.nasa.gov/api/v3/events](https://eonet.gsfc.nasa.gov/api/v3/events), to gather information on recent natural events on Earth.\n",
    "\n",
    "**Query Parameters**\n",
    "\n",
    "| Parameter | Value(s) |  Description |\n",
    "| --- | --- | --- |\n",
    "|`source` | Source ID | Filter the returned events by the [Source](https://eonet.gsfc.nasa.gov/api/v3/sources). Multiple sources can be included in the parameter: comma separated, operates as a boolean `OR`. |\n",
    "|`category` | Category ID | Filter the returned events by the category. |\n",
    "|`status` | open or closed | Events that have ended are assigned a closed date and the existence of that date will allow you to filter for only-open or only-closed events. Omitting the status parameter will return only the currently open events. |\n",
    "| `limit` | int | Limits the number of events returned |\n",
    "| `days ` | int | Limit the number of prior days (including today) from which events will be returned. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sample sources__:\n",
    "\n",
    "- `EO`: [Earth Observatory](https://earthobservatory.nasa.gov/)\n",
    "- `Earthdata`: [NASA Earth Observation Data](https://earthdata.nasa.gov)\n",
    "- `FEMA`: [Federal Emergency Management Agency (FEMA)](https://www.fema.gov/)\n",
    "- `JTWC`: [Joint Typhoon Warning Center](http://www.metoc.navy.mil/jtwc/jtwc.html)\n",
    "- `NASA_ESRS`: [NASA Earth Science and Remote Sensing Unit](https://eol.jsc.nasa.gov/ESRS/)\n",
    "- `NASA_HURR`: [NASA Hurricane And Typhoon Updates](https://blogs.nasa.gov/hurricanes/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Access the database</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eonet_url = \"https://eonet.gsfc.nasa.gov/api/v3/events\"\n",
    "eonet_source = \"EO,JTWC,Earthdata,FEMA\"\n",
    "eonet_payload = {\n",
    "    'source': eonet_source,\n",
    "    'status': \"open\",\n",
    "    'limit': 100,\n",
    "    'days': 180\n",
    "}\n",
    "\n",
    "page_content = access_website(eonet_url, eonet_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eonet_page = json.loads(page_content.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in eonet_page:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(eonet_page['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(eonet_page['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">List the events</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(eonet_page['events'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eonet_page['events'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in eonet_page['events']:\n",
    "    print(event['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Analyze one event</font>\n",
    "\n",
    "- We use `Pandas`, `GeoPandas` and `MovingPandas` to track the movement of an event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = eonet_page['events'][0]\n",
    "print(event['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a Pandas DataFrame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['latitude', 'longitude', 't']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for geom in event['geometry']:\n",
    "    lat = geom['coordinates'][1]\n",
    "    lon = geom['coordinates'][0]\n",
    "    date = geom['date']\n",
    "    row = dict(latitude=lat, longitude=lon, t=date)\n",
    "    df.loc[len(df)] = row\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t'] = pd.to_datetime(df['t'], format = '%Y-%m-%dT%H:%M:%SZ')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['geometry'] = [Point(xy) for xy in zip(df.longitude, df.latitude)] \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a GeoPandas GeoDataFrame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(df)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a MovingPandas Trajectory__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = mpd.Trajectory(gdf, 1)\n",
    "mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compute the distance and the speed__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.add_distance(overwrite=True, name=\"distance\", units=\"mi\")\n",
    "mdf.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.add_speed(overwrite=True, \n",
    "                      name=\"speed\", units=(\"mi\", \"h\"))\n",
    "\n",
    "mdf.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plot the trajectory__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.hvplot(tiles=\"ESRI\",\n",
    "           c=\"speed\",\n",
    "           title=event['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"purple\">Breakout</font>\n",
    "\n",
    "- Go to the sitethe website `https://eonet.gsfc.nasa.gov/api/v3/events`\n",
    "- Select a date range and the number of events you want to retrieve.\n",
    "- Creade a Pandas DataFrame that contains as columns the event type, date, latitude and longitude.\n",
    "\n",
    "```python\n",
    "url = \"https://eonet.gsfc.nasa.gov/api/v3/events\"\n",
    "payload = {'source': \"EO\",\n",
    "          'status': \"open\",\n",
    "          'limit': 6,\n",
    "          'days': 100}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"green\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "import json\n",
    "\n",
    "url = \"https://eonet.gsfc.nasa.gov/api/v3/events\"\n",
    "payload = {'source': \"EO\",\n",
    "          'status': \"open\",\n",
    "          'limit': 6,\n",
    "          'days': 100}\n",
    "\n",
    "page_content = reqs.get(url, params=payload)\n",
    "\n",
    "if page_content.status_code == 200:\n",
    "    json_page = json.loads(page_content.text)\n",
    "\n",
    "for x in json_page:\n",
    "    print(x)\n",
    "\n",
    "list_events = json_page['events']\n",
    "\n",
    "print(f\"Number of events: {len(list_events)}\")\n",
    "print(f\"List of events: \\n {list_events}\")\n",
    "\n",
    "event_types = [evt['categories'][0]['title'] for evt in list_events]\n",
    "event_dates = [evt['geometries'][0]['date'] for evt in list_events]\n",
    "event_lons = [evt['geometries'][0]['coordinates'][0] for evt in list_events]\n",
    "event_lats = [evt['geometries'][0]['coordinates'][1] for evt in list_events]\n",
    "\n",
    "print()\n",
    "\n",
    "df_events = pd.DataFrame({\n",
    "    \"Type\": event_types,\n",
    "    \"Dates\": event_dates,\n",
    "    #\"Latitudes\": event_lats,\n",
    "    \"Longitudes\":event_lons\n",
    "})\n",
    "df_events\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application 4: <font color='red'>Meteorite Landings</font>\n",
    "\n",
    "- Meteorite impacts can have effects on the climate,\n",
    "   - The size and velocity of the impacting body determine the amount of energy released.\n",
    "   - While most impacts are small and have minimal effects, larger impacts can have far-reaching consequences.\n",
    "   - Impacts from asteroids and comets can generate more atmospheric dust than large volcanic explosions.\n",
    "- The Meteoritical Society maintains a comprehensive [data set](https://datasets.ai/datasets/meteorite-landings-api) that contains information on all of the known meteorite landings.\n",
    "- We want to access the data set and perform analyses.\n",
    "\n",
    "A more comprehensive analyses can be found at: \n",
    "\n",
    "[Meteorite Landings Per Country Using Geopandas](https://github.com/msikorski93/Meteorite-Landings/blob/main/world_geopandas.ipynb)\n",
    "\n",
    "[Meteorite Landings](https://github.com/msikorski93/Meteorite-Landings/blob/main/meteorites_landings.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Read the meteorite dataset</font>\n",
    "\n",
    "We read the first 1000 rows of the database.\n",
    "\n",
    "To read additional rows you can consult the webpage:\n",
    "\n",
    "[How to query more than 1000 rows of a dataset](https://support.socrata.com/hc/en-us/articles/202949268-How-to-query-more-than-1000-rows-of-a-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_url = \"https://data.nasa.gov/resource/gh4g-9sfh.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_resp = access_website(meteorite_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convert the JSON object into a Python object__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_page = json.loads(meteorite_resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(meteorite_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(meteorite_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_page[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a Pandas DataFrame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_keys = list(meteorite_page[0].keys())\n",
    "list_keys = list_keys[:-1]\n",
    "list_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df = pd.DataFrame(columns=list_keys)\n",
    "meteorite_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_val = \"-99999\"\n",
    "\n",
    "for item in meteorite_page:\n",
    "    data = list()\n",
    "    for key in list_keys:\n",
    "        try:\n",
    "            data.append(item[key])\n",
    "        except:\n",
    "            data.append(missing_val)\n",
    "    meteorite_df.loc[len(meteorite_df)] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Perform data profiling</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dealing with missing values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.replace(missing_val, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Type conversion__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df['id'] = meteorite_df['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['mass', 'reclat', 'reclong']\n",
    "meteorite_df[cols] = meteorite_df[cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df['year'] = pd.to_datetime(meteorite_df['year'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a `geometry` column__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df['geometry'] = [Point(xy) for xy in zip(meteorite_df.reclong, meteorite_df.reclat)] \n",
    "meteorite_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a GeoPandas GeoDataFrame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_gdf = gpd.GeoDataFrame(meteorite_df, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Count values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df['fall'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df['fall'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Examine the classes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df['recclass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Barplot__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "# create list of labels\n",
    "class_labels = meteorite_df['recclass'].value_counts().head(n).tolist()\n",
    "\n",
    "meteorite_df['recclass'].value_counts().head(n).plot(kind='barh', title=f'Top {n} Meteorite Classes', width=0.9, figsize=(10, 5))\n",
    "plt.grid(axis='x', alpha=0.5)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# add count values from list\n",
    "for i, v in enumerate(class_labels):\n",
    "    plt.text(x=v+3, y=i+0.25, s=str(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pie chart__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "# extract dataset by labels\n",
    "meteo_class = meteorite_df['recclass'].value_counts().head(n)\n",
    "\n",
    "# pie plot\n",
    "meteo_class.plot(kind='pie', title=f'Top {n} Meteorite Classes', figsize=(7, 7))\n",
    "plt.pie(meteo_class, wedgeprops = {'linewidth': 3, 'edgecolor': 'white'})\n",
    "\n",
    "# insert circle\n",
    "circle = plt.Circle((0, 0), 0.6, color='white')\n",
    "plt.gcf().gca().add_artist(circle);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Another barplot__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of labels\n",
    "fall_labels = meteorite_df['fall'].value_counts().tolist()\n",
    "\n",
    "# bar plot - 'fall' labels\n",
    "meteorite_df['fall'].value_counts().plot.bar()\n",
    "\n",
    "# add count values from list\n",
    "for i, v in enumerate(fall_labels):\n",
    "    plt.text(x=i, y=v, s=str(v), ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Histogram of mass distribution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram by 'fall' labels\n",
    "falls = meteorite_df.groupby('fall')\n",
    "\n",
    "for name, group in falls:\n",
    "    plt.hist(x=group['mass'], bins=10**np.linspace(-7, 7), alpha=0.5)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('log [mass]')\n",
    "plt.legend(['Fell','Found'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Year distribution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot by 'fall' label\n",
    "for i in ['Found', 'Fell']:\n",
    "    pd.pivot_table(meteorite_df[meteorite_df['fall'] == i], \n",
    "                   index='year', values='name', \n",
    "                   aggfunc='count').plot(title=f'year vs {i}', ylabel=f'Num. of {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scatter plot: year over latitude__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.plot(kind=\"scatter\", x=\"year\", y=\"reclat\", figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scatter plot: year over mass__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.plot(kind=\"scatter\", x=\"year\", y=\"mass\", logy=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scatter plot: year over mass (with colors)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x=meteorite_df['year'], \n",
    "            y=meteorite_df['mass'], c=np.log10(meteorite_df['mass']), \n",
    "            cmap='gist_earth', alpha=0.7\n",
    "           )\n",
    "plt.yscale('log')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('mass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Create maps</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Include the world map__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_url = url = \"https://naciscdn.org/naturalearth/110m/cultural/ne_110m_admin_0_countries.zip\"\n",
    "world_gdf = gpd.read_file(world_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_gdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_gdf = gpd.GeoDataFrame(meteorite_df)\n",
    "meteorite_gdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15, 10))\n",
    "world_gdf.boundary.plot(ax=axes)\n",
    "meteorite_gdf.plot(ax=axes, marker='o', color='red', markersize=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_gdf['CONTINENT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "north_america = world_gdf[world_gdf['CONTINENT'] == 'North America']\n",
    "asia = world_gdf[world_gdf['CONTINENT'] == 'Asia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_meteorite= gpd.sjoin(meteorite_gdf, north_america, \n",
    "                           how='inner', predicate='intersects')\n",
    "na_meteorite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15, 10))\n",
    "north_america.boundary.plot(ax=axes)\n",
    "na_meteorite.plot(ax=axes, marker='o', color='red', markersize=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = north_america.explore() # world_gdf.explore()\n",
    "na_meteorite.explore(\n",
    "    m=m, \n",
    "    column=\"mass\", \n",
    "    cmap=\"viridis_r\",\n",
    "    #style_kwds={\"style_function\":lambda x: {\"radius\":x[\"properties\"][\"mass\"]}}\n",
    ") #color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 5: <font color=\"red\"> Extract weather data</font>\n",
    "\n",
    "- We access the web site [www.weather.gov/](https://www.weather.gov/) to extract the weather forecast information for the city of Greenbelt, Maryland."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Access the web page__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_url = \"https://forecast.weather.gov/MapClick.php\"\n",
    "\n",
    "greenbelt_lat = 39.00079000000005\n",
    "greenbelt_lon = -76.88055999999995\n",
    "\n",
    "weather_params = {\n",
    "    'lat': greenbelt_lat,\n",
    "    'lon': greenbelt_lon\n",
    "}\n",
    "\n",
    "weather_source = access_website(weather_url, weather_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_soup = bso(weather_source.text, 'html.parser')\n",
    "#print(weather_soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract Tonight's Forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_day = weather_soup.find(id=\"seven-day-forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in forecast_items:\n",
    "    if item.find(class_=\"period-name\").get_text() == \"Tonight\":\n",
    "        tonight = item\n",
    "        break\n",
    "\n",
    "print(tonight.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = tonight.find(class_=\"period-name\").get_text()\n",
    "print(f\"\\t {GREEN} {period} {RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_desc = tonight.find(class_=\"short-desc\").get_text()\n",
    "print(f\"\\t {GREEN} {short_desc} {RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tonight.find(class_=\"temp\").get_text()\n",
    "print(f\"\\t {GREEN} {temp} {RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tonight.find(\"img\")\n",
    "desc = img['title']\n",
    "print(f\"\\t {GREEN} {desc} {RESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting all data**\n",
    "\n",
    "We use CSS selectors to extract everything at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select all items with the class `period-name` inside an item with the class `tombstone-container` in `seven_day`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_tags = seven_day.select(\".tombstone-container .period-name\")\n",
    "periods = [pt.get_text() for pt in period_tags]\n",
    "for item in periods:\n",
    "    print(f\"\\t {GREEN} {item.strip()} {RESET}\")\n",
    "#print(f\"\\t {GREEN} {periods} {RESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get text from `short-desc` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_descs = [sd.get_text() for sd in seven_day.select(\".tombstone-container .short-desc\")]\n",
    "for item in short_descs:\n",
    "    print(f\"\\t {GREEN} {item.strip()} {RESET}\")\n",
    "#print(f\"\\t {GREEN} {short_descs} {RESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get text from `temp` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\n",
    "for item in temps:\n",
    "    print(f\"\\t {GREEN} {item.strip()} {RESET}\")\n",
    "#print(f\"\\t {GREEN} {temps} {RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]\n",
    "for item in descs:\n",
    "    print(f\"\\t {GREEN} {item.strip()} {RESET}\")\n",
    "#print(f\"\\t {GREEN} {descs} {RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(temps) < len(descs):\n",
    "    temps = [\" \"] + temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the data into a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_dict = dict(\n",
    "    Period=periods, \n",
    "    Temperature=temps,\n",
    "    Short_Description=short_descs,  \n",
    "    Description=descs\n",
    ")\n",
    "df_weather = pd.DataFrame(forecast_dict)\n",
    "df_weather = df_weather.set_index(\"Period\")\n",
    "df_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detailed Forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_forecast = weather_soup.find(id=\"detailed-forecast-body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_labels = det_forecast.find_all(class_=\"col-sm-2 forecast-label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_texts = det_forecast.find_all(class_=\"col-sm-10 forecast-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in zip(forecast_labels, forecast_texts):\n",
    "    print(f\"{GREEN} {a.get_text():>15}: {RESET} {b.get_text():<}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
