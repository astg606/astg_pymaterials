{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<CENTER>\n",
    "<H1> <font color=\"red\" size=\"+3\">\n",
    "    Web Scraping with Python</font>\n",
    "    <br>\n",
    "    Earth Science Applications\n",
    "</H1>\n",
    "</CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Reference Documents</font>\n",
    "\n",
    "- [Web Scraping: What It Is and How to Use It](https://scrape-it.cloud/blog/web-scraping-what-it-is-and-how-to-use-it)\n",
    "- [What is web scraping](https://www.scrapehero.com/a-beginners-guide-to-web-scraping-part-1-the-basics/)\n",
    "- [Python Requests Tutorial](http://zetcode.com/python/requests/)\n",
    "- [Python’s Requests Library (Guide](https://realpython.com/python-requests/)\n",
    "- [Download Files with Python](https://stackabuse.com/download-files-with-python/)\n",
    "- [Building a Web Scraper from start to finish](https://hackernoon.com/building-a-web-scraper-from-start-to-finish-bb6b95388184)\n",
    "- [Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup](https://www.learndatasci.com/tutorials/ultimate-guide-web-scraping-w-python-requests-and-beautifulsoup/)\n",
    "- [Beautiful Soup: Build a Web Scraper With Python](https://realpython.com/beautiful-soup-web-scraper-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Objectives</font>\n",
    "\n",
    "In this course, we want to describe web scraping and show how it can be accomplished with Python. We present the basic steps of web scraping and run examples on accessing HTTP servers, grabbing the content of web pages (in JSON and HTML formats), parsing the content to extract useful information and performing analyses.\n",
    "\n",
    "The following topics will be covered:\n",
    "\n",
    "+ What is web scraping?\n",
    "+ Components of a web page\n",
    "+ Accessing Web Pages with `requests`\n",
    "+ Web Scraping with `Json`\n",
    "+ Web Scraping with `Beautiful Soup`\n",
    "\n",
    "We expect that at end of this presentation, participants will be able to write Python scripts that automatically perform web scraping to extract specific data from webpages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Web Scraping</font>\n",
    "\n",
    "> Web scraping is a mechanism of collecting large amounts of data from a webpage and store the data into any required format which further helps us to perform analysis on the extracted data.\n",
    "\n",
    "\n",
    "Web scraping involves a three-step process:\n",
    "\n",
    "1. **Step 1**: Send an HTTP request to the webpage\n",
    "   - The server responds to the request by returning the (JSON, HTML, etc.) content of the target webpage.\n",
    "2. **Step 2**: Parse the webpage content\n",
    "   - A parser is needed to create a nested structure of the data. \n",
    "3. **Step 3**: Pull out useful data out\n",
    "   - We use Python packages such as Json and Beautiful Soup to pull out data and store them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Required Packages</font>\n",
    "We will need the three main Python packages:\n",
    "\n",
    "- `requests`: for accessing servers and getting the contents of web pages.\n",
    "- `json`: for manipulating JSON documents.\n",
    "- `BeautifupSoup`: for parsing the content of a HTML document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Requests version:  {reqs.__version__}\")\n",
    "print(f\"JSON version:      {json.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Python `requests` Module</font>\n",
    "\n",
    "* Requests is a built-in Python module.\n",
    "* Requests is a simple and elegant Python HTTP (Hypertext Transfer Protocol) library. \n",
    "* It provides methods for accessing Web resources via HTTP. \n",
    "* The HTTP request returns a Response Object with all the response data (content, encoding, status, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sending Parmeters in URL\n",
    "\n",
    "- We often ant to send some sort of data in the URL’s query string.\n",
    "- The `get()` method takes a `params` keyword argument where we can specify the query parameters.\n",
    "     - The beginning of the query parameters is denoted by a question mark (`?`).\n",
    "     - The pieces of information constituting one query parameter are encoded in key-value pairs, where related keys and values are joined together by an equals sign (`key=value`).\n",
    "     - Every URL can have multiple query parameters, which are separated from each other by an ampersand (`&`)\n",
    "\n",
    "If:\n",
    "```python\n",
    "   {'key1': value1, 'key2': value2, 'key2': value3}\n",
    "```\n",
    "is the dictionary of the parameters, and `https://MyOwnWebsite.com/` is the url, then the final url to access will be:\n",
    "```\n",
    "    https://MyOwnWebsite.com/?key1=value1&key2=value2&key3=value3\n",
    "```\n",
    "\n",
    "The code to reach the webpage is:\n",
    "```Python\n",
    "payload = {'key1': value1, 'key2': value2, 'key2': value3}\n",
    "resp = reqs.get(\"https://MyOwnWebsite.com\", params=payload)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_website(url: str, payload: dict = None, timeout: int = 10):\n",
    "    \"\"\"\n",
    "    Attempt to access a server. If the attempt is successful,\n",
    "    return the response object, otherwise return an error message.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "       HTTP address of the web page we want to access\n",
    "    payload : dict\n",
    "       Parameters needed to construct the target url.\n",
    "    timeout : int\n",
    "       Maximum number of seconds to access the web page.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    resp : object\n",
    "       Object which has infomation on the web page of interest.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if payload:\n",
    "            resp = reqs.get(url, params=payload, timeout=timeout)\n",
    "        else:\n",
    "            resp = reqs.get(url, timeout=timeout)\n",
    "        resp.raise_for_status()\n",
    "    except reqs.exceptions.HTTPError as errh:\n",
    "        print(f\"Http Error: {errh}\")\n",
    "    except reqs.exceptions.ConnectionError as errc:\n",
    "        print(f\"Error Connecting: {errc}\")\n",
    "    except reqs.exceptions.Timeout as errt:\n",
    "        print(f\"Timeout Error: {errt}\")\n",
    "    except reqs.exceptions.RequestException as err:\n",
    "        print(f\"General Error: {err}\")\n",
    "    else:\n",
    "        print(\"Successfully accessed the site!\")\n",
    "    \n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Application 1</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Meteorite Landings</font>\n",
    "\n",
    "- Meteorite impacts can have effects on the climate,\n",
    "   - The size and velocity of the impacting body determine the amount of energy released.\n",
    "   - While most impacts are small and have minimal effects, larger impacts can have far-reaching consequences.\n",
    "   - Impacts from asteroids and comets can generate more atmospheric dust than large volcanic explosions.\n",
    "- The Meteoritical Society maintains a comprehensive [data set](https://datasets.ai/datasets/meteorite-landings-api) that contains information on all of the known meteorite landings.\n",
    "- We want to access the data set and perform analyses.\n",
    "\n",
    "A more comprehensive analyses can be found at: \n",
    "\n",
    "[Meteorite Landings Per Country Using Geopandas](https://github.com/msikorski93/Meteorite-Landings/blob/main/world_geopandas.ipynb)\n",
    "\n",
    "[Meteorite Landings](https://github.com/msikorski93/Meteorite-Landings/blob/main/meteorites_landings.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_url = \"https://data.nasa.gov/resource/gh4g-9sfh.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_resp = access_website(meteorite_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Content type: \\n\\t {meteorite_resp.headers['content-type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_page = json.loads(meteorite_resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(meteorite_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(meteorite_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_page[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_keys = list(meteorite_page[0].keys())\n",
    "list_keys = list_keys[:-1]\n",
    "list_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df = pd.DataFrame(columns=list_keys)\n",
    "meteorite_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_val = \"-99999\"\n",
    "\n",
    "for item in meteorite_page:\n",
    "    data = list()\n",
    "    for key in list_keys:\n",
    "        try:\n",
    "            data.append(item[key])\n",
    "        except:\n",
    "            data.append(missing_val)\n",
    "    meteorite_df.loc[len(meteorite_df)] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.replace(missing_val, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Type conversion__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df['id'] = meteorite_df['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['mass', 'reclat', 'reclong']\n",
    "meteorite_df[cols] = meteorite_df[cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df['year'] = pd.to_datetime(meteorite_df['year'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a `geometry` column__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df['geometry'] = [Point(xy) for xy in zip(meteorite_df.reclong, meteorite_df.reclat)] \n",
    "meteorite_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a GeoPandas GeoDataFrame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_gdf = gpd.GeoDataFrame(meteorite_df, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform data profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df['fall'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df['fall'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Examin the classes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df['recclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "# create list of labels\n",
    "class_labels = meteorite_df['recclass'].value_counts().head(n).tolist()\n",
    "\n",
    "meteorite_df['recclass'].value_counts().head(n).plot(kind='barh', title=f'Top {n} Meteorite Classes', width=0.9, figsize=(10, 5))\n",
    "plt.grid(axis='x', alpha=0.5)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# add count values from list\n",
    "for i, v in enumerate(class_labels):\n",
    "    plt.text(x=v+3, y=i+0.25, s=str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "# extract dataset by labels\n",
    "meteo_class = meteorite_df['recclass'].value_counts().head(n)\n",
    "\n",
    "# pie plot\n",
    "meteo_class.plot(kind='pie', title=f'Top {n} Meteorite Classes', figsize=(7, 7))\n",
    "plt.pie(meteo_class, wedgeprops = {'linewidth': 3, 'edgecolor': 'white'})\n",
    "\n",
    "# insert circle\n",
    "circle = plt.Circle((0, 0), 0.6, color='white')\n",
    "plt.gcf().gca().add_artist(circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of labels\n",
    "fall_labels = meteorite_df['fall'].value_counts().tolist()\n",
    "\n",
    "# bar plot - 'fall' labels\n",
    "meteorite_df['fall'].value_counts().plot.bar()\n",
    "\n",
    "# add count values from list\n",
    "for i, v in enumerate(fall_labels):\n",
    "    plt.text(x=i, y=v, s=str(v), ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Mass Distribution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram by 'fall' labels\n",
    "falls = meteorite_df.groupby('fall')\n",
    "\n",
    "for name, group in falls:\n",
    "    plt.hist(x=group['mass'], bins=10**np.linspace(-7, 7), alpha=0.5)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('log [mass]')\n",
    "plt.legend(['Fell','Found'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.plot(kind=\"scatter\", x=\"year\", y=\"mass\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x=meteorite_df['year'], \n",
    "            y=meteorite_df['mass'], c=np.log10(meteorite_df['mass']), \n",
    "            cmap='gist_earth', alpha=0.7\n",
    "           )\n",
    "plt.yscale('log')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('mass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Year distribution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot by 'fall' label\n",
    "for i in ['Found', 'Fell']:\n",
    "    pd.pivot_table(meteorite_df[meteorite_df['fall'] == i], \n",
    "                   index='year', values='name', \n",
    "                   aggfunc='count').plot(title=f'year vs {i}', ylabel=f'Num. of {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorite_df.plot(kind=\"scatter\", x=\"year\", y=\"reclat\", figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x=data['year'], y=data['lat'], alpha=0.4, marker='.')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('latitude')\n",
    "plt.grid(visible=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_url = url = \"https://naciscdn.org/naturalearth/110m/cultural/ne_110m_admin_0_countries.zip\"\n",
    "world_gdf = gpd.read_file(world_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_gdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_gdf['CONTINENT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "north_america = world_gdf[world_gdf['CONTINENT'] == 'North America']\n",
    "asia = = world_gdf[world_gdf['CONTINENT'] == 'Asia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = world_gdf.explore()\n",
    "meteorite_gdf.explore(\n",
    "    m=m, \n",
    "    column=\"mass\", \n",
    "    cmap=\"viridis_r\",\n",
    "    #style_kwds={\"style_function\":lambda x: {\"radius\":x[\"properties\"][\"mass\"]}}\n",
    ") #color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Scraping the NASA Astronomy Picture Of the Day (APOD) Webpage </font>\n",
    "\n",
    "- We want to be able to obtain from the webpage <a href=\"https://api.nasa.gov/planetary/apod\"> https://api.nasa.gov/planetary/apod</a>,  the Astronomy picture of the day for a given day and plot the image.\n",
    "- We access the webpage (using a set of parameters) and retrieve the content of the page as a JSON object.\n",
    "\n",
    "**Query Parameters**\n",
    "\n",
    "| Parameter | Type | Default | Description |\n",
    "| --- | --- | --- | --- |\n",
    "|`date` | YYYY-MM-DD | today | Date of the APOD image to retrieve |\n",
    "|`start_date` | YYYY-MM-DD | none | The start of a date range, when requesting date for a range of dates. Cannot be used with `date`. |\n",
    "|`end_date` | YYYY-MM-DD | today | The end of the date range, when used with `start_date`. |\n",
    "| `count` |\tint\t| none\t| If this is specified then count randomly chosen images will be returned. Cannot be used with `date` or `start_date` and `end_date`. |\n",
    "| `hd` | bool | False | Retrieve the URL for the high resolution image |\n",
    "| `api_key` | string | DEMO_KEY | <a href=\"https://api.nasa.gov/\">[https://api.nasa.gov/</a> key for expanded usage |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.nasa.gov/planetary/apod\"\n",
    "date = \"2022-07-04\"\n",
    "payload = {'api_key': \"DEMO_KEY\",\n",
    "          'date': date,\n",
    "          'hd': True}\n",
    "\n",
    "page_content = access_website(url, payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"URL: \\n\\t {page_content.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the content type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Content type: \\n\\t {page_content.headers['content-type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data with JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_page = json.loads(page_content.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The APOD variable is a dictionary of various keys and values. Let’s take a look at the keys of this variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in json_page:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the keys and values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in json_page:\n",
    "    print(f\"{x} --> {json_page[x]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(json_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if json_page[\"media_type\"] == \"image\":\n",
    "    io.imshow(io.imread(json_page[\"url\"]))\n",
    "    plt.title(json_page[\"title\"])\n",
    "    io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">If you want to download the file on your local system:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "url_name = json_page[\"url\"]\n",
    "loc_file_name = os.path.basename(url_name)\n",
    "\n",
    "urllib.request.urlretrieve(url_name, loc_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to view the image through a browser, use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript\n",
    "def window_open(url):\n",
    "    display(Javascript('window.open(\"{url}\");'.format(url=url)))\n",
    "    \n",
    "window_open(json_page['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Obtaining Mars Rover Photos</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rover_url = 'https://api.nasa.gov/mars-photos/api/v1/rovers/curiosity/photos'\n",
    "\n",
    "payload = {'api_key': \"DEMO_KEY\",\n",
    "           'sol': 1000}\n",
    "\n",
    "response = access_website(rover_url, payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"URL: \\n\\t {response.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Content type: \\n\\t {response.headers['content-type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"KEYS: \\n\\t {response_dict.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos = response_dict['photos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(photos))\n",
    "print(len(photos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(photos[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the URL of each photo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_photos = list()\n",
    "for photo in photos:\n",
    "    url_photos.append(photo['img_src'])\n",
    "\n",
    "print(url_photos[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly select 20 pictures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "url_pictures = random.sample(url_photos, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the 20 photos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(20, 20))\n",
    "ax = axes.ravel()\n",
    "\n",
    "for i in range(20):\n",
    "    ax[i].imshow(io.imread(url_pictures[i]))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"purple\">Breakout 1</font>\n",
    "\n",
    "Use the following code to list all the images in the provided range of years:\n",
    "\n",
    "```python\n",
    "url = \"https://images-api.nasa.gov/search\"\n",
    "\n",
    "payload = {\n",
    "        \"q\": \"apollo\",\n",
    "        \"page\": \"1\",\n",
    "        \"media_type\": \"image\",\n",
    "        \"year_start\": \"2020\",\n",
    "        \"year_end\": \"2022\"}\n",
    "\n",
    "response = reqs.get(url, params=payload)\n",
    "images = response.json()[\"collection\"][\"items\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"green\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "import requests as reqs\n",
    "\n",
    "url = \"https://images-api.nasa.gov/search\"\n",
    "\n",
    "params = {\n",
    "    \"q\": \"apollo\",\n",
    "    \"page\": \"1\",\n",
    "    \"media_type\": \"image\",\n",
    "    \"year_start\": \"2020\",\n",
    "    \"year_end\": \"2022\"\n",
    "}\n",
    "\n",
    "response = reqs.get(url, params=params)\n",
    "response.raise_for_status()\n",
    "\n",
    "images = response.json()[\"collection\"][\"items\"]\n",
    "print(f\"Number of images: {len(images)}\")\n",
    "for image in images:\n",
    "    thumbnail_url = image[\"links\"][0][\"href\"]\n",
    "    image_url = thumbnail_url[:thumbnail_url.rfind(\"~\")] + \"~orig.jpg\"\n",
    "    print(image_url)\n",
    "``` \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Global Temperature</font>\n",
    "\n",
    "https://www.columbia.edu/~mhs119/Temperature/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_url = \"https://www.columbia.edu/~mhs119/Temperature/Table_Ts.1880-2024vs1951-1980.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = access_website(temp_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Content type: \\n\\t {response.headers['content-type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = io.StringIO(response.text)\n",
    "df = pd.read_csv(file_object, \n",
    "                 sep=r\"\\s+\", \n",
    "                 skiprows=3, \n",
    "                 skipfooter=7, \n",
    "                 index_col=0,\n",
    "                 na_values=\"*****\",\n",
    "                 engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[list(df.columns)[:-1]].T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [i for i in range(1880, 2024, 20)]\n",
    "years.append(2024)\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[years][list(df.columns)[:-1]].T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[list(df.columns)[:-1]].plot(figsize=(10, 13), subplots=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Annual\"].iloc[:-1].astype(float).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Scraping the Earth Observatory Natural Event Tracker (EONET) Webpage </font>\n",
    "\n",
    "- EONET is a repository of metadata about natural events.\n",
    "- We want to be able to browse the webpage [https://eonet.gsfc.nasa.gov/api/v3/events](https://eonet.gsfc.nasa.gov/api/v2.1/events), to gather information on recent natural events on Earth.\n",
    "\n",
    "**Query Parameters**\n",
    "\n",
    "| Parameter | Value(s) |  Description |\n",
    "| --- | --- | --- |\n",
    "|`source` | Source ID | Filter the returned events by the [Source](https://eonet.gsfc.nasa.gov/api/v3/sources). Multiple sources can be included in the parameter: comma separated, operates as a boolean `OR`. |\n",
    "|`category` | Category ID | Filter the returned events by the category. |\n",
    "|`status` | open or closed | Events that have ended are assigned a closed date and the existence of that date will allow you to filter for only-open or only-closed events. Omitting the status parameter will return only the currently open events. |\n",
    "| `limit` | int | Limits the number of events returned |\n",
    "| `days ` | int | Limit the number of prior days (including today) from which events will be returned. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sample sources__:\n",
    "\n",
    "- `EO`: [Earth Observatory](https://earthobservatory.nasa.gov/)\n",
    "- `Earthdata`: [NASA Earth Observation Data](https://earthdata.nasa.gov)\n",
    "- `FEMA`: [Federal Emergency Management Agency (FEMA)](https://www.fema.gov/)\n",
    "- `JTWC`: [Joint Typhoon Warning Center](http://www.metoc.navy.mil/jtwc/jtwc.html)\n",
    "- `NASA_ESRS`: [NASA Earth Science and Remote Sensing Unit](https://eol.jsc.nasa.gov/ESRS/)\n",
    "- `NASA_HURR`: [NASA Hurricane And Typhoon Updates](https://blogs.nasa.gov/hurricanes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eonet_url = \"https://eonet.gsfc.nasa.gov/api/v3/events\"\n",
    "eonet_source = \"EO,JTWC,Earthdata,FEMA\"\n",
    "eonet_payload = {\n",
    "    'source': eonet_source,\n",
    "    'status': \"open\",\n",
    "    'limit': 100,\n",
    "    'days': 180\n",
    "}\n",
    "\n",
    "page_content = access_website(eonet_url, eonet_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Content type: \\n\\t {page_content.headers['content-type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eonet_page = json.loads(page_content.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in eonet_page:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(eonet_page['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(eonet_page['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(eonet_page['events'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eonet_page['events'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in eonet_page['events']:\n",
    "    print(event['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze one event\n",
    "\n",
    "We use `Pandas`, `GeoPandas` and `MovingPandas` to track the movement of an event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = eonet_page['events'][0]\n",
    "print(event['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['latitude', 'longitude', 't']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for geom in event['geometry']:\n",
    "    lat = geom['coordinates'][1]\n",
    "    lon = geom['coordinates'][0]\n",
    "    date = geom['date']\n",
    "    row = dict(latitude=lat, longitude=lon, t=date)\n",
    "    df.loc[len(df)] = row\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t'] = pd.to_datetime(df['t'], format = '%Y-%m-%dT%H:%M:%SZ')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['geometry'] = [Point(xy) for xy in zip(df.longitude, df.latitude)] \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a GeoPandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(df)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a MovingPandas Trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = mpd.Trajectory(gdf, 1)\n",
    "mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the distance and the speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.add_distance(overwrite=True, name=\"distance\", units=\"mi\")\n",
    "mdf.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.add_speed(overwrite=True, \n",
    "                      name=\"speed\", units=(\"mi\", \"h\"))\n",
    "\n",
    "mdf.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.hvplot(tiles=\"ESRI\",\n",
    "           c=\"speed\",\n",
    "           title=event['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Web Scraping with Beautiful Soup</font>\n",
    "\n",
    "- Web scraping allows you to download the HTML of a website and extract the data that you need.\n",
    "- Beautiful Soup is a Python library for scraping data from websites.\n",
    "- Beautiful Soup creates a parse tree from parsed HTML and XML documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Example: Extract the web link of the Astronomy Picture of the Day</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://apod.nasa.gov/apod/astropix.html\"\n",
    "source = access_website(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysoup = bso(source.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mysoup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print basic information of the Image of the Day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mysoup.find('p').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "href_comments = mysoup.find_all('a')\n",
    "for a in href_comments:\n",
    "    print(a.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">__The `Picture of the Day` can either be a picture or a video.__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_day = \"picture\"\n",
    "if mysoup.iframe:\n",
    "    print(\"We have a video.\")\n",
    "    picture_day = \"video\"\n",
    "else:\n",
    "    print(\"We have a picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if picture_day == \"video\":\n",
    "    HTML(str(mysoup.iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if picture_day == \"video\":\n",
    "    mysoup.iframe['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if picture_day == \"video\":\n",
    "    src_list = [a['src'] for a in mysoup.select('iframe[src]')]\n",
    "    src_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the `src` tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tags = mysoup.find_all(src=True)\n",
    "src_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all `href` attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "href_tags = mysoup.find_all(href=True)\n",
    "href_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all valud urls in `a` tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_with_text = [a['href'] for a in mysoup.find_all('a', href=True) if a.text]\n",
    "links_with_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list1 = [a['href'] for a in mysoup.find_all('a', href=True)]\n",
    "link_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list2 = [l.get('href') for l in mysoup.find_all('a')]\n",
    "link_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list3 = [a['href'] for a in mysoup.select('a[href]')]\n",
    "link_list3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the Picture of the Day is an image instead (not a video), the following can help us view the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if picture_day == \"picture\":\n",
    "    url_image = \"\".join([\"https://apod.nasa.gov/apod/\", link_list3[1]])\n",
    "    fig, axes = plt.subplots(figsize=(10, 8))\n",
    "    axes.imshow(io.imread(url_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"purple\">Breakout 2</font>\n",
    "\n",
    "Go to the webpage:\n",
    "\n",
    "[https://astg606.github.io/py_courses/summer_2022/](https://astg606.github.io/py_courses/summer_2022/)\n",
    "\n",
    "and extract the `Course Evaluation` web link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"green\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "import requests as reqs\n",
    "\n",
    "from bs4 import BeautifulSoup as bso\n",
    "\n",
    "URL = \"https://astg606.github.io/py_courses/summer_2022/\"\n",
    "\n",
    "source = reqs.get(URL)\n",
    "if source.status_code == 200:\n",
    "    mysoup = bso(source.content, 'html.parser')\n",
    "    href_tags = mysoup.find_all(href=True)\n",
    "    for tag in href_tags:\n",
    "        if tag.get_text() == \"Course Evaluation\":\n",
    "            print(tag[\"href\"])\n",
    "else:\n",
    "    print(\"URL not accessible.\")\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Example: Weather Data for Greenbelt, Maryland</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://forecast.weather.gov/MapClick.php\"\n",
    "params = {'lat': 39.00079000000005,\n",
    "          'lon': -76.88055999999995}\n",
    "\n",
    "source = access_website(url, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"URL: \\n\\t {source.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysoup = bso(source.text, 'html.parser')\n",
    "print(mysoup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract Tonight's Forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_day = mysoup.find(id=\"seven-day-forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in forecast_items:\n",
    "    if item.find(class_=\"period-name\").get_text() == \"Tonight\":\n",
    "        tonight = item\n",
    "        break\n",
    "\n",
    "print(tonight.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = tonight.find(class_=\"period-name\").get_text()\n",
    "print(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_desc = tonight.find(class_=\"short-desc\").get_text()\n",
    "print(short_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tonight.find(class_=\"temp\").get_text()\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tonight.find(\"img\")\n",
    "desc = img['title']\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting all Data**\n",
    "\n",
    "We use CSS selectors to extract everything at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select all items with the class `period-name` inside an item with the class `tombstone-container` in `seven_day`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_tags = seven_day.select(\".tombstone-container .period-name\")\n",
    "periods = [pt.get_text() for pt in period_tags]\n",
    "print(periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the same technique to get the other fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_descs = [sd.get_text() for sd in seven_day.select(\".tombstone-container .short-desc\")]\n",
    "print(short_descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]\n",
    "print(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(temps) < len(descs):\n",
    "    temps = [\" \"] + temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the data into a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "forecast_dict = dict(Period=periods, \n",
    "                     Temperature=temps,\n",
    "                     Short_Description=short_descs,  \n",
    "                     Description=descs)\n",
    "df_weather = pd.DataFrame(forecast_dict)\n",
    "df_weather = df_weather.set_index(\"Period\")\n",
    "df_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detailed Forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_forecast = mysoup.find(id=\"detailed-forecast-body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_labels = det_forecast.find_all(class_=\"col-sm-2 forecast-label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_texts = det_forecast.find_all(class_=\"col-sm-10 forecast-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in zip(forecast_labels, forecast_texts):\n",
    "    print(f\"\\033[1m {a.get_text():>15}: \\033[0m {b.get_text():<}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"purple\">Breakout 3</font>\n",
    "\n",
    "- Go to the sitethe website `https://eonet.gsfc.nasa.gov/api/v2.1/events`\n",
    "- Select a date range and the number of events you want to retrieve.\n",
    "- Creade a Pandas DataFrame that contains as columns the event type, date, latitude and longitude.\n",
    "\n",
    "```python\n",
    "url = \"https://eonet.gsfc.nasa.gov/api/v2.1/events\"\n",
    "payload = {'source': \"EO\",\n",
    "          'status': \"open\",\n",
    "          'limit': 6,\n",
    "          'days': 100}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b><font color=\"green\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "import json\n",
    "\n",
    "url = \"https://eonet.gsfc.nasa.gov/api/v2.1/events\"\n",
    "payload = {'source': \"EO\",\n",
    "          'status': \"open\",\n",
    "          'limit': 6,\n",
    "          'days': 100}\n",
    "\n",
    "page_content = reqs.get(url, params=payload)\n",
    "\n",
    "if page_content.status_code == 200:\n",
    "    json_page = json.loads(page_content.text)\n",
    "\n",
    "for x in json_page:\n",
    "    print(x)\n",
    "\n",
    "list_events = json_page['events']\n",
    "\n",
    "print(f\"Number of events: {len(list_events)}\")\n",
    "print(f\"List of events: \\n {list_events}\")\n",
    "\n",
    "event_types = [evt['categories'][0]['title'] for evt in list_events]\n",
    "event_dates = [evt['geometries'][0]['date'] for evt in list_events]\n",
    "event_lons = [evt['geometries'][0]['coordinates'][0] for evt in list_events]\n",
    "event_lats = [evt['geometries'][0]['coordinates'][1] for evt in list_events]\n",
    "\n",
    "print()\n",
    "\n",
    "import pandas as pd\n",
    "df_events = pd.DataFrame({\n",
    "    \"Type\": event_types,\n",
    "    \"Dates\": event_dates,\n",
    "    #\"Latitudes\": event_lats,\n",
    "    \"Longitudes\":event_lons\n",
    "})\n",
    "df_events\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Example: MODIS Aerosol Optical Thickness</font>\n",
    "\n",
    "- Scientists use measurements from the MODIS sensor aboard NASA's Terra and Aqua satellites to map the amount of aerosol that is in the air all over the world. Because aerosols reflect visible and near-infrared light back to space, scientists can use satellites to make maps of where there are high concentrations of these particles.\n",
    "- Scientists call this measurement aerosol optical thickness (AOT). \n",
    "- It is a measure of how much light the airborne particles prevent from traveling through the atmosphere. \n",
    "- Aerosols absorb and scatter incoming sunlight, thus reducing visibility and increasing optical thickness. An optical thickness of less than 0.1 indicates a crystal clear sky with maximum visibility, whereas a value of 1 indicates the presence of aerosols so dense that people would have difficulty seeing the Sun, even at mid-day!\n",
    "\n",
    "\n",
    "In this example, we want to access the <a href=\"https://neo.gsfc.nasa.gov/\">NASA Earth Observations (NEO)</a> website to obtain the AOT measurements for a given day or a range of days (from 2000 to present)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the day range of interest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_date = '2019-12-30'\n",
    "end_date = '2019-12-31'\n",
    "\n",
    "pd_series = pd.date_range(start=beg_date, end=end_date, freq='D')\n",
    "dates = [dt.strftime('%Y-%m-%d') for dt in pd_series]\n",
    "\n",
    "url_base = \"https://neo.gsfc.nasa.gov/view.php?datasetId=MODAL2_M_AER_OD&year=\"\n",
    "\n",
    "urls = [url_base+dt for dt in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(urls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Access the webpage for the first day:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = reqs.get(urls[0])\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse the webpage and print its content:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysoup = bso(source.text, 'html.parser')\n",
    "print(mysoup.prettify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gather all the lines with `href` tag:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "href_tags = mysoup.find_all(href=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "href_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the `http` address that has the word `CSV`. That will give us the remote location of the file we want to read.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in href_tags:\n",
    "    loc_url = tag[\"href\"]\n",
    "    print(loc_url)\n",
    "    if \"csv\" in loc_url.lower():\n",
    "        csv_url = loc_url\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(csv_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use `Pandas` to read the remote file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = access_website(csv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = io.StringIO(resp.content.decode('utf-8'))\n",
    "pd.read_csv(file_object, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It seems that `99999.0` corresponds to a missing value. Let us replace it with `NaN`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = io.StringIO(resp.content.decode('utf-8'))\n",
    "df = pd.read_csv(file_object, index_col=0, na_values=99999.0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use `Xarray` to quickly visualize the data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.DataArray(\n",
    "    df.values,\n",
    "    coords=[[float(lat) for lat in df.index], [float(lon) for lon in df.columns]],\n",
    "    dims=['latitude', 'longitude']\n",
    ")\n",
    "\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
